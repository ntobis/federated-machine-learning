{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.minimum(c, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2.]\n",
      " [2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session().as_default():\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [a, b, c]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.path.dirname(os.path.dirname('/Users/nico/PycharmProjects/FederatedLearning/Notebooks/explore.ipynb'))\n",
    "AUTISM = os.path.join(ROOT, 'Data', 'Autism')\n",
    "MODELS = os.path.join(ROOT, 'Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickle_files(directory):\n",
    "    files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".pkl\"):\n",
    "            files.append(os.path.join(directory, file))\n",
    "    files = sorted(files)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        file = pickle.load(f)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_autism_data(file):\n",
    "    frame_number_col = 5\n",
    "    splits = 6, 257, 327, 354, 378, 393\n",
    "    \n",
    "    frames = file[frame_number_col]\n",
    "    offset_file = file[:,splits[0]:]\n",
    "    face = offset_file[:,:splits[1]]\n",
    "    body = offset_file[:,splits[1]:splits[2]]\n",
    "    phy = offset_file[:,splits[2]:splits[3]]\n",
    "    audio = offset_file[:,splits[3]:splits[4]]\n",
    "    cars = offset_file[:,splits[4]:splits[5]]\n",
    "    labels = offset_file[:,-1:]\n",
    "    return frames, face, body, phy, audio, cars, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_autism_data_into_clients():\n",
    "    files = get_pickle_files(AUTISM)\n",
    "    clients_frames, clients_face, clients_body, clients_phy, clients_audio, clients_cars, clients_labels = [],[],[],[],[],[],[]\n",
    "\n",
    "    for file_name in files:\n",
    "        file = load_pickle(file_name)\n",
    "        frames, face, body, phy, audio, cars, labels = prepare_autism_data(file)\n",
    "        clients_frames.append(frames)\n",
    "        clients_face.append(face)\n",
    "        clients_body.append(body)\n",
    "        clients_phy.append(phy)\n",
    "        clients_audio.append(audio)\n",
    "        clients_cars.append(cars)\n",
    "        clients_labels.append(labels)\n",
    "    return clients_frames, clients_face, clients_body, clients_phy, clients_audio, clients_cars, clients_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(features, labels, test_split=0.25, shuffle=False):\n",
    "    if shuffle:\n",
    "        features, labels = unison_shuffled_copies(features, labels)\n",
    "    split_point = int(len(features)*test_split)\n",
    "    train_data = features[split_point:]\n",
    "    test_data = features[:split_point]\n",
    "    train_labels = features[split_point:]\n",
    "    test_labels = features[:split_point]\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = load_autism_data_into_clients()\n",
    "body = clients[2]\n",
    "labels = clients[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_test_train_split(features, labels, test_split=0.25, shuffle=False):\n",
    "    \n",
    "    for idx, client in enumerate(features):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490342, 257)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(clients[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
