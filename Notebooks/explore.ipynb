{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tf.keras.models  # like 'from tensorflow.keras import models' (PyCharm import issue workaround)\n",
    "layers = tf.keras.layers  # like 'from tensorflow.keras import layers' (PyCharm import issue workaround)\n",
    "optimizers = tf.keras.optimizers  # like 'from tensorflow.keras import optimizers' (PyCharm import issue workaround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    \"\"\"\n",
    "    Loads the MNIST Data Set and reshapes it for further model training\n",
    "\n",
    "    :return:\n",
    "        train_images        numpy array of shape (60000, 28, 28, 1)\n",
    "        train_labels        numpy array of shape (60000, )\n",
    "        test_images         numpy array of shape (10000, 28, 28, 1)\n",
    "        test_labels         numpy array of shape (10000, )\n",
    "    \"\"\"\n",
    "\n",
    "    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "    test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "    # Normalize pixel values to be between 0 and 1\n",
    "    train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_clients(clients, split, train_data, train_labels):\n",
    "    \"\"\"\n",
    "    Utility function to split train data and labels into a specified number of clients, in accordance with a specified\n",
    "    type of split.\n",
    "\n",
    "    :param clients:                     int, number of clients the data needs to be split into\n",
    "    :param split:                       string, type of split that should be performed\n",
    "    :param train_data:                  numpy array, train data\n",
    "    :param train_labels:                numpy array, train_labels\n",
    "    :return:\n",
    "        train_data                      list of numpy arrays, train_data, split into clients\n",
    "        train_labels                    list of numpy arrays, train_labels, split into clients\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(train_data) == len(train_labels)\n",
    "\n",
    "    # Split data\n",
    "    if split.lower() == 'random':\n",
    "        train_data, train_labels = fed_CNN.split_data_into_clients(clients, train_data, train_labels)\n",
    "    elif split.lower() == 'overlap':\n",
    "        train_data, train_labels = Data_Loader.sort_data(train_data, train_labels)\n",
    "        train_data, train_labels = fed_CNN.split_data_into_clients(clients, train_data, train_labels)\n",
    "        for idx in range(len(train_data)):\n",
    "            train_data[idx], train_labels[idx] = Data_Loader.unison_shuffled_copies(train_data[idx], train_labels[idx])\n",
    "    elif split.lower() == 'no_overlap':\n",
    "        split_data, split_labels = Data_Loader.split_by_label(train_data, train_labels)\n",
    "        train_data, train_labels = Data_Loader.allocate_data(clients,\n",
    "                                                             split_data,\n",
    "                                                             split_labels,\n",
    "                                                             categories_per_client=2,\n",
    "                                                             data_points_per_category=int(\n",
    "                                                                 len(train_data) / (clients * 2)))\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid value for 'Split'. Value can be 'random', 'overlap', 'no_overlap', value was: {}\".format(split))\n",
    "    return train_data, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape):\n",
    "    \"\"\"\n",
    "    Compile and return a simple CNN model for image recognition.\n",
    "\n",
    "    Configuration:\n",
    "    Layer 1: Convolution Layer | Filters: 32 | Kernel Size: 3x3 | Activation: Relu\n",
    "    Layer 2: Max Pooling Layer | Filter: 2x2\n",
    "    Layer 3: Dense Layer       | Neurons: 32 | Activation: Relu\n",
    "    Layer 4: Dense Layer       | Neurons: 10 | Activation: Softmax\n",
    "\n",
    "    Optimizer:      Adam\n",
    "    Loss function:  Sparse Categorical Cross Entropy\n",
    "    Loss metric:    Accuracy\n",
    "\n",
    "\n",
    "    :param input_shape:     image input shape (tuple), e.g. (28, 28, 1)\n",
    "\n",
    "    :return:\n",
    "        model               compiled tensorflow model\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up model type\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add layers, inspired by https://www.tensorflow.org/beta/tutorials/images/intro_to_cnns\n",
    "    model.add(layers.Conv2D(32, (5, 5), input_shape=input_shape, kernel_initializer='random_normal'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (5, 5), input_shape=input_shape, kernel_initializer='random_normal'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(layers.Dense(10, activation='softmax', kernel_initializer='random_normal'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model_1 = build_cnn(input_shape=(28, 28, 1))\n",
    "model_2 = build_cnn(input_shape=(28, 28, 1))\n",
    "model_3 = build_cnn(input_shape=(28, 28, 1))\n",
    "model_4 = build_cnn(input_shape=(28, 28, 1))\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fed_CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b73b6fe5c588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data_into_clients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-ce9cee5aef71>\u001b[0m in \u001b[0;36msplit_data_into_clients\u001b[0;34m(clients, split, train_data, train_labels)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfed_CNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_data_into_clients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'overlap'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_Loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fed_CNN' is not defined"
     ]
    }
   ],
   "source": [
    "clients = 10\n",
    "split = 'random'\n",
    "train_data, train_labels, test_data, test_labels = load_mnist_data()\n",
    "train_data, train_labels = split_data_into_clients(clients, split, train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
