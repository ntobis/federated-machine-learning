{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain Data Preparation\n",
    "This notebook prepares the pain dataset in to be able to successfully train a convolutional neural network. Data augmentation techniques such as greyscaling, histogram equalization, etc. are employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from Scripts import Data_Loader_Functions as DL\n",
    "from Scripts import Image_Processor as IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths\n",
    "RAW_DATA = os.path.join(module_path, \"Data\", \"Raw Data\", \"Pain\")\n",
    "PREPROCESSED_DATA = os.path.join(module_path, \"Data\", \"Preprocessed Data\", \"Pain\")\n",
    "AUGMENTED_DATA = os.path.join(module_path, \"Data\", \"Augmented Data\", \"Pain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Folder Structure\n",
    "First, we will duplicate the folder structure in \"Raw Data\" into \"Preprocessed Data\" and \"Augmented Data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate folder structure\n",
    "DL.mirror_folder_structure(RAW_DATA, PREPROCESSED_DATA)\n",
    "DL.mirror_folder_structure(RAW_DATA, AUGMENTED_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images\n",
    "We will now process the images. Preprocessing includes converting to greyscale, and histogram equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "IP.bulk_process_images(RAW_DATA, PREPROCESSED_DATA, \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip images and copy originals into augmented data folder\n",
    "IP.bulk_augment_images(PREPROCESSED_DATA, AUGMENTED_DATA, \".jpg\", \"flip\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_augment_images(PREPROCESSED_DATA, AUGMENTED_DATA, \".jpg\", \"original\", \"pain\", label_threshold=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate Originals and flipped images, and ensure that naming conventions stay consistent\n",
    "IP.bulk_augment_images(AUGMENTED_DATA, AUGMENTED_DATA, \"_flipped.jpg\", \"rotate_crop\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_augment_images(AUGMENTED_DATA, AUGMENTED_DATA, \"_original.jpg\", \"rotate_crop\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_rename_files(AUGMENTED_DATA, AUGMENTED_DATA, \"_rotated\", \"_straight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample augmented data\n",
    "DL.downsample_data(os.path.join(AUGMENTED_DATA, \"training\"))\n",
    "DL.downsample_data(os.path.join(AUGMENTED_DATA, \"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Images\n",
    "In this part we check that the image augmentation had the desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images processed\n",
      "1000 images processed\n",
      "2000 images processed\n",
      "3000 images processed\n",
      "4000 images processed\n",
      "5000 images processed\n",
      "6000 images processed\n",
      "7000 images processed\n",
      "8000 images processed\n",
      "9000 images processed\n",
      "10000 images processed\n",
      "11000 images processed\n",
      "12000 images processed\n"
     ]
    }
   ],
   "source": [
    "# Load all images into numpy array\n",
    "PAIN_TRAIN = os.path.join(AUGMENTED_DATA, \"training\")\n",
    "PAIN_TEST = os.path.join(AUGMENTED_DATA, \"test\")\n",
    "train_data, train_labels, test_data, test_labels = DL.load_pain_data(PAIN_TRAIN, '', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['flipped', 'original'], dtype='<U8'), array([6146, 6186]))\n"
     ]
    }
   ],
   "source": [
    "# Show Flipped/Original Distribution for Train and Test\n",
    "print(np.unique(train_labels[:,-1], return_counts=True))\n",
    "# print(np.unique(test_labels[:,-1], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['109', '5', '0', '12', '5', 'flipped'], dtype='<U8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show exemplary label\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce Pain Labels down to 0/1\n",
    "pain_label = 4\n",
    "max_pain_level = 1\n",
    "\n",
    "train_labels = DL.reduce_pain_label_categories(train_labels[:,pain_label].astype(np.int), max_pain=max_pain_level)\n",
    "# test_labels = DL.reduce_pain_label_categories(test_labels[:,pain_label].astype(np.int), max_pain=max_pain_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show pain distribution for train and test\n",
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the results\n",
    "print(\"Train Data: Shape\", train_data.shape)\n",
    "print(\"Train Labels: Shape\", train_labels.shape)\n",
    "print(\"Test Data: Shape\", test_data.shape)\n",
    "print(\"Test Labels: Shape\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "Here we bild a simple Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape):\n",
    "    \"\"\"\n",
    "    Compile and return a simple CNN model for image recognition.\n",
    "\n",
    "    Configuration:\n",
    "    Layer 1: Convolution Layer | Filters: 32 | Kernel Size: 3x3 | Activation: Relu\n",
    "    Layer 2: Max Pooling Layer | Filter: 2x2\n",
    "    Layer 3: Dense Layer       | Neurons: 32 | Activation: Relu\n",
    "    Layer 4: Dense Layer       | Neurons: 10 | Activation: Softmax\n",
    "\n",
    "    Optimizer:      Adam\n",
    "    Loss function:  Sparse Categorical Cross Entropy\n",
    "    Loss metric:    Accuracy\n",
    "\n",
    "\n",
    "    :param input_shape:     image input shape (tuple), e.g. (28, 28, 1)\n",
    "\n",
    "    :return:\n",
    "        model               compiled tensorflow model\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up model type\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add layers\n",
    "    model.add(layers.Conv2D(32, (5, 5), input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (5, 5)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (5, 5)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "models = tf.keras.models  # like 'from tensorflow.keras import models' (PyCharm import issue workaround)\n",
    "layers = tf.keras.layers  # like 'from tensorflow.keras import layers' (PyCharm import issue workaround)\n",
    "optimizers = tf.keras.optimizers  # like 'from tensorflow.keras import optimizers' (PyCharm import issue workaround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn(train_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data[:500], train_labels[:500], epochs=1, batch_size=32, validation_split=0,  use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FederatedLearning",
   "language": "python",
   "name": "federatedlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
