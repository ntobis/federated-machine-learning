{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain Data Preparation\n",
    "This notebook prepares the pain dataset in to be able to successfully train a convolutional neural network. Data augmentation techniques such as greyscaling, histogram equalization, etc. are employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from Scripts import Data_Loader_Functions as DL\n",
    "from Scripts import Image_Processor as IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths\n",
    "RAW_DATA = os.path.join(module_path, \"Data\", \"Raw Data\", \"Pain\")\n",
    "PREPROCESSED_DATA = os.path.join(module_path, \"Data\", \"Preprocessed Data\", \"Pain\")\n",
    "AUGMENTED_DATA = os.path.join(module_path, \"Data\", \"Augmented Data\", \"Pain\")\n",
    "AUGMENTED_DATA_TWOSTEP = os.path.join(module_path, \"Data\", \"Augmented Data\", \"Pain Two-Step Augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Folder Structure\n",
    "First, we will duplicate the folder structure in \"Raw Data\" into \"Preprocessed Data\" and \"Augmented Data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate folder structure\n",
    "DL.mirror_folder_structure(RAW_DATA, PREPROCESSED_DATA)\n",
    "DL.mirror_folder_structure(RAW_DATA, AUGMENTED_DATA)\n",
    "DL.mirror_folder_structure(RAW_DATA, AUGMENTED_DATA_TWOSTEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original pain distribution\n",
    "img_paths = np.array(DL.get_image_paths(RAW_DATA))\n",
    "labels = np.array(DL.get_labels(img_paths))\n",
    "no_pain_labels = labels[labels[:,4].astype(int)==0]\n",
    "pain_labels = labels[labels[:,4].astype(int)>0]\n",
    "print(\"Pain Labels:\", len(pain_labels))\n",
    "print(\"No Pain Labels:\", len(no_pain_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of clients per group\n",
    "g1_img_paths = [x for x in os.listdir(os.path.join(RAW_DATA, \"group_1\")) if x != '.DS_Store']\n",
    "g2_img_paths = [x for x in os.listdir(os.path.join(RAW_DATA, \"group_2\")) if x != '.DS_Store']\n",
    "print(\"Group 1:\", len(g1_img_paths))\n",
    "print(\"Group 2:\", len(g2_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of sessions per client\n",
    "g1_img_paths = np.array(DL.get_image_paths(os.path.join(RAW_DATA, \"group_1\")))\n",
    "g2_img_paths = np.array(DL.get_image_paths(os.path.join(RAW_DATA, \"group_2\")))\n",
    "g1_labels = np.array(DL.get_labels(g1_img_paths))\n",
    "g2_labels = np.array(DL.get_labels(g2_img_paths))\n",
    "df_1 = pd.DataFrame(g1_labels, columns=['Person','Session','Culture','Frame','Pain']).astype(int)\n",
    "df_2 = pd.DataFrame(g2_labels, columns=['Person','Session','Culture','Frame','Pain']).astype(int)\n",
    "df_1['Group'] = 1\n",
    "df_2['Group'] = 2\n",
    "df = pd.concat([df_1, df_2])\n",
    "sess_num = pd.DataFrame(df.groupby(['Person', 'Group'])['Session'].nunique()).sort_values(['Group','Person'])\n",
    "sess_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of sessions per group\n",
    "print(\"Average Sessions Group 1: {0:.2f}\".format(df_1.groupby('Person')['Session'].nunique().mean()))\n",
    "print(\"Average Sessions Group 2: {0:.2f}\".format(df_2.groupby('Person')['Session'].nunique().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pain / No Pain per group\n",
    "print(\"Group 1 Pain/No Pain/Ratio: {} | {}\".format(df[(df['Group'] == 1) & (df['Pain'] == 0)].count()[0], df[(df['Group'] == 1) & (df['Pain'] > 0)].count()[0]))\n",
    "print(\"Group 2 Pain/No Pain/Ratio: {} | {}\".format(df[(df['Group'] == 2) & (df['Pain'] == 0)].count()[0], df[(df['Group'] == 2) & (df['Pain'] > 0)].count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images\n",
    "We will now process the images. Preprocessing includes converting to greyscale, and histogram equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "IP.bulk_process_images(RAW_DATA, PREPROCESSED_DATA, \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip images and copy originals into augmented data folder\n",
    "IP.bulk_augment_images(PREPROCESSED_DATA, AUGMENTED_DATA_TWOSTEP, \".jpg\", \"flip\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_augment_images(PREPROCESSED_DATA, AUGMENTED_DATA_TWOSTEP, \".jpg\", \"original\", \"pain\", label_threshold=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate Originals and flipped images, and ensure that naming conventions stay consistent\n",
    "IP.bulk_augment_images(AUGMENTED_DATA_TWOSTEP, AUGMENTED_DATA_TWOSTEP, \"_flipped.jpg\", \"rotate_crop\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_augment_images(AUGMENTED_DATA_TWOSTEP, AUGMENTED_DATA_TWOSTEP, \"_original.jpg\", \"rotate_crop\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_rename_files(AUGMENTED_DATA_TWOSTEP, AUGMENTED_DATA_TWOSTEP, \"_rotated\", \"_straight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop images to same maximum width and height (10-degree rotation in previous step cropped rotated images \n",
    "# down to (215, 215), so this is chosen as a max width/height)\n",
    "IP.bulk_rename_files(AUGMENTED_DATA_TWOSTEP, AUGMENTED_DATA_TWOSTEP, \"_rotated\", \"_straight\")\n",
    "IP.bulk_crop_images(AUGMENTED_DATA_TWOSTEP, AUGMENTED_DATA_TWOSTEP, (215, 215))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample augmented data\n",
    "DL.downsample_data(os.path.join(AUGMENTED_DATA_TWOSTEP, \"training\"))\n",
    "DL.downsample_data(os.path.join(AUGMENTED_DATA_TWOSTEP, \"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset by clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = DL.get_image_paths(AUGMENTED_DATA_TWOSTEP)\n",
    "labels = DL.get_labels(img_paths)\n",
    "df = pd.DataFrame(labels, columns=['Person','Session','Culture','Frame','Pain', 'Trans_1', 'Trans_2'])\n",
    "df[['Person','Session','Culture','Frame','Pain']] = df[['Person','Session','Culture','Frame','Pain']].astype(int)\n",
    "df['img_path'] = img_paths\n",
    "df[['Trans_1', 'Trans_2', 'img_path']] = df[['Trans_1', 'Trans_2', 'img_path']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset (Randomly)\n",
    "Splitting the dataset into training data and test data, by sampling without replacement from the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all images and select 20% at random\n",
    "img_paths = DL.get_image_paths(AUGMENTED_DATA_TWOSTEP)\n",
    "np.random.shuffle(img_paths)\n",
    "split_idx = int(len(img_paths)*0.2)\n",
    "img_paths_test = img_paths[:split_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that each client is represented with ~20% in the test data set\n",
    "img_per_client_test = np.unique(np.array(DL.get_labels(img_paths_test))[:,0], return_counts=True)[1]\n",
    "img_per_client_total = np.unique(np.array(DL.get_labels(img_paths))[:,0], return_counts=True)[1]\n",
    "img_per_client_test / img_per_client_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the test set is balanced\n",
    "pain = np.array(img_paths_test)[np.array(DL.get_labels(img_paths_test))[:,4].astype(int) >= 1]\n",
    "pain_test_labels = np.array(DL.get_labels(pain))\n",
    "all_test_labels = np.array(DL.get_labels(img_paths_test))\n",
    "print(\"Test Pain Split:\",len(pain_labels) / len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the split for each client in the test set\n",
    "DL.print_pain_split_per_client(all_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move test data set into test folder\n",
    "for src in img_paths_test:\n",
    "    file = os.path.basename(src)\n",
    "    dest = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(src))), 'test')\n",
    "    if not os.path.isdir(dest):\n",
    "        os.mkdir(dest)\n",
    "    try:\n",
    "        os.rename(src, os.path.join(dest, file))\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Images\n",
    "In this part we check that the image augmentation had the desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = os.path.join(AUGMENTED_DATA_TWOSTEP, \"test\")\n",
    "print(\"DISTRIBUTION\")\n",
    "DL.print_pain_label_dist(AUGMENTED_DATA_TWOSTEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images processed\n",
      "1000 images processed\n",
      "2000 images processed\n",
      "3000 images processed\n",
      "4000 images processed\n",
      "5000 images processed\n",
      "6000 images processed\n",
      "7000 images processed\n",
      "8000 images processed\n",
      "9000 images processed\n",
      "10000 images processed\n",
      "11000 images processed\n"
     ]
    }
   ],
   "source": [
    "# Load all images into numpy array\n",
    "PAIN_TRAIN = os.path.join(AUGMENTED_DATA_TWOSTEP, \"training\")\n",
    "PAIN_TEST = os.path.join(AUGMENTED_DATA_TWOSTEP, \"test\")\n",
    "train_data, train_labels, test_data, test_labels = DL.load_pain_data(PAIN_TRAIN, PAIN_TEST, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Flipped/Original Distribution for Train and Test\n",
    "print(np.unique(train_labels[:,-2], return_counts=True))\n",
    "print(np.unique(test_labels[:,-2], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show exemplary label\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce Pain Labels down to 0/1\n",
    "pain_label = 4\n",
    "max_pain_level = 1\n",
    "\n",
    "# train_labels = DL.reduce_pain_label_categories(train_labels[:,pain_label].astype(np.int), max_pain=max_pain_level)\n",
    "test_labels = DL.reduce_pain_label_categories(test_labels[:,pain_label].astype(np.int), max_pain=max_pain_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show pain distribution for train and test\n",
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the results\n",
    "print(\"Train Data: Shape\", train_data.shape)\n",
    "print(\"Train Labels: Shape\", train_labels.shape)\n",
    "print(\"Test Data: Shape\", test_data.shape)\n",
    "print(\"Test Labels: Shape\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "Here we bild a simple Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape):\n",
    "    \"\"\"\n",
    "    Compile and return a simple CNN model for image recognition.\n",
    "\n",
    "    Configuration:\n",
    "    Layer 1: Convolution Layer | Filters: 32 | Kernel Size: 3x3 | Activation: Relu\n",
    "    Layer 2: Max Pooling Layer | Filter: 2x2\n",
    "    Layer 3: Dense Layer       | Neurons: 32 | Activation: Relu\n",
    "    Layer 4: Dense Layer       | Neurons: 10 | Activation: Softmax\n",
    "\n",
    "    Optimizer:      Adam\n",
    "    Loss function:  Sparse Categorical Cross Entropy\n",
    "    Loss metric:    Accuracy\n",
    "\n",
    "\n",
    "    :param input_shape:     image input shape (tuple), e.g. (28, 28, 1)\n",
    "\n",
    "    :return:\n",
    "        model               compiled tensorflow model\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up model type\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add layers\n",
    "    model.add(layers.Conv2D(32, (5, 5), input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (5, 5)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (5, 5)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "models = tf.keras.models  # like 'from tensorflow.keras import models' (PyCharm import issue workaround)\n",
    "layers = tf.keras.layers  # like 'from tensorflow.keras import layers' (PyCharm import issue workaround)\n",
    "optimizers = tf.keras.optimizers  # like 'from tensorflow.keras import optimizers' (PyCharm import issue workaround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "        'accuracy',\n",
    "        tf.metrics.Recall(),\n",
    "        tf.metrics.Precision(),\n",
    "        tf.metrics.AUC(curve='PR'),\n",
    "        tf.metrics.TruePositives(),\n",
    "        tf.metrics.TrueNegatives(),\n",
    "        tf.metrics.FalsePositives(),\n",
    "        tf.metrics.FalseNegatives(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn(test_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples\n",
      "30/30 [==============================] - 2s 63ms/sample - loss: 0.6669 - accuracy: 0.6667\n",
      "30/30 [==============================] - 1s 32ms/sample - loss: 0.6558 - accuracy: 0.6667 - recall_4: 0.5000 - precision_3: 0.5667 - auc_3: 0.6027 - true_positives_3: 17.0000 - true_negatives_3: 13.0000 - false_positives_3: 13.0000 - false_negatives_3: 17.0000\n",
      "Train on 30 samples\n",
      "30/30 [==============================] - 2s 64ms/sample - loss: 0.6558 - accuracy: 0.6667\n",
      "30/30 [==============================] - 1s 32ms/sample - loss: 0.6475 - accuracy: 0.7000 - recall_4: 0.5000 - precision_3: 0.5667 - auc_3: 0.6148 - true_positives_3: 17.0000 - true_negatives_3: 13.0000 - false_positives_3: 13.0000 - false_negatives_3: 17.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 2\n",
    "\n",
    "results = []\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(test_data[:30], test_labels[:30], epochs=1, batch_size=32, validation_split=0,  use_multiprocessing=True)\n",
    "    \n",
    "    # Evaluating\n",
    "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=metrics)\n",
    "    epoch_results = model.evaluate(test_data[:30], test_labels[:30], batch_size=1)\n",
    "    results.append(epoch_results)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\n",
    "            'Loss',\n",
    "            'Accuracy',\n",
    "            'Recall',\n",
    "            'Precision',\n",
    "            'AUC',\n",
    "            'TP',\n",
    "            'TN',\n",
    "            'FP',\n",
    "            'FN'\n",
    "            ]\n",
    "        )\n",
    "    f1_score = 2*((df['Precision']*df['Recall'])/(df['Precision']+df['Recall']))\n",
    "    df['F1_Score'] = f1_score\n",
    "    df.to_csv('log_results_epoch-{}_type-{}.csv'.format(epoch, train_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655810</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.602681</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.647472</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.614824</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.53125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loss  Accuracy  Recall  Precision       AUC    TP    TN    FP    FN  \\\n",
       "0  0.655810  0.666667     0.5   0.566667  0.602681  17.0  13.0  13.0  17.0   \n",
       "1  0.647472  0.700000     0.5   0.566667  0.614824  17.0  13.0  13.0  17.0   \n",
       "\n",
       "   F1_Score  \n",
       "0   0.53125  \n",
       "1   0.53125  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples\n",
      "500/500 [==============================] - 38s 75ms/sample - loss: 0.7116 - accuracy: 0.0000e+00 - recall_1: 0.5000 - precision: 0.5120 - auc: 0.5154 - true_positives: 256.0000 - true_negatives: 244.0000 - false_positives: 244.0000 - false_negatives: 256.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142378e10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(test_data[:500], test_labels[:500], epochs=1, batch_size=32, validation_split=0,  use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/sample - loss: 0.6754 - accuracy: 0.6160 - recall_4: 0.5000 - precision_3: 0.5120 - auc_3: 0.6208 - true_positives_3: 256.0000 - true_negatives_3: 244.0000 - false_positives_3: 244.0000 - false_negatives_3: 256.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6754372404813767, 0.616, 0.5, 0.512, 0.6207885, 256.0, 244.0, 244.0, 256.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=metrics)\n",
    "model.evaluate(test_data[:500], test_labels[:500], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FederatedLearning",
   "language": "python",
   "name": "federatedlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
