{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain Data Preparation\n",
    "This notebook prepares the pain dataset in to be able to successfully train a convolutional neural network. Data augmentation techniques such as greyscaling, histogram equalization, etc. are employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from Scripts import Data_Loader_Functions as dL\n",
    "from Scripts import Image_Processor as IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths\n",
    "RAW_DATA = os.path.join(module_path, \"Data\", \"Raw Data\")\n",
    "PREPROCESSED_DATA = os.path.join(module_path, \"Data\", \"Preprocessed Data\")\n",
    "AUGMENTED_DATA = os.path.join(module_path, \"Data\", \"Augmented Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_group(df, path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    for f_path in df['img_path'].values:\n",
    "        os.rename(f_path, os.path.join(path, os.path.basename(f_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-Process and augment images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mirror Folder structure\n",
      "Pre-process Images\n",
      "Flip Images\n",
      "Rotate Images\n",
      "Crop Images\n"
     ]
    }
   ],
   "source": [
    "# Mirror Folder structure\n",
    "print(\"Mirror Folder structure\")\n",
    "dL.mirror_folder_structure(RAW_DATA, PREPROCESSED_DATA)\n",
    "dL.mirror_folder_structure(RAW_DATA, AUGMENTED_DATA)\n",
    "\n",
    "# Pre-process images\n",
    "print(\"Pre-process Images\")\n",
    "IP.bulk_process_images(RAW_DATA, PREPROCESSED_DATA, \".jpg\")\n",
    "\n",
    "# Flip images and copy originals into augmented data folder\n",
    "print(\"Flip Images\")\n",
    "IP.bulk_augment_images(PREPROCESSED_DATA, AUGMENTED_DATA, \".jpg\", \"flip\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_augment_images(PREPROCESSED_DATA, AUGMENTED_DATA, \".jpg\", \"original\", \"pain\", label_threshold=-1)\n",
    "\n",
    "# Rotate Originals and flipped images, and ensure that naming conventions stay consistent\n",
    "print(\"Rotate Images\")\n",
    "IP.bulk_augment_images(AUGMENTED_DATA, AUGMENTED_DATA, \"_flipped.jpg\", \"rotate_crop\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_augment_images(AUGMENTED_DATA, AUGMENTED_DATA, \"_original.jpg\", \"rotate_crop\", \"pain\", label_threshold=-1)\n",
    "IP.bulk_rename_files(AUGMENTED_DATA, AUGMENTED_DATA, \"_rotated\", \"_straight\")\n",
    "\n",
    "# Crop images to same maximum width and height (10-degree rotation in previous step cropped rotated images \n",
    "# down to (215, 215), so this is chosen as a max width/height)\n",
    "print(\"Crop Images\")\n",
    "IP.bulk_crop_images(AUGMENTED_DATA, AUGMENTED_DATA, (215, 215), \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Reset Folder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving all images into the \"raw\" subfolder\n",
    "dL.reset_to_raw(AUGMENTED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting all empty folders\n",
    "dL.delete_empty_folders(AUGMENTED_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image paths and corresponding labels into a dataframe\n",
    "img_paths = np.array(dL.get_image_paths(AUGMENTED_DATA))\n",
    "labels = np.array(dL.get_labels(img_paths))\n",
    "df = pd.DataFrame(labels, columns=['Person','Session','Culture','Frame','Pain', 'Trans_1', 'Trans_2'])\n",
    "df[['Person','Session','Culture','Frame','Pain']] = df[['Person','Session','Culture','Frame','Pain']].astype(int)\n",
    "df['img_path'] = img_paths\n",
    "df[['Trans_1', 'Trans_2', 'img_path']] = df[['Trans_1', 'Trans_2', 'img_path']].astype(str)\n",
    "df = df.sort_values(['Person', 'Session', 'Frame', 'Trans_1', 'Trans_2'], ascending=[True, True, True, False, False]).reset_index(drop=True)\n",
    "df['temp_id'] = df['Person'].astype(str) + df['Session'].astype(str) + df['Frame'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.1: Remove Subject 101 from the data\n",
    "Subject 101 only has negative examples \"0\" and will therefore show \"0%\" on metrics like \"Recall\" or \"Precision\", skewing output graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Pain Labels Subject 101 :  0\n"
     ]
    }
   ],
   "source": [
    "# Proving that subject 101 only has 0 labels\n",
    "subject = 101\n",
    "print(\"# Pain Labels Subject {} : \".format(subject), np.sum(df[df['Person'] == subject]['Pain']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing subject 101 from the data\n",
    "df = df[df['Person'] != 101]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Redistribute Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into two groups\n",
    "group_1 = [42, 47, 49, 66, 95, 97, 103, 106, 108, 121, 123, 124]\n",
    "df_1 = df[df['Person'].isin(group_1)]\n",
    "df_2 = df[~df['Person'].isin(group_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 43,  48,  52,  59,  64,  80,  92,  96, 107, 109, 115, 120])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['Person'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate Group 1\n",
    "group_1_path = os.path.join(AUGMENTED_DATA, \"group_1\")\n",
    "if not os.path.isdir(group_1_path):\n",
    "    os.mkdir(group_1_path)\n",
    "allocate_group(df_1, group_1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate Group 2\n",
    "group_2_path = os.path.join(AUGMENTED_DATA, \"group_2\")\n",
    "if not os.path.isdir(group_2_path):\n",
    "    os.mkdir(group_2_path)\n",
    "allocate_group(df_2, group_2_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FederatedLearning",
   "language": "python",
   "name": "federatedlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
