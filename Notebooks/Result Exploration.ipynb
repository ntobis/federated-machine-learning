{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Exploration\n",
    "This notebook helps to build functions for printing results of CNN training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from IPython.display import display_html\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from Scripts import Print_Functions as PF\n",
    "from Scripts import Centralized_Pain_CNN as painCNN\n",
    "from Scripts import Data_Loader_Functions as DL\n",
    "\n",
    "FIGURES = os.path.join(module_path, \"Figures\")\n",
    "RESULTS = os.path.join(module_path, \"Results\")\n",
    "DATA = os.path.join(module_path, \"Data\", \"Augmented Data\", \"Flexible Augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Plots for Aggregate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "model_type = 'Centralized'\n",
    "data_type = 'Sessions'\n",
    "\n",
    "centralized_path = os.path.join(module_path, 'Models', 'Pain', 'Centralized', 'Final', data_type)\n",
    "centralized_model_paths = sorted([os.path.join(centralized_path, path) for path in os.listdir(centralized_path) if 'shard-0.00' in path])\n",
    "federated_path = os.path.join(module_path, 'Models', 'Pain', 'Federated', 'Final', data_type)\n",
    "federated_model_paths = sorted([os.path.join(federated_path, path) for path in os.listdir(federated_path) if 'shard-0.00' in path])\n",
    "model_paths = centralized_model_paths if model_type == 'Centralized' else federated_model_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Create Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "if data_type == 'Sessions':\n",
    "    test_path = os.path.join(DATA, \"group_2\")\n",
    "    df = DL.create_pain_df(test_path)\n",
    "    df_test = df[(df['Trans_1'] == 'original') & (df['Trans_2'] == 'straight')]\n",
    "else:\n",
    "    test_path = os.path.join(DATA, \"group_2_test\")\n",
    "    test_data, test_labels = DL.load_pain_data(test_path)\n",
    "    test_labels_binary = DL.reduce_pain_label_categories(test_labels[:, 4].astype(int), 1)\n",
    "    enc = OneHotEncoder(sparse=False, categories='auto')\n",
    "    test_labels_binary = enc.fit_transform(test_labels_binary.reshape(len(test_labels_binary), 1))\n",
    "    people = test_labels[:, 0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(model_paths[-1])\n",
    "model = tf.keras.models.load_model(model_paths[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "if data_type is not 'Sessions':\n",
    "    df_history = painCNN.evaluate_pain_cnn(model, 0, test_data, test_labels_binary, history=None, people=people, loss=loss)\n",
    "else:\n",
    "    df_history = painCNN.evaluate_pain_cnn(model, 0, test_data=None, test_labels=None, df=df_test, history=None, people=None, loss=loss, session=True)\n",
    "df_history['Shard'] = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save predictions to file\n",
    "baseline_path = os.path.join(RESULTS, 'Final', data_type, '2019-08-06_PAIN_0-' + data_type.lower() + \"-\" + model_type + '-Baseline')\n",
    "if not os.path.isdir(baseline_path):\n",
    "    os.mkdir(baseline_path)\n",
    "\n",
    "file = time.strftime(\"%Y-%m-%d-%H%M%S\") + \"_PAIN_\" + data_type.lower() + \"-\" + model_type + \".csv\"\n",
    "df_history.to_csv(os.path.join(baseline_path, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set variable to plot\n",
    "current_metric = 'Accuracy'\n",
    "# current_metric = 'Precision'\n",
    "# current_metric = 'Recall'\n",
    "# current_metric = 'F1_Score'\n",
    "# current_metric = 'Avg. Precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set experiment filter\n",
    "criteria = '-sessions'\n",
    "date = '2019-08-08'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get relevant folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all paths in Final Results folder\n",
    "final_results = os.path.join(RESULTS, 'Final', data_type)\n",
    "final_results_folders = sorted([os.path.join(final_results, path) for path in os.listdir(final_results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter paths for relevant experiments\n",
    "final_results_folders = [folder for folder in final_results_folders if criteria in folder and date in folder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Draw Aggregate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = 'Aggregate ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = folders[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir(folder)):\n",
    "    if 'shard-0.00' not in file:\n",
    "        file = os.path.join(folder, file)\n",
    "        df = pd.read_csv(file, index_col=0)\n",
    "        df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "        for sess, df_session in df.groupby('Session'):\n",
    "            tn_g = df.groupby('Epoch')['TN'].transform(sum)\n",
    "            fp_g = df.groupby('Epoch')['FP'].transform(sum)\n",
    "            fn_g = df.groupby('Epoch')['FN'].transform(sum)\n",
    "            tp_g = df.groupby('Epoch')['TP'].transform(sum)\n",
    "            df['Aggregate Accuracy'] = (tp_g + tn_g) / (tn_g + fp_g + fn_g + tp_g)\n",
    "            df['Aggregate Precision'] = tp_g / (fp_g + tp_g)\n",
    "            df['Aggregate Recall'] = tp_g / (fn_g + tp_g)\n",
    "            df['Aggregate F1_Score'] = 2 * ((df['Aggregate Precision'] * df['Aggregate Recall']) / (\n",
    "                    df['Aggregate Precision'] + df['Aggregate Recall']))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 18, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 22})\n",
    "\n",
    "# Draw Aggregate Plot\n",
    "columns = ['Shard', 'Epoch', 'Loss', 'Aggregate Avg. Precision', 'Aggregate Accuracy', \n",
    "            'Aggregate Precision', 'Aggregate Recall', 'Aggregate F1_Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Draw metrics\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = pd.DataFrame(columns=columns)\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "            df_concat.drop_duplicates(inplace=True)\n",
    "    df_concat.reset_index(inplace=True)\n",
    "    ax = df_concat[metric].plot(figsize=(24, 16), color=colors[idx], linewidth=1, linestyle=line_style[idx])\n",
    "\n",
    "# Draw VLines\n",
    "for i, file in enumerate(sorted(os.listdir(folders[0]))):\n",
    "    ax.axvline(i * (df_concat['Epoch'].max() + 1), color='#C0C0C0', linestyle='dashed', label='_nolegend_')\n",
    "    shard = float(file.split('_shard-')[1].split('_')[0])\n",
    "    shard_text = \"Shard: {:.0%}\".format(shard) if \"sessions\" not in file else \"Session: {}\".format(int(shard)+1)\n",
    "    plt.text(i * (df_concat['Epoch'].max() + 1) + 1, 0.02, shard_text)\n",
    "\n",
    "# Draw Baselines\n",
    "# baseline_folders = sorted([folder for folder in final_results_folders if 'Baseline' in folder])\n",
    "# h_colors =['#002BA0', '#DD0426']\n",
    "# h_line_style = ['--', '-']\n",
    "# for idx, folder in enumerate(baseline_folders):\n",
    "#     for file in os.listdir(folder):\n",
    "#         file = os.path.join(folder, file)\n",
    "#         df = pd.read_csv(file, index_col=0)\n",
    "#         ax.axhline(df[metric].iloc[0], color=h_colors[idx], linestyle=h_line_style[idx])\n",
    "\n",
    "\n",
    "# Set plot parameters\n",
    "folders.extend(baseline_folders)\n",
    "ax.legend([folder.split('PAIN_')[1] for folder in folders], loc='best')\n",
    "ax.set_title(\"{} | All Experiments\".format(metric))\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in np.arange(0,1.1,0.1)])\n",
    "ax.set_ylabel(metric)\n",
    "ax.set_xlabel('Epochs / Communication Rounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save figure\n",
    "fig_path = os.path.join(FIGURES, 'Final', data_type)\n",
    "file = os.path.join(fig_path, metric + '.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 Individual Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify Metrics\n",
    "current_metric = \"F1-Score\" if current_metric == \"F1_Score\" else current_metric\n",
    "metric = 'Individual ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 18, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 22})\n",
    "\n",
    "# Draw standard deviation\n",
    "columns = ['Shard', 'Epoch', 'Person', 'Loss', 'Individual Avg. Precision', 'Individual Accuracy', \n",
    "            'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Plot standard deviations\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df['Person'] = df['Person'].astype(int)\n",
    "            pivot = df.pivot(index='Epoch', columns='Person', values=metric)\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=pivot.columns)\n",
    "            df_concat = pd.concat((df_concat, pivot), ignore_index=True)\n",
    "    df_concat['Mean'] = df_concat.mean(axis=1)\n",
    "    df_concat['SD'] = df_concat.std(axis=1)\n",
    "    ax = df_concat['SD'].plot(figsize=(24, 16), color=colors[idx], linewidth=1, linestyle=line_style[idx])\n",
    "    \n",
    "for i, file in enumerate(sorted(os.listdir(folders[0]))):\n",
    "    ax.axvline(i * int(len(df_concat) / len(os.listdir(folders[0]))), color='#C0C0C0', linestyle='dashed', label='_nolegend_')\n",
    "    shard = float(file.split('_shard-')[1].split('_')[0])\n",
    "    shard_text = \"Shard: {:.0%}\".format(shard) if \"sessions\" not in file else \"Session: {}\".format(int(shard)+1)\n",
    "    plt.text(i * int(len(df_concat) / len(os.listdir(folders[0]))) + 1, 0.005, shard_text)\n",
    "    \n",
    "ax.legend([folder.split('PAIN_')[1] for folder in folders], loc='best')\n",
    "ax.set_title(\"{} | Standard deviation between subjects | All Experiments\".format(metric))\n",
    "ax.set_yticks(np.arange(0, 0.5, 0.1))\n",
    "ax.set_ylabel('Standard deviation between subjects')\n",
    "ax.set_xlabel('Epochs / Communication Rounds')\n",
    "metric = 'SD_' + metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save figure\n",
    "fig_path = os.path.join(FIGURES, 'Final', data_type)\n",
    "file = os.path.join(fig_path, metric + '.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3 Individual metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify Metrics\n",
    "current_metric = \"F1-Score\" if current_metric == \"F1_Score\" else current_metric\n",
    "metric = 'Individual ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 12, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 14})\n",
    "\n",
    "# Draw individual metrics\n",
    "columns = ['Shard', 'Epoch', 'Person', 'Loss', 'Individual Avg. Precision', 'Individual Accuracy', \n",
    "            'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Plot standard deviations\n",
    "fig = plt.figure(dpi=300, figsize=(48, 60))\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df['Person'] = df['Person'].astype(int)\n",
    "            pivot = df.pivot(index='Epoch', columns='Person', values=metric)\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=pivot.columns)\n",
    "            df_concat = pd.concat((df_concat, pivot), ignore_index=True)\n",
    "    ax = df_concat.plot(figsize=(24, 20), linewidth=1, ax=fig.add_subplot(3, 2, idx+1))\n",
    "    \n",
    "    for i, file in enumerate(sorted(os.listdir(folders[0]))):\n",
    "        ax.axvline(i * int(len(df_concat) / len(os.listdir(folders[0]))), color='#C0C0C0', linestyle='dashed', label='_nolegend_')\n",
    "        shard = float(file.split('_shard-')[1].split('_')[0])\n",
    "        shard_text = \"Shard: {:.0%}\".format(shard) if \"sessions\" not in file else \"Session: {}\".format(int(shard)+1)\n",
    "        plt.text(i * int(len(df_concat) / len(os.listdir(folders[0]))) + 1, 0.005, shard_text)\n",
    "    \n",
    "    ax.legend(loc='best', title='Test Subject')\n",
    "    ax.set_title(\"{}\".format(folder.split('PAIN_')[1]))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in np.arange(0,1.1,0.1)])\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel('Epochs / Communication Rounds')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(metric, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save figure\n",
    "fig_path = os.path.join(FIGURES, 'Final', data_type)\n",
    "file = os.path.join(fig_path, metric + '.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4 Individual Metrics - Final Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify Metrics\n",
    "current_metric = \"F1-Score\" if current_metric == \"F1_Score\" else current_metric\n",
    "metric = 'Individual ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 12, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 14})\n",
    "\n",
    "# Draw individual metrics\n",
    "columns = ['Shard', 'Epoch', 'Person', 'Loss', 'Individual Avg. Precision', 'Individual Accuracy', \n",
    "            'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Plot standard deviations\n",
    "fig = plt.figure(dpi=300, figsize=(48, 60))\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df['Person'] = df['Person'].astype(int)\n",
    "            df = df[df['Epoch'] == df['Epoch'].max()]\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=df.columns)\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "    pivot = df_concat.pivot(index='Shard', columns='Person', values=metric)\n",
    "    ax = pivot.plot(figsize=(24, 20), linewidth=1, ax=fig.add_subplot(3, 2, idx+1))\n",
    "    ax.legend(loc='best', title='Test Subject')\n",
    "    ax.set_title(\"{}\".format(folder.split('PAIN_')[1]))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in np.arange(0,1.1,0.1)])\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xticks(pivot.index)\n",
    "    x_tick_format = '{:,.0%}' if \"sessions\" not in file else \"{:.0f}\"\n",
    "    ax.set_xticklabels([x_tick_format.format(x) for x in pivot.index])\n",
    "    xlabel = \"Shard\" if \"sessions\" not in file else \"Sessions\"\n",
    "    ax.set_xlabel(xlabel)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(\"Last Epoch Value: \" + metric, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save figure\n",
    "fig_path = os.path.join(FIGURES, 'Final', data_type)\n",
    "file = os.path.join(fig_path, \"Last Epoch \" + metric + '.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Session Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 18, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 22})\n",
    "\n",
    "# Draw Aggregate Plot\n",
    "columns = ['Shard', 'Epoch', 'Aggregate Accuracy', \n",
    "            'Aggregate Precision', 'Aggregate Recall', 'Aggregate F1_Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Draw metrics\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate([folders[1]]):\n",
    "    df_concat = pd.DataFrame(columns=columns)\n",
    "    for idx, file in enumerate(sorted(os.listdir(folder))):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            df.reset_index(inplace=True)\n",
    "            ax = df[metric].plot(figsize=(24, 16), linewidth=1)\n",
    "            \n",
    "# Draw VLines\n",
    "for i, file in enumerate(sorted(os.listdir(folders[0]))):\n",
    "    ax.axvline(i * (df_concat['Epoch'].max() + 1), color='#C0C0C0', linestyle='dashed', label='_nolegend_')\n",
    "    shard = float(file.split('_shard-')[1].split('_')[0])\n",
    "    shard_text = \"Shard: {:.0%}\".format(shard) if \"sessions\" not in file else \"Session: {}\".format(int(shard)+1)\n",
    "    plt.text(i * (df_concat['Epoch'].max() + 1) + 1, 0.02, shard_text)\n",
    "\n",
    "# Draw Baselines\n",
    "# baseline_folders = sorted([folder for folder in final_results_folders if 'Baseline' in folder])\n",
    "# h_colors =['#002BA0', '#DD0426']\n",
    "# h_line_style = ['--', '-']\n",
    "# for idx, folder in enumerate(baseline_folders):\n",
    "#     for file in os.listdir(folder):\n",
    "#         file = os.path.join(folder, file)\n",
    "#         df = pd.read_csv(file, index_col=0)\n",
    "#         ax.axhline(df[metric].iloc[0], color=h_colors[idx], linestyle=h_line_style[idx])\n",
    "\n",
    "\n",
    "# Set plot parameters\n",
    "folders.extend(baseline_folders)\n",
    "ax.legend([folder.split('PAIN_')[1] for folder in folders], loc='best')\n",
    "ax.set_title(\"{} | All Experiments\".format(metric))\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in np.arange(0,1.1,0.1)])\n",
    "ax.set_ylabel(metric)\n",
    "ax.set_xlabel('Epochs / Communication Rounds')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sumarize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: DataFrame Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.render()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display Data in Dataframe\n",
    "metrics = ['Individual Accuracy', 'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "display_type = 'single'\n",
    "\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    pivots = []\n",
    "    print(\"\\n\\n\\033[1m{}\\033[0m\".format(folder.split('PAIN_')[1]))\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df['Person'] = df['Person'].astype(int)\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=df.columns)\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "            df_concat.drop_duplicates(inplace=True)\n",
    "    df_concat.reset_index(inplace=True)\n",
    "    for metric in metrics:\n",
    "        columns = 'Shard'\n",
    "        index = 'Person'\n",
    "        df_filtered = df_concat[df_concat['Epoch'] == df_concat['Epoch'].max()]\n",
    "        pivot = df_filtered[[index, columns, metric]].drop_duplicates().pivot(index=index, columns=columns, values=metric)\n",
    "        cm = sns.diverging_palette(10, 130, n=9, as_cmap=True)\n",
    "        style = pivot.style.background_gradient(cmap=cm).format('{:,.0%}').set_caption(metric)\n",
    "        pivots.append(style)\n",
    "    display_side_by_side(pivots[0], pivots[1])\n",
    "    display_side_by_side(pivots[2], pivots[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Step 4.2 Table Summary Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_metric = 'Accuracy'\n",
    "metric = 'Aggregate ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save concatenated pivot to excel\n",
    "plt.rcParams.update({'font.size': 12, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 16})\n",
    "\n",
    "# Draw Aggregate Table\n",
    "columns = ['Shard', 'Epoch', 'Loss', 'Session', 'Aggregate Avg. Precision', 'Aggregate Accuracy', \n",
    "            'Aggregate Precision', 'Aggregate Recall', 'Aggregate F1_Score']\n",
    "\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "piv_conc = None\n",
    "for j, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            f_path = os.path.join(folder, file)\n",
    "            df = pd.read_csv(f_path, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=df.columns)\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "            df_concat.drop_duplicates(inplace=True)\n",
    "    df_concat = df_concat[df_concat['Epoch'] == 29]\n",
    "\n",
    "    pivot = df_concat.pivot(index='Shard', columns='Session', values=metric)   \n",
    "    pivot['Mean'] = pivot.mean(axis=1)\n",
    "    pivot = pivot.fillna(0)\n",
    "    if piv_conc is None:\n",
    "        piv_conc = pd.DataFrame(columns=pivot.columns)\n",
    "    piv_conc = pd.concat((piv_conc, pivot))\n",
    "piv_conc.to_excel(os.path.join(FIGURES, 'Final', data_type, \"Sessions Table \" + metric + '.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Step 4.3 Table Summary Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_metric = 'Avg. Precision'\n",
    "metric = 'Individual ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save concatenated pivot to excel\n",
    "plt.rcParams.update({'font.size': 12, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 16})\n",
    "\n",
    "# Draw Aggregate Table\n",
    "columns = ['Shard', 'Epoch', 'Loss', 'Person', 'Session', 'Individual Avg. Precision', 'Individual Accuracy', \n",
    "            'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "pivot_concat = None\n",
    "for j, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            f_path = os.path.join(folder, file)\n",
    "            df = pd.read_csv(f_path, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=df.columns)\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "            df_concat.drop_duplicates(inplace=True)\n",
    "    df_concat = df_concat[df_concat['Epoch'] == df_concat['Epoch'].max()]\n",
    "    df_concat['Shard'] = df_concat['Shard'].astype(int)\n",
    "    for person, df_person in df_concat.groupby('Person'):\n",
    "        pivot = df_person.pivot(index=\"Shard\", columns=\"Session\", values=metric)\n",
    "        pivot['Test Subject'] = person\n",
    "        if pivot_concat is None:\n",
    "            pivot_concat = pd.DataFrame(columns=[0,1,2,3,4,5,6,7,8,9, 'Test Subject'])\n",
    "        pivot_concat = pd.concat((pivot_concat, pivot), sort=False)\n",
    "    \n",
    "# Add Baseline\n",
    "baseline_folders = sorted([folder for folder in final_results_folders if 'Baseline' in folder])\n",
    "pivot_baseline = None\n",
    "for idx, folder in enumerate(baseline_folders):\n",
    "    for file in os.listdir(folder):\n",
    "        if os.path.splitext(file)[1] == '.csv':\n",
    "            f_path = os.path.join(folder, file)\n",
    "            df = pd.read_csv(f_path, index_col=0)\n",
    "            for person, df_person in df.groupby('Person'):\n",
    "                pivot = df_person.pivot(index=\"Shard\", columns=\"Session\", values=metric)\n",
    "                pivot['Test Subject'] = person\n",
    "                if pivot_baseline is None:\n",
    "                    pivot_baseline = pd.DataFrame(columns=[0,1,2,3,4,5,6,7,8,9, 'Test Subject'])\n",
    "                pivot_baseline = pd.concat((pivot_baseline, pivot), sort=False)\n",
    "pivot_concat = pd.concat((pivot_concat, pivot_baseline), sort=False)\n",
    "pivot_concat.to_excel(os.path.join(FIGURES, 'Final', data_type, \"Feeder Table\", \"Sessions Table \" + metric + '.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.4: Session Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_2 = DL.get_image_paths(os.path.join(DATA, 'group_2'))\n",
    "labels = np.array(DL.get_labels(group_2))\n",
    "columns = ['Person', 'Session', 'Culture', 'Frame', 'Pain', 'Trans_1', 'Trans_2']\n",
    "df = pd.DataFrame(labels, columns=columns)\n",
    "df[['Person', 'Session', 'Culture', 'Frame', 'Pain']] = df[['Person', 'Session', 'Culture', 'Frame', 'Pain']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot(index, columns, values):\n",
    "    pivot = ~df[['Person', 'Session']].drop_duplicates().pivot(index=index, columns=columns, values=values).isnull() * 1\n",
    "    pivot['# of ' + columns + 's'] = pivot.sum(1)\n",
    "    pivot = pivot.sort_values('# of ' + columns + 's', ascending=False)\n",
    "    \n",
    "    pivot['Pain'] = 0\n",
    "    pivot['No Pain'] = 0\n",
    "    for person, df_person in df.groupby(index):\n",
    "        pivot.at[person, 'No Pain'] = sum(df_person['Pain'] == 0)\n",
    "        pivot.at[person, 'Pain'] = sum(df_person['Pain'] > 0)\n",
    "        for col in pivot.columns:\n",
    "            if type(col) is int:\n",
    "                pivot.at[person, col] = sum(df_person[df_person[columns] == col]['Pain'] > 0)\n",
    "                \n",
    "    if columns is 'Session':\n",
    "        for col in reversed(pivot.columns):\n",
    "            if type(col) is int:\n",
    "                pivot.rename(columns={col:col+1}, inplace=True)\n",
    "    if index is 'Session':\n",
    "        for idx in reversed(pivot.index):\n",
    "            pivot.rename(index={idx:idx+1}, inplace=True)\n",
    "    pivot = pivot.append(pivot.sum(0).rename(\"Total\"))\n",
    "    pivot['Pain %'] = round(pivot['Pain'] / (pivot['Pain'] + pivot['No Pain']), 2)\n",
    "    pivot[pivot == 0] = ''\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index='Person'\n",
    "columns='Session'\n",
    "values=columns\n",
    "df = create_pivot(index, columns, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index='Session'\n",
    "columns='Person'\n",
    "values=columns\n",
    "create_pivot(index, columns, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_folders = [folder for folder in final_results_folders if criteria in folder and date in folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = None\n",
    "\n",
    "folder = final_results_folders[3]\n",
    "for file in os.listdir(folder):\n",
    "    if \"shard-0.00\" not in file:\n",
    "        f_path = os.path.join(folder, file)\n",
    "        df = pd.read_csv(f_path)\n",
    "        df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "        if df_concat is None:\n",
    "            df_concat = pd.DataFrame(columns=df.columns)\n",
    "        df_concat = pd.concat((df_concat, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session = None\n",
    "for sess, df in df_concat.groupby('Session'):\n",
    "    df_this = pd.DataFrame(columns=df.columns, data=df.values)\n",
    "    tn_g = df_this.groupby('Epoch')['TN'].transform(sum)\n",
    "    fp_g = df_this.groupby('Epoch')['FP'].transform(sum)\n",
    "    fn_g = df_this.groupby('Epoch')['FN'].transform(sum)\n",
    "    tp_g = df_this.groupby('Epoch')['TP'].transform(sum)\n",
    "    df_this['Aggregate Accuracy'] = (tp_g + tn_g) / (tn_g + fp_g + fn_g + tp_g)\n",
    "    df_this['Aggregate Precision'] = tp_g / (fp_g + tp_g)\n",
    "    df_this['Aggregate Recall'] = tp_g / (fn_g + tp_g)\n",
    "    df_this['Aggregate F1_Score'] = 2 * ((df_this['Aggregate Precision'] * df_this['Aggregate Recall']) / (\n",
    "            df_this['Aggregate Precision'] + df_this['Aggregate Recall']))\n",
    "    if df_session is None:\n",
    "        df_session = pd.DataFrame(columns=df_this.columns)\n",
    "    df_session = pd.concat((df_session, df_this), ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FederatedLearning",
   "language": "python",
   "name": "federatedlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
