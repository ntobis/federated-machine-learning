{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Exploration\n",
    "This notebook helps to build functions for printing results of CNN training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from IPython.display import display_html\n",
    "import shutil\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from Scripts import Print_Functions as PF\n",
    "from Scripts import Centralized_Pain as painCNN\n",
    "from Scripts import Data_Loader_Functions as DL\n",
    "\n",
    "FIGURES = os.path.join(module_path, \"Figures\")\n",
    "RESULTS = os.path.join(module_path, \"Results\")\n",
    "DATA = os.path.join(module_path, \"Data\", \"Augmented Data\", \"Flexible Augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Plots for Aggregate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "model_type = 'Centralized'\n",
    "data_type = 'Sessions'\n",
    "\n",
    "centralized_path = os.path.join(module_path, 'Models', 'Pain', 'Centralized', 'Final', data_type)\n",
    "centralized_model_paths = sorted([os.path.join(centralized_path, path) for path in os.listdir(centralized_path) if 'shard-0.00' in path])\n",
    "federated_path = os.path.join(module_path, 'Models', 'Pain', 'Federated', 'Final', data_type)\n",
    "federated_model_paths = sorted([os.path.join(federated_path, path) for path in os.listdir(federated_path) if 'shard-0.00' in path])\n",
    "model_paths = centralized_model_paths if model_type == 'Centralized' else federated_model_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Create Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "if data_type == 'Sessions':\n",
    "    test_path = os.path.join(DATA, \"group_2\")\n",
    "    df = DL.create_pain_df(test_path)\n",
    "    df_test = df[(df['Trans_1'] == 'original') & (df['Trans_2'] == 'straight')]\n",
    "else:\n",
    "    test_path = os.path.join(DATA, \"group_2_test\")\n",
    "    test_data, test_labels = DL.load_pain_data(test_path)\n",
    "    test_labels_binary = DL.reduce_pain_label_categories(test_labels[:, 4].astype(int), 1)\n",
    "    enc = OneHotEncoder(sparse=False, categories='auto')\n",
    "    test_labels_binary = enc.fit_transform(test_labels_binary.reshape(len(test_labels_binary), 1))\n",
    "    people = test_labels[:, 0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(model_paths[-1])\n",
    "model = tf.keras.models.load_model(model_paths[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "if data_type is not 'Sessions':\n",
    "    df_history = painCNN.evaluate_pain_cnn(model, 0, test_data, test_labels_binary, history=None, people=people, loss=loss)\n",
    "else:\n",
    "    df_history = painCNN.evaluate_pain_cnn(model, 0, test_data=None, test_labels=None, df=df_test, history=None, people=None, loss=loss, session=True)\n",
    "df_history['Shard'] = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save predictions to file\n",
    "baseline_path = os.path.join(RESULTS, 'Final', data_type, '2019-08-06_PAIN_0-' + data_type.lower() + \"-\" + model_type + '-Baseline')\n",
    "if not os.path.isdir(baseline_path):\n",
    "    os.mkdir(baseline_path)\n",
    "\n",
    "file = time.strftime(\"%Y-%m-%d-%H%M%S\") + \"_PAIN_\" + data_type.lower() + \"-\" + model_type + \".csv\"\n",
    "df_history.to_csv(os.path.join(baseline_path, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set variable to plot\n",
    "current_metric = 'Accuracy'\n",
    "# current_metric = 'Precision'\n",
    "# current_metric = 'Recall'\n",
    "# current_metric = 'F1_Score'\n",
    "# current_metric = 'Avg. Precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set experiment filter\n",
    "criteria = '-sessions'\n",
    "date = '2019-08-09'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get relevant folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all paths in Final Results folder\n",
    "final_results = os.path.join(RESULTS, 'Final', data_type)\n",
    "final_results_folders = sorted([os.path.join(final_results, path) for path in os.listdir(final_results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter paths for relevant experiments\n",
    "final_results_folders = [folder for folder in final_results_folders if criteria in folder and date in folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for person, df_person in df.groupby('Person'):\n",
    "    fig = plt.figure(dpi=300, figsize=(12, 8))\n",
    "    for session, df_session in df_person.groupby('Session'):\n",
    "        df_session.reset_index()['Loss'].plot(ax=fig.add_subplot(2, 1, 1), title='Person {}'.format(int(person)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Draw Aggregate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = 'Aggregate ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 18, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 22})\n",
    "\n",
    "# Draw Aggregate Plot\n",
    "columns = ['Shard', 'Epoch', 'Loss', 'Aggregate Avg. Precision', 'Aggregate Accuracy', \n",
    "            'Aggregate Precision', 'Aggregate Recall', 'Aggregate F1_Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Draw metrics\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = pd.DataFrame(columns=columns)\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "            df_concat.drop_duplicates(inplace=True)\n",
    "    df_concat.reset_index(inplace=True)\n",
    "    ax = df_concat[metric].plot(figsize=(24, 16), color=colors[idx], linewidth=1, linestyle=line_style[idx])\n",
    "\n",
    "# Draw VLines\n",
    "for i, file in enumerate(sorted(os.listdir(folders[0]))):\n",
    "    ax.axvline(i * (df_concat['Epoch'].max() + 1), color='#C0C0C0', linestyle='dashed', label='_nolegend_')\n",
    "    shard = float(file.split('_shard-')[1].split('_')[0])\n",
    "    shard_text = \"Shard: {:.0%}\".format(shard) if \"sessions\" not in file else \"Session: {}\".format(int(shard)+1)\n",
    "    plt.text(i * (df_concat['Epoch'].max() + 1) + 1, 0.02, shard_text)\n",
    "\n",
    "# Draw Baselines\n",
    "# baseline_folders = sorted([folder for folder in final_results_folders if 'Baseline' in folder])\n",
    "# h_colors =['#002BA0', '#DD0426']\n",
    "# h_line_style = ['--', '-']\n",
    "# for idx, folder in enumerate(baseline_folders):\n",
    "#     for file in os.listdir(folder):\n",
    "#         file = os.path.join(folder, file)\n",
    "#         df = pd.read_csv(file, index_col=0)\n",
    "#         ax.axhline(df[metric].iloc[0], color=h_colors[idx], linestyle=h_line_style[idx])\n",
    "\n",
    "\n",
    "# Set plot parameters\n",
    "folders.extend(baseline_folders)\n",
    "ax.legend([folder.split('PAIN_')[1] for folder in folders], loc='best')\n",
    "ax.set_title(\"{} | All Experiments\".format(metric))\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in np.arange(0,1.1,0.1)])\n",
    "ax.set_ylabel(metric)\n",
    "ax.set_xlabel('Epochs / Communication Rounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save figure\n",
    "fig_path = os.path.join(FIGURES, 'Final', data_type)\n",
    "file = os.path.join(fig_path, metric + '.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 Individual Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify Metrics\n",
    "current_metric = \"F1-Score\" if current_metric == \"F1_Score\" else current_metric\n",
    "metric = 'Individual ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 18, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 22})\n",
    "\n",
    "# Draw standard deviation\n",
    "columns = ['Shard', 'Epoch', 'Person', 'Loss', 'Individual Avg. Precision', 'Individual Accuracy', \n",
    "            'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Plot standard deviations\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df['Person'] = df['Person'].astype(int)\n",
    "            pivot = df.pivot(index='Epoch', columns='Person', values=metric)\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=pivot.columns)\n",
    "            df_concat = pd.concat((df_concat, pivot), ignore_index=True)\n",
    "    df_concat['Mean'] = df_concat.mean(axis=1)\n",
    "    df_concat['SD'] = df_concat.std(axis=1)\n",
    "    ax = df_concat['SD'].plot(figsize=(24, 16), color=colors[idx], linewidth=1, linestyle=line_style[idx])\n",
    "    \n",
    "for i, file in enumerate(sorted(os.listdir(folders[0]))):\n",
    "    ax.axvline(i * int(len(df_concat) / len(os.listdir(folders[0]))), color='#C0C0C0', linestyle='dashed', label='_nolegend_')\n",
    "    shard = float(file.split('_shard-')[1].split('_')[0])\n",
    "    shard_text = \"Shard: {:.0%}\".format(shard) if \"sessions\" not in file else \"Session: {}\".format(int(shard)+1)\n",
    "    plt.text(i * int(len(df_concat) / len(os.listdir(folders[0]))) + 1, 0.005, shard_text)\n",
    "    \n",
    "ax.legend([folder.split('PAIN_')[1] for folder in folders], loc='best')\n",
    "ax.set_title(\"{} | Standard deviation between subjects | All Experiments\".format(metric))\n",
    "ax.set_yticks(np.arange(0, 0.5, 0.1))\n",
    "ax.set_ylabel('Standard deviation between subjects')\n",
    "ax.set_xlabel('Epochs / Communication Rounds')\n",
    "metric = 'SD_' + metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save figure\n",
    "fig_path = os.path.join(FIGURES, 'Final', data_type)\n",
    "file = os.path.join(fig_path, metric + '.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3 Individual metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify Metrics\n",
    "current_metric = \"F1-Score\" if current_metric == \"F1_Score\" else current_metric\n",
    "metric = 'Individual ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 12, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 14})\n",
    "\n",
    "# Draw individual metrics\n",
    "columns = ['Shard', 'Epoch', 'Person', 'Loss', 'Individual Avg. Precision', 'Individual Accuracy', \n",
    "            'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Plot standard deviations\n",
    "fig = plt.figure(dpi=300, figsize=(48, 60))\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df['Person'] = df['Person'].astype(int)\n",
    "            pivot = df.pivot(index='Epoch', columns='Person', values=metric)\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=pivot.columns)\n",
    "            df_concat = pd.concat((df_concat, pivot), ignore_index=True)\n",
    "    ax = df_concat.plot(figsize=(24, 20), linewidth=1, ax=fig.add_subplot(3, 2, idx+1))\n",
    "    \n",
    "    for i, file in enumerate(sorted(os.listdir(folders[0]))):\n",
    "        ax.axvline(i * int(len(df_concat) / len(os.listdir(folders[0]))), color='#C0C0C0', linestyle='dashed', label='_nolegend_')\n",
    "        shard = float(file.split('_shard-')[1].split('_')[0])\n",
    "        shard_text = \"Shard: {:.0%}\".format(shard) if \"sessions\" not in file else \"Session: {}\".format(int(shard)+1)\n",
    "        plt.text(i * int(len(df_concat) / len(os.listdir(folders[0]))) + 1, 0.005, shard_text)\n",
    "    \n",
    "    ax.legend(loc='best', title='Test Subject')\n",
    "    ax.set_title(\"{}\".format(folder.split('PAIN_')[1]))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in np.arange(0,1.1,0.1)])\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel('Epochs / Communication Rounds')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(metric, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save figure\n",
    "fig_path = os.path.join(FIGURES, 'Final', data_type)\n",
    "file = os.path.join(fig_path, metric + '.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4 Individual Metrics - Final Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify Metrics\n",
    "current_metric = \"F1-Score\" if current_metric == \"F1_Score\" else current_metric\n",
    "metric = 'Individual ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 12, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 14})\n",
    "\n",
    "# Draw individual metrics\n",
    "columns = ['Shard', 'Epoch', 'Person', 'Loss', 'Individual Avg. Precision', 'Individual Accuracy', \n",
    "            'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Plot standard deviations\n",
    "fig = plt.figure(dpi=300, figsize=(48, 60))\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df['Person'] = df['Person'].astype(int)\n",
    "            df = df[df['Epoch'] == df['Epoch'].max()]\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=df.columns)\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "    pivot = df_concat.pivot(index='Shard', columns='Person', values=metric)\n",
    "    ax = pivot.plot(figsize=(24, 20), linewidth=1, ax=fig.add_subplot(3, 2, idx+1))\n",
    "    ax.legend(loc='best', title='Test Subject')\n",
    "    ax.set_title(\"{}\".format(folder.split('PAIN_')[1]))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in np.arange(0,1.1,0.1)])\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xticks(pivot.index)\n",
    "    x_tick_format = '{:,.0%}' if \"sessions\" not in file else \"{:.0f}\"\n",
    "    ax.set_xticklabels([x_tick_format.format(x) for x in pivot.index])\n",
    "    xlabel = \"Shard\" if \"sessions\" not in file else \"Sessions\"\n",
    "    ax.set_xlabel(xlabel)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(\"Last Epoch Value: \" + metric, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save figure\n",
    "fig_path = os.path.join(FIGURES, 'Final', data_type)\n",
    "file = os.path.join(fig_path, \"Last Epoch \" + metric + '.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Session Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 18, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 22})\n",
    "\n",
    "# Draw Aggregate Plot\n",
    "columns = ['Shard', 'Epoch', 'Aggregate Accuracy', \n",
    "            'Aggregate Precision', 'Aggregate Recall', 'Aggregate F1_Score']\n",
    "\n",
    "colors = ['#00065E', '#266DC9', '#F3752B', '#F02D3A', '#A20021']\n",
    "line_style = ['--', '--', '-', '-', '-']\n",
    "\n",
    "# Draw metrics\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate([folders[1]]):\n",
    "    df_concat = pd.DataFrame(columns=columns)\n",
    "    for idx, file in enumerate(sorted(os.listdir(folder))):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            df.reset_index(inplace=True)\n",
    "            ax = df[metric].plot(figsize=(24, 16), linewidth=1)\n",
    "            \n",
    "# Draw VLines\n",
    "for i, file in enumerate(sorted(os.listdir(folders[0]))):\n",
    "    ax.axvline(i * (df_concat['Epoch'].max() + 1), color='#C0C0C0', linestyle='dashed', label='_nolegend_')\n",
    "    shard = float(file.split('_shard-')[1].split('_')[0])\n",
    "    shard_text = \"Shard: {:.0%}\".format(shard) if \"sessions\" not in file else \"Session: {}\".format(int(shard)+1)\n",
    "    plt.text(i * (df_concat['Epoch'].max() + 1) + 1, 0.02, shard_text)\n",
    "\n",
    "# Draw Baselines\n",
    "# baseline_folders = sorted([folder for folder in final_results_folders if 'Baseline' in folder])\n",
    "# h_colors =['#002BA0', '#DD0426']\n",
    "# h_line_style = ['--', '-']\n",
    "# for idx, folder in enumerate(baseline_folders):\n",
    "#     for file in os.listdir(folder):\n",
    "#         file = os.path.join(folder, file)\n",
    "#         df = pd.read_csv(file, index_col=0)\n",
    "#         ax.axhline(df[metric].iloc[0], color=h_colors[idx], linestyle=h_line_style[idx])\n",
    "\n",
    "\n",
    "# Set plot parameters\n",
    "folders.extend(baseline_folders)\n",
    "ax.legend([folder.split('PAIN_')[1] for folder in folders], loc='best')\n",
    "ax.set_title(\"{} | All Experiments\".format(metric))\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in np.arange(0,1.1,0.1)])\n",
    "ax.set_ylabel(metric)\n",
    "ax.set_xlabel('Epochs / Communication Rounds')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sumarize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: DataFrame Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.render()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display Data in Dataframe\n",
    "metrics = ['Individual Accuracy', 'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "display_type = 'single'\n",
    "\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "for idx, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    pivots = []\n",
    "    print(\"\\n\\n\\033[1m{}\\033[0m\".format(folder.split('PAIN_')[1]))\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            file = os.path.join(folder, file)\n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df['Person'] = df['Person'].astype(int)\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=df.columns)\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "            df_concat.drop_duplicates(inplace=True)\n",
    "    df_concat.reset_index(inplace=True)\n",
    "    for metric in metrics:\n",
    "        columns = 'Shard'\n",
    "        index = 'Person'\n",
    "        df_filtered = df_concat[df_concat['Epoch'] == df_concat['Epoch'].max()]\n",
    "        pivot = df_filtered[[index, columns, metric]].drop_duplicates().pivot(index=index, columns=columns, values=metric)\n",
    "        cm = sns.diverging_palette(10, 130, n=9, as_cmap=True)\n",
    "        style = pivot.style.background_gradient(cmap=cm).format('{:,.0%}').set_caption(metric)\n",
    "        pivots.append(style)\n",
    "    display_side_by_side(pivots[0], pivots[1])\n",
    "    display_side_by_side(pivots[2], pivots[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Step 4.2 Table Summary Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_metric = 'Accuracy'\n",
    "metric = 'Aggregate ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save concatenated pivot to excel\n",
    "plt.rcParams.update({'font.size': 12, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 16})\n",
    "\n",
    "# Draw Aggregate Table\n",
    "columns = ['Shard', 'Epoch', 'Loss', 'Session', 'Aggregate Avg. Precision', 'Aggregate Accuracy', \n",
    "            'Aggregate Precision', 'Aggregate Recall', 'Aggregate F1_Score']\n",
    "\n",
    "folders = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "piv_conc = None\n",
    "for j, folder in enumerate(folders):\n",
    "    df_concat = None\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        if 'shard-0.00' not in file:\n",
    "            f_path = os.path.join(folder, file)\n",
    "            df = pd.read_csv(f_path, index_col=0)\n",
    "            df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "            df = df[columns]\n",
    "            if df_concat is None:\n",
    "                df_concat = pd.DataFrame(columns=df.columns)\n",
    "            df_concat = pd.concat((df_concat, df), ignore_index=True)\n",
    "            df_concat.drop_duplicates(inplace=True)\n",
    "    df_concat = df_concat[df_concat['Epoch'] == 29]\n",
    "\n",
    "    pivot = df_concat.pivot(index='Shard', columns='Session', values=metric)   \n",
    "    pivot['Mean'] = pivot.mean(axis=1)\n",
    "    pivot = pivot.fillna(0)\n",
    "    if piv_conc is None:\n",
    "        piv_conc = pd.DataFrame(columns=pivot.columns)\n",
    "    piv_conc = pd.concat((piv_conc, pivot))\n",
    "piv_conc.to_excel(os.path.join(FIGURES, 'Final', data_type, \"Sessions Table \" + metric + '.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Step 4.3 Table Summary Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_metric = 'Avg. Precision'\n",
    "metric = 'Individual ' + current_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save concatenated pivot to excel\n",
    "DATA = '/Users/nico/PycharmProjects/FederatedLearning/Results/Final/Sessions'\n",
    "plt.rcParams.update({'font.size': 12, \n",
    "                     'font.family' : 'arial', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 16})\n",
    "\n",
    "# Draw Aggregate Table\n",
    "columns = ['Shard', 'Epoch', 'Loss', 'Person', 'Session', 'Individual Avg. Precision', 'Individual Accuracy', \n",
    "            'Individual Precision', 'Individual Recall', 'Individual F1-Score']\n",
    "\n",
    "files = [folder for folder in final_results_folders if 'Baseline' not in folder]\n",
    "pivot_concat = None\n",
    "df_concat = None\n",
    "for file in sorted(files):\n",
    "    f_path = os.path.join(DATA, file)\n",
    "    df_concat = pd.read_csv(f_path, index_col=0)\n",
    "    df_concat = df_concat[columns]\n",
    "    df_concat = df_concat[df_concat['Epoch'] == df_concat['Epoch'].max()]\n",
    "    for person, df_person in df_concat.groupby('Person'):\n",
    "        pivot = df_person.pivot(index=\"Shard\", columns=\"Session\", values=metric)\n",
    "        pivot['Test Subject'] = person\n",
    "        if pivot_concat is None:\n",
    "            pivot_concat = pd.DataFrame(columns=[0,1,2,3,4,5,6,7,8,9, 'Test Subject'])\n",
    "        pivot_concat = pd.concat((pivot_concat, pivot), sort=False)\n",
    "    \n",
    "# Add Baseline\n",
    "# baseline_folders = sorted([folder for folder in final_results_folders if 'Baseline' in folder])\n",
    "# pivot_baseline = None\n",
    "# for idx, folder in enumerate(baseline_folders):\n",
    "#     for file in os.listdir(folder):\n",
    "#         if os.path.splitext(file)[1] == '.csv':\n",
    "#             f_path = os.path.join(folder, file)\n",
    "#             df = pd.read_csv(f_path, index_col=0)\n",
    "#             for person, df_person in df.groupby('Person'):\n",
    "#                 pivot = df_person.pivot(index=\"Shard\", columns=\"Session\", values=metric)\n",
    "#                 pivot['Test Subject'] = person\n",
    "#                 if pivot_baseline is None:\n",
    "#                     pivot_baseline = pd.DataFrame(columns=[0,1,2,3,4,5,6,7,8,9, 'Test Subject'])\n",
    "#                 pivot_baseline = pd.concat((pivot_baseline, pivot), sort=False)\n",
    "# pivot_concat = pd.concat((pivot_concat, pivot_baseline), sort=False)\n",
    "    pivot_concat.to_excel(os.path.join(FIGURES, 'Final', data_type, \"Feeder Table\", \"Sessions Table \" + metric + ' TEST.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.4: Session Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nico/PycharmProjects/FederatedLearning/Results/Final/Sessions/group_2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(DATA, 'group_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty data passed with indices specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/FederatedLearning/venv/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 blocks = [make_block(values=blocks[0],\n\u001b[0;32m-> 1651\u001b[0;31m                                      placement=slice(0, len(axes[0])))]\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/FederatedLearning/venv/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   3094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3095\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/FederatedLearning/venv/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;34m'Wrong number of items passed {val}, placement implies '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 7",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-547c3e44baef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Person'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Session'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Culture'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trans_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trans_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Person'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Session'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Culture'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Person'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Session'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Culture'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/FederatedLearning/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 424\u001b[0;31m                                    copy=copy)\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/FederatedLearning/venv/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/FederatedLearning/venv/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/FederatedLearning/venv/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m   1691\u001b[0m         passed, implied))\n",
      "\u001b[0;31mValueError\u001b[0m: Empty data passed with indices specified."
     ]
    }
   ],
   "source": [
    "group_2 = DL.get_image_paths(os.path.join(DATA, 'group_2'))\n",
    "labels = np.array(DL.get_labels(group_2))\n",
    "columns = ['Person', 'Session', 'Culture', 'Frame', 'Pain', 'Trans_1', 'Trans_2']\n",
    "df = pd.DataFrame(labels, columns=columns)\n",
    "df[['Person', 'Session', 'Culture', 'Frame', 'Pain']] = df[['Person', 'Session', 'Culture', 'Frame', 'Pain']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot(df, index, columns, values):\n",
    "    pivot = ~df[['Person', 'Session']].drop_duplicates().pivot(index=index, columns=columns, values=values).isnull() * 1\n",
    "    pivot['# of ' + columns + 's'] = pivot.sum(1)\n",
    "    pivot = pivot.sort_values('# of ' + columns + 's', ascending=False)\n",
    "    \n",
    "    pivot['Pain'] = 0\n",
    "    pivot['No Pain'] = 0\n",
    "    for person, df_person in df.groupby(index):\n",
    "        pivot.at[person, 'No Pain'] = sum(df_person['Pain'] == 0)\n",
    "        pivot.at[person, 'Pain'] = sum(df_person['Pain'] > 0)\n",
    "        for col in pivot.columns:\n",
    "            if type(col) is int:\n",
    "                pivot.at[person, col] = sum(df_person[df_person[columns] == col]['Pain'] > 0)\n",
    "                \n",
    "    if columns is 'Session':\n",
    "        for col in reversed(pivot.columns):\n",
    "            if type(col) is int:\n",
    "                pivot.rename(columns={col:col+1}, inplace=True)\n",
    "    if index is 'Session':\n",
    "        for idx in reversed(pivot.index):\n",
    "            pivot.rename(index={idx:idx+1}, inplace=True)\n",
    "    pivot = pivot.append(pivot.sum(0).rename(\"Total\"))\n",
    "    pivot['Pain %'] = round(pivot['Pain'] / (pivot['Pain'] + pivot['No Pain']), 2)\n",
    "    pivot[pivot == 0] = ''\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_2 = DL.get_image_paths(os.path.join(DATA, 'group_2'))\n",
    "labels = np.array(DL.get_labels(group_2))\n",
    "columns = ['Person', 'Session', 'Culture', 'Frame', 'Pain', 'Trans_1', 'Trans_2']\n",
    "df = pd.DataFrame(labels, columns=columns)\n",
    "df[['Person', 'Session', 'Culture', 'Frame', 'Pain']] = df[['Person', 'Session', 'Culture', 'Frame', 'Pain']].astype(int)\n",
    "\n",
    "index='Person'\n",
    "columns='Session'\n",
    "values=columns\n",
    "pivot = create_pivot(df, index, columns, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index='Session'\n",
    "columns='Person'\n",
    "values=columns\n",
    "create_pivot(index, columns, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_folders = [folder for folder in final_results_folders if criteria in folder and date in folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = None\n",
    "\n",
    "folder = final_results_folders[3]\n",
    "for file in os.listdir(folder):\n",
    "    if \"shard-0.00\" not in file:\n",
    "        f_path = os.path.join(folder, file)\n",
    "        df = pd.read_csv(f_path)\n",
    "        df['Shard'] = float(file.split('_shard-')[1].split('_')[0])\n",
    "        if df_concat is None:\n",
    "            df_concat = pd.DataFrame(columns=df.columns)\n",
    "        df_concat = pd.concat((df_concat, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session = None\n",
    "for sess, df in df_concat.groupby('Session'):\n",
    "    df_this = pd.DataFrame(columns=df.columns, data=df.values)\n",
    "    tn_g = df_this.groupby('Epoch')['TN'].transform(sum)\n",
    "    fp_g = df_this.groupby('Epoch')['FP'].transform(sum)\n",
    "    fn_g = df_this.groupby('Epoch')['FN'].transform(sum)\n",
    "    tp_g = df_this.groupby('Epoch')['TP'].transform(sum)\n",
    "    df_this['Aggregate Accuracy'] = (tp_g + tn_g) / (tn_g + fp_g + fn_g + tp_g)\n",
    "    df_this['Aggregate Precision'] = tp_g / (fp_g + tp_g)\n",
    "    df_this['Aggregate Recall'] = tp_g / (fn_g + tp_g)\n",
    "    df_this['Aggregate F1_Score'] = 2 * ((df_this['Aggregate Precision'] * df_this['Aggregate Recall']) / (\n",
    "            df_this['Aggregate Precision'] + df_this['Aggregate Recall']))\n",
    "    if df_session is None:\n",
    "        df_session = pd.DataFrame(columns=df_this.columns)\n",
    "    df_session = pd.concat((df_session, df_this), ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FederatedLearning",
   "language": "python",
   "name": "federatedlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
