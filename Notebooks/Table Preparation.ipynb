{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from Scripts import Data_Loader_Functions as dL\n",
    "from Scripts import Results_Evaluation as rE\n",
    "RESULTS = os.path.join(module_path, 'Results', 'Thesis')\n",
    "DATA = os.path.join(module_path, 'Data', 'Augmented Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = dL.create_pivot(os.path.join(DATA, 'group_2'), 'Session', 'Person', 'Session')\n",
    "subjects = dL.create_pain_df(os.path.join(DATA, 'group_2'))['Person'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric & Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'accuracy'\n",
    "view_by = 'person'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-random</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6-sessions-Federated-no-pre-training-personalization</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-sessions-Federated-central-pre-training-personalization</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8-sessions-Federated-federated-pre-training-personalization</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-sessions-Federated-no-pre-training-local-models</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-sessions-Federated-central-pre-training-local-models</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-sessions-Federated-federated-pre-training-local-models</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     43   48    52   59   64  \\\n",
       "Experiment                                                                     \n",
       "0-sessions-Baseline-central-pre-training           0.69 0.78  0.92 0.53 0.91   \n",
       "0-sessions-Baseline-federated-pre-training         0.66 0.67   0.9 0.74 0.89   \n",
       "0-sessions-Baseline-random                         0.34 0.21 0.075 0.36 0.11   \n",
       "1-sessions-Centralized-no-pre-training             0.79 0.79  0.78 0.64 0.91   \n",
       "2-sessions-Centralized-pre-training                0.76 0.78   0.8 0.53  0.9   \n",
       "3-sessions-Federated-no-pre-training               0.71 0.79   0.9 0.64  0.9   \n",
       "4-sessions-Federated-central-pre-training          0.74 0.78  0.92 0.53 0.91   \n",
       "5-sessions-Federated-federated-pre-training        0.71 0.74  0.89 0.74 0.91   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 0.71 0.79  0.92 0.64  0.9   \n",
       "7-sessions-Federated-central-pre-training-perso... 0.82 0.78  0.88 0.53 0.92   \n",
       "8-sessions-Federated-federated-pre-training-per... 0.75 0.74  0.89 0.74 0.91   \n",
       "9-sessions-Federated-no-pre-training-local-models  0.68 0.79  0.92 0.64  0.9   \n",
       "10-sessions-Federated-central-pre-training-loca... 0.83 0.78  0.86 0.53 0.93   \n",
       "11-sessions-Federated-federated-pre-training-lo... 0.73 0.74  0.88 0.74 0.91   \n",
       "\n",
       "                                                     80   92   96  107  109  \\\n",
       "Experiment                                                                    \n",
       "0-sessions-Baseline-central-pre-training            0.6 0.67 0.79 0.64  0.8   \n",
       "0-sessions-Baseline-federated-pre-training         0.59  0.6 0.79 0.61 0.72   \n",
       "0-sessions-Baseline-random                         0.49 0.62 0.22 0.45 0.28   \n",
       "1-sessions-Centralized-no-pre-training             0.59 0.38 0.83 0.57 0.72   \n",
       "2-sessions-Centralized-pre-training                 0.6 0.71 0.84 0.72 0.79   \n",
       "3-sessions-Federated-no-pre-training               0.56 0.44 0.71 0.62 0.44   \n",
       "4-sessions-Federated-central-pre-training          0.62 0.75 0.82 0.68 0.76   \n",
       "5-sessions-Federated-federated-pre-training        0.64 0.67 0.81 0.73 0.71   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 0.57 0.38 0.78  0.6 0.72   \n",
       "7-sessions-Federated-central-pre-training-perso... 0.63 0.77 0.84 0.68 0.79   \n",
       "8-sessions-Federated-federated-pre-training-per... 0.63 0.59 0.83 0.66 0.72   \n",
       "9-sessions-Federated-no-pre-training-local-models  0.56 0.38 0.76 0.62 0.72   \n",
       "10-sessions-Federated-central-pre-training-loca... 0.63 0.65 0.85 0.69  0.8   \n",
       "11-sessions-Federated-federated-pre-training-lo... 0.62 0.59 0.82 0.66 0.72   \n",
       "\n",
       "                                                    115  120  Weighted Mean  \\\n",
       "Experiment                                                                    \n",
       "0-sessions-Baseline-central-pre-training           0.66 0.76           0.73   \n",
       "0-sessions-Baseline-federated-pre-training         0.89 0.74           0.74   \n",
       "0-sessions-Baseline-random                         0.12 0.35            0.3   \n",
       "1-sessions-Centralized-no-pre-training             0.85 0.55            0.7   \n",
       "2-sessions-Centralized-pre-training                0.85 0.66           0.75   \n",
       "3-sessions-Federated-no-pre-training               0.81 0.49           0.68   \n",
       "4-sessions-Federated-central-pre-training          0.73 0.63           0.75   \n",
       "5-sessions-Federated-federated-pre-training        0.88 0.64           0.77   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 0.88 0.65           0.72   \n",
       "7-sessions-Federated-central-pre-training-perso...  0.9 0.71           0.77   \n",
       "8-sessions-Federated-federated-pre-training-per...  0.9 0.68           0.76   \n",
       "9-sessions-Federated-no-pre-training-local-models  0.88 0.65           0.72   \n",
       "10-sessions-Federated-central-pre-training-loca... 0.89  0.7           0.76   \n",
       "11-sessions-Federated-federated-pre-training-lo... 0.89 0.67           0.75   \n",
       "\n",
       "                                                    Weighted SD  Mean    SD  \n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training                   0.12  0.73  0.12  \n",
       "0-sessions-Baseline-federated-pre-training                 0.13  0.73  0.11  \n",
       "0-sessions-Baseline-random                                 0.15   0.3  0.17  \n",
       "1-sessions-Centralized-no-pre-training                     0.16   0.7  0.16  \n",
       "2-sessions-Centralized-pre-training                        0.14  0.75  0.11  \n",
       "3-sessions-Federated-no-pre-training                       0.14  0.67  0.16  \n",
       "4-sessions-Federated-central-pre-training                  0.12  0.74  0.11  \n",
       "5-sessions-Federated-federated-pre-training                0.12  0.76 0.094  \n",
       "6-sessions-Federated-no-pre-training-personaliz...         0.16  0.71  0.16  \n",
       "7-sessions-Federated-central-pre-training-perso...         0.12  0.77  0.12  \n",
       "8-sessions-Federated-federated-pre-training-per...         0.14  0.75  0.11  \n",
       "9-sessions-Federated-no-pre-training-local-models          0.15  0.71  0.16  \n",
       "10-sessions-Federated-central-pre-training-loca...         0.13  0.76  0.12  \n",
       "11-sessions-Federated-federated-pre-training-lo...         0.14  0.75  0.11  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, 'Original', '123 - Seed 123')\n",
    "results['Base'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(module_path, \"CDL.csv\"))\n",
    "df['label'] = np.minimum(df['True Label'], 1)\n",
    "df['prediction'] = df['CDL'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TP'] = (df['label'] == 1) & (df['prediction'] == 1)\n",
    "df['TN'] = (df['label'] == 0) & (df['prediction'] == 0)\n",
    "df['FP'] = (df['label'] == 0) & (df['prediction'] == 1)\n",
    "df['FN'] = (df['label'] == 1) & (df['prediction'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  0\n",
      "TN:  96\n",
      "FP:  3\n",
      "FN:  0\n"
     ]
    }
   ],
   "source": [
    "df_filter = df[(df['Seed'] == 123) & (df['Subject ID'] == 43) & (df['Session'] == 8)]\n",
    "print(\"TP: \", df_filter['TP'].sum())\n",
    "print(\"TN: \", df_filter['TN'].sum())\n",
    "print(\"FP: \", df_filter['FP'].sum())\n",
    "print(\"FN: \", df_filter['FN'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv(os.path.join(module_path, 'Results/Thesis/NEW/123 - Seed 123 - Sessions NEW/2020-01-26-010842_PAIN_0-sessions-centralized-pre-training_TEST.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session</th>\n",
       "      <th>subject_43_true_positives</th>\n",
       "      <th>subject_43_true_negatives</th>\n",
       "      <th>subject_43_false_positives</th>\n",
       "      <th>subject_43_false_negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>644.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>651.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>456.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.00</td>\n",
       "      <td>440.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>215.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>397.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>477.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>279.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>374.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Session  subject_43_true_positives  subject_43_true_negatives  \\\n",
       "0        1                       0.00                     644.00   \n",
       "1        2                       0.00                     651.00   \n",
       "2        3                       0.00                     456.00   \n",
       "3        4                      13.00                     440.00   \n",
       "4        5                       0.00                     397.00   \n",
       "5        6                       0.00                     477.00   \n",
       "6        7                       0.00                     279.00   \n",
       "7        8                       0.00                     374.00   \n",
       "8        9                        nan                        nan   \n",
       "\n",
       "   subject_43_false_positives  subject_43_false_negatives  \n",
       "0                        0.00                        0.00  \n",
       "1                        1.00                        0.00  \n",
       "2                       20.00                        0.00  \n",
       "3                        0.00                      215.00  \n",
       "4                        3.00                        0.00  \n",
       "5                       19.00                        0.00  \n",
       "6                       57.00                        0.00  \n",
       "7                       22.00                        0.00  \n",
       "8                         nan                         nan  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res[['Session', \n",
    "        'subject_43_true_positives', \n",
    "        'subject_43_true_negatives',\n",
    "       'subject_43_false_positives',\n",
    "       'subject_43_false_negatives']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-centralized-pre-training</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-sessions-Federated-central-pre-training-personalization</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-sessions-Federated-central-pre-training-local-models</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     43   48   52   59   64  \\\n",
       "Experiment                                                                    \n",
       "0-sessions-centralized-pre-training                0.74 0.79  0.9 0.56 0.92   \n",
       "2-sessions-Centralized-pre-training                0.79 0.78 0.79 0.56 0.93   \n",
       "4-sessions-Federated-central-pre-training           0.7 0.78 0.91 0.56 0.93   \n",
       "7-sessions-Federated-central-pre-training-perso... 0.81 0.78 0.87 0.56 0.92   \n",
       "10-sessions-Federated-central-pre-training-loca... 0.81 0.78 0.87 0.56 0.92   \n",
       "\n",
       "                                                     80   92   96  107  109  \\\n",
       "Experiment                                                                    \n",
       "0-sessions-centralized-pre-training                0.55 0.71 0.79 0.63 0.74   \n",
       "2-sessions-Centralized-pre-training                 0.6 0.66 0.84 0.71 0.74   \n",
       "4-sessions-Federated-central-pre-training          0.61  0.7 0.83 0.69 0.68   \n",
       "7-sessions-Federated-central-pre-training-perso... 0.62 0.68 0.83 0.67 0.74   \n",
       "10-sessions-Federated-central-pre-training-loca... 0.61 0.62 0.83 0.66 0.74   \n",
       "\n",
       "                                                    115  120  Weighted Mean  \\\n",
       "Experiment                                                                    \n",
       "0-sessions-centralized-pre-training                0.72 0.65           0.72   \n",
       "2-sessions-Centralized-pre-training                0.83 0.66           0.74   \n",
       "4-sessions-Federated-central-pre-training          0.78 0.61           0.75   \n",
       "7-sessions-Federated-central-pre-training-perso...  0.9 0.73           0.76   \n",
       "10-sessions-Federated-central-pre-training-loca...  0.9 0.71           0.75   \n",
       "\n",
       "                                                    Weighted SD  Mean   SD  \n",
       "Experiment                                                                  \n",
       "0-sessions-centralized-pre-training                        0.12  0.72 0.12  \n",
       "2-sessions-Centralized-pre-training                        0.13  0.74 0.11  \n",
       "4-sessions-Federated-central-pre-training                  0.11  0.73 0.12  \n",
       "7-sessions-Federated-central-pre-training-perso...         0.13  0.76 0.11  \n",
       "10-sessions-Federated-central-pre-training-loca...         0.14  0.75 0.12  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, 'NEW', '132 - Seed 132 - Sessions NEW')\n",
    "results['Base'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>66.0%</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>92.3%</td>\n",
       "      <td>54.7%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>48.4%</td>\n",
       "      <td>63.3%</td>\n",
       "      <td>77.9%</td>\n",
       "      <td>59.9%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>80.4%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>69.5%</td>\n",
       "      <td>12.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.3%</td>\n",
       "      <td>79.6%</td>\n",
       "      <td>90.9%</td>\n",
       "      <td>68.4%</td>\n",
       "      <td>66.3%</td>\n",
       "      <td>49.0%</td>\n",
       "      <td>59.2%</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>83.3%</td>\n",
       "      <td>58.5%</td>\n",
       "      <td>69.6%</td>\n",
       "      <td>15.6%</td>\n",
       "      <td>70.1%</td>\n",
       "      <td>12.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>69.2%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>89.1%</td>\n",
       "      <td>58.3%</td>\n",
       "      <td>37.9%</td>\n",
       "      <td>86.5%</td>\n",
       "      <td>61.1%</td>\n",
       "      <td>72.3%</td>\n",
       "      <td>91.0%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>72.7%</td>\n",
       "      <td>14.8%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>15.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>76.0%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>87.3%</td>\n",
       "      <td>54.7%</td>\n",
       "      <td>67.5%</td>\n",
       "      <td>63.2%</td>\n",
       "      <td>50.5%</td>\n",
       "      <td>83.5%</td>\n",
       "      <td>70.8%</td>\n",
       "      <td>76.3%</td>\n",
       "      <td>88.4%</td>\n",
       "      <td>68.3%</td>\n",
       "      <td>72.7%</td>\n",
       "      <td>15.4%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>12.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>74.3%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>88.2%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>91.0%</td>\n",
       "      <td>54.2%</td>\n",
       "      <td>37.9%</td>\n",
       "      <td>83.7%</td>\n",
       "      <td>55.6%</td>\n",
       "      <td>38.4%</td>\n",
       "      <td>76.7%</td>\n",
       "      <td>47.8%</td>\n",
       "      <td>67.1%</td>\n",
       "      <td>14.2%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>18.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>77.7%</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>88.4%</td>\n",
       "      <td>54.7%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>60.3%</td>\n",
       "      <td>66.3%</td>\n",
       "      <td>83.3%</td>\n",
       "      <td>59.1%</td>\n",
       "      <td>70.6%</td>\n",
       "      <td>83.4%</td>\n",
       "      <td>64.4%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>16.4%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>10.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>76.9%</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>85.4%</td>\n",
       "      <td>68.4%</td>\n",
       "      <td>70.5%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>50.8%</td>\n",
       "      <td>87.4%</td>\n",
       "      <td>59.2%</td>\n",
       "      <td>65.4%</td>\n",
       "      <td>82.8%</td>\n",
       "      <td>63.0%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>15.9%</td>\n",
       "      <td>70.4%</td>\n",
       "      <td>12.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    66.0% 78.9% 92.3% 54.7% 67.3%   \n",
       "0-sessions-Baseline-federated-pre-training  66.3% 79.6% 90.9% 68.4% 66.3%   \n",
       "1-sessions-Centralized-no-pre-training      69.2% 79.1% 88.0% 63.9% 89.1%   \n",
       "2-sessions-Centralized-pre-training         76.0% 78.8% 87.3% 54.7% 67.5%   \n",
       "3-sessions-Federated-no-pre-training        74.3% 79.1% 88.2% 63.9% 91.0%   \n",
       "4-sessions-Federated-central-pre-training   77.7% 78.9% 88.4% 54.7% 68.5%   \n",
       "5-sessions-Federated-federated-pre-training 76.9% 79.4% 85.4% 68.4% 70.5%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    48.4% 63.3% 77.9% 59.9% 75.7%   \n",
       "0-sessions-Baseline-federated-pre-training  49.0% 59.2% 85.2% 62.2% 71.9%   \n",
       "1-sessions-Centralized-no-pre-training      58.3% 37.9% 86.5% 61.1% 72.3%   \n",
       "2-sessions-Centralized-pre-training         63.2% 50.5% 83.5% 70.8% 76.3%   \n",
       "3-sessions-Federated-no-pre-training        54.2% 37.9% 83.7% 55.6% 38.4%   \n",
       "4-sessions-Federated-central-pre-training   60.3% 66.3% 83.3% 59.1% 70.6%   \n",
       "5-sessions-Federated-federated-pre-training 56.0% 50.8% 87.4% 59.2% 65.4%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    80.4% 68.5%          68.7%   \n",
       "0-sessions-Baseline-federated-pre-training  83.3% 58.5%          69.6%   \n",
       "1-sessions-Centralized-no-pre-training      91.0% 73.9%          72.7%   \n",
       "2-sessions-Centralized-pre-training         88.4% 68.3%          72.7%   \n",
       "3-sessions-Federated-no-pre-training        76.7% 47.8%          67.1%   \n",
       "4-sessions-Federated-central-pre-training   83.4% 64.4%          71.3%   \n",
       "5-sessions-Federated-federated-pre-training 82.8% 63.0%          69.7%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           15.8% 69.5% 12.2%  \n",
       "0-sessions-Baseline-federated-pre-training         15.6% 70.1% 12.5%  \n",
       "1-sessions-Centralized-no-pre-training             14.8% 72.5% 15.7%  \n",
       "2-sessions-Centralized-pre-training                15.4% 72.1% 12.0%  \n",
       "3-sessions-Federated-no-pre-training               14.2% 65.9% 18.9%  \n",
       "4-sessions-Federated-central-pre-training          16.4% 71.3% 10.9%  \n",
       "5-sessions-Federated-federated-pre-training        15.9% 70.4% 12.0%  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '1 - CNN - Base')\n",
    "results['Base'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Base']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude Pain Level \"0\" from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>70.7%</td>\n",
       "      <td>77.2%</td>\n",
       "      <td>90.7%</td>\n",
       "      <td>56.7%</td>\n",
       "      <td>52.6%</td>\n",
       "      <td>48.4%</td>\n",
       "      <td>68.6%</td>\n",
       "      <td>81.0%</td>\n",
       "      <td>63.2%</td>\n",
       "      <td>84.8%</td>\n",
       "      <td>58.7%</td>\n",
       "      <td>64.6%</td>\n",
       "      <td>66.9%</td>\n",
       "      <td>13.0%</td>\n",
       "      <td>68.1%</td>\n",
       "      <td>13.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>79.7%</td>\n",
       "      <td>91.4%</td>\n",
       "      <td>67.9%</td>\n",
       "      <td>72.2%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>42.5%</td>\n",
       "      <td>80.3%</td>\n",
       "      <td>56.3%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>69.6%</td>\n",
       "      <td>13.9%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>14.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>67.5%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>88.1%</td>\n",
       "      <td>54.5%</td>\n",
       "      <td>37.9%</td>\n",
       "      <td>81.5%</td>\n",
       "      <td>58.2%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>90.6%</td>\n",
       "      <td>63.1%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>14.9%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>16.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>69.2%</td>\n",
       "      <td>77.4%</td>\n",
       "      <td>91.2%</td>\n",
       "      <td>56.7%</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>59.2%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>85.6%</td>\n",
       "      <td>65.4%</td>\n",
       "      <td>84.8%</td>\n",
       "      <td>91.3%</td>\n",
       "      <td>67.8%</td>\n",
       "      <td>72.9%</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>12.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>79.9%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>82.2%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>56.7%</td>\n",
       "      <td>53.9%</td>\n",
       "      <td>81.9%</td>\n",
       "      <td>55.5%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>76.9%</td>\n",
       "      <td>44.4%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>14.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>73.4%</td>\n",
       "      <td>77.5%</td>\n",
       "      <td>88.2%</td>\n",
       "      <td>56.7%</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>76.6%</td>\n",
       "      <td>84.6%</td>\n",
       "      <td>57.3%</td>\n",
       "      <td>85.6%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>61.3%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>16.9%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>11.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>77.7%</td>\n",
       "      <td>79.7%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>67.9%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>58.7%</td>\n",
       "      <td>45.8%</td>\n",
       "      <td>86.4%</td>\n",
       "      <td>55.7%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>49.6%</td>\n",
       "      <td>68.4%</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>68.6%</td>\n",
       "      <td>13.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    70.7% 77.2% 90.7% 56.7% 52.6%   \n",
       "0-sessions-Baseline-federated-pre-training  65.9% 79.7% 91.4% 67.9% 72.2%   \n",
       "1-sessions-Centralized-no-pre-training      67.5% 79.3% 91.9% 63.9% 88.1%   \n",
       "2-sessions-Centralized-pre-training         69.2% 77.4% 91.2% 56.7% 62.0%   \n",
       "3-sessions-Federated-no-pre-training        79.9% 79.1% 82.2% 63.9% 90.5%   \n",
       "4-sessions-Federated-central-pre-training   73.4% 77.5% 88.2% 56.7% 62.0%   \n",
       "5-sessions-Federated-federated-pre-training 77.7% 79.7% 75.7% 67.9% 74.9%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    48.4% 68.6% 81.0% 63.2% 84.8%   \n",
       "0-sessions-Baseline-federated-pre-training  53.5% 42.5% 80.3% 56.3% 71.9%   \n",
       "1-sessions-Centralized-no-pre-training      54.5% 37.9% 81.5% 58.2% 72.0%   \n",
       "2-sessions-Centralized-pre-training         59.2% 60.0% 85.6% 65.4% 84.8%   \n",
       "3-sessions-Federated-no-pre-training        56.7% 53.9% 81.9% 55.5% 71.9%   \n",
       "4-sessions-Federated-central-pre-training   62.2% 76.6% 84.6% 57.3% 85.6%   \n",
       "5-sessions-Federated-federated-pre-training 58.7% 45.8% 86.4% 55.7% 71.9%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    58.7% 64.6%          66.9%   \n",
       "0-sessions-Baseline-federated-pre-training  88.7% 78.0%          69.6%   \n",
       "1-sessions-Centralized-no-pre-training      90.6% 63.1%          71.3%   \n",
       "2-sessions-Centralized-pre-training         91.3% 67.8%          72.9%   \n",
       "3-sessions-Federated-no-pre-training        76.9% 44.4%          70.2%   \n",
       "4-sessions-Federated-central-pre-training   78.1% 61.3%          72.1%   \n",
       "5-sessions-Federated-federated-pre-training 78.8% 49.6%          68.4%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           13.0% 68.1% 13.2%  \n",
       "0-sessions-Baseline-federated-pre-training         13.9% 70.7% 14.5%  \n",
       "1-sessions-Centralized-no-pre-training             14.9% 70.7% 16.4%  \n",
       "2-sessions-Centralized-pre-training                16.3% 72.5% 12.9%  \n",
       "3-sessions-Federated-no-pre-training               16.7% 69.7% 14.4%  \n",
       "4-sessions-Federated-central-pre-training          16.9% 71.9% 11.5%  \n",
       "5-sessions-Federated-federated-pre-training        16.7% 68.6% 13.0%  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '2 - CNN - Pain Gap')\n",
    "results['Pain Level 0'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Pain Level 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RMSProp as an optimizer instead of SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>68.1%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>80.9%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>59.0%</td>\n",
       "      <td>81.6%</td>\n",
       "      <td>62.4%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>92.1%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>69.9%</td>\n",
       "      <td>15.0%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>10.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>67.8%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>61.4%</td>\n",
       "      <td>60.1%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>54.9%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>88.5%</td>\n",
       "      <td>67.6%</td>\n",
       "      <td>73.3%</td>\n",
       "      <td>15.9%</td>\n",
       "      <td>72.6%</td>\n",
       "      <td>12.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>82.0%</td>\n",
       "      <td>79.2%</td>\n",
       "      <td>87.3%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>88.5%</td>\n",
       "      <td>59.3%</td>\n",
       "      <td>39.1%</td>\n",
       "      <td>77.0%</td>\n",
       "      <td>68.2%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>91.1%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>15.5%</td>\n",
       "      <td>73.3%</td>\n",
       "      <td>14.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>82.8%</td>\n",
       "      <td>74.5%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>61.4%</td>\n",
       "      <td>56.1%</td>\n",
       "      <td>81.9%</td>\n",
       "      <td>70.1%</td>\n",
       "      <td>75.2%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>74.8%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>9.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>66.5%</td>\n",
       "      <td>79.2%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>90.9%</td>\n",
       "      <td>51.4%</td>\n",
       "      <td>37.1%</td>\n",
       "      <td>72.2%</td>\n",
       "      <td>60.1%</td>\n",
       "      <td>45.1%</td>\n",
       "      <td>66.4%</td>\n",
       "      <td>43.5%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>15.7%</td>\n",
       "      <td>64.0%</td>\n",
       "      <td>17.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>80.7%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>88.4%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>81.7%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>51.2%</td>\n",
       "      <td>84.5%</td>\n",
       "      <td>61.5%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>77.4%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>15.1%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>11.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>72.8%</td>\n",
       "      <td>73.6%</td>\n",
       "      <td>90.9%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>56.3%</td>\n",
       "      <td>58.8%</td>\n",
       "      <td>82.7%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>76.6%</td>\n",
       "      <td>54.3%</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>16.1%</td>\n",
       "      <td>70.9%</td>\n",
       "      <td>13.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    68.1% 74.6% 69.7% 66.0% 80.9%   \n",
       "0-sessions-Baseline-federated-pre-training  67.8% 73.8% 91.7% 65.8% 88.7%   \n",
       "1-sessions-Centralized-no-pre-training      82.0% 79.2% 87.3% 63.9% 88.5%   \n",
       "2-sessions-Centralized-pre-training         82.8% 74.5% 74.4% 66.0% 78.9%   \n",
       "3-sessions-Federated-no-pre-training        66.5% 79.2% 91.9% 63.9% 90.9%   \n",
       "4-sessions-Federated-central-pre-training   80.7% 74.6% 88.4% 66.0% 81.7%   \n",
       "5-sessions-Federated-federated-pre-training 72.8% 73.6% 90.9% 65.8% 90.5%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    55.3% 59.0% 81.6% 62.4% 74.6%   \n",
       "0-sessions-Baseline-federated-pre-training  61.4% 60.1% 79.1% 54.9% 71.9%   \n",
       "1-sessions-Centralized-no-pre-training      59.3% 39.1% 77.0% 68.2% 72.8%   \n",
       "2-sessions-Centralized-pre-training         61.4% 56.1% 81.9% 70.1% 75.2%   \n",
       "3-sessions-Federated-no-pre-training        51.4% 37.1% 72.2% 60.1% 45.1%   \n",
       "4-sessions-Federated-central-pre-training   65.9% 51.2% 84.5% 61.5% 74.6%   \n",
       "5-sessions-Federated-federated-pre-training 56.3% 58.8% 82.7% 56.0% 72.0%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    92.1% 73.7%          69.9%   \n",
       "0-sessions-Baseline-federated-pre-training  88.5% 67.6%          73.3%   \n",
       "1-sessions-Centralized-no-pre-training      91.1% 71.5%          73.0%   \n",
       "2-sessions-Centralized-pre-training         89.3% 74.8%          72.4%   \n",
       "3-sessions-Federated-no-pre-training        66.4% 43.5%          65.9%   \n",
       "4-sessions-Federated-central-pre-training   89.3% 77.4%          74.4%   \n",
       "5-sessions-Federated-federated-pre-training 76.6% 54.3%          71.7%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           15.0% 71.5% 10.4%  \n",
       "0-sessions-Baseline-federated-pre-training         15.9% 72.6% 12.1%  \n",
       "1-sessions-Centralized-no-pre-training             15.5% 73.3% 14.6%  \n",
       "2-sessions-Centralized-pre-training                15.3% 73.8%  9.3%  \n",
       "3-sessions-Federated-no-pre-training               15.7% 64.0% 17.8%  \n",
       "4-sessions-Federated-central-pre-training          15.1% 74.7% 11.5%  \n",
       "5-sessions-Federated-federated-pre-training        16.1% 70.9% 13.0%  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '3 - CNN - RMS Prop')\n",
    "results['RMSProp'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['RMSProp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>54.6%</td>\n",
       "      <td>92.5%</td>\n",
       "      <td>36.1%</td>\n",
       "      <td>57.0%</td>\n",
       "      <td>52.8%</td>\n",
       "      <td>64.3%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>54.8%</td>\n",
       "      <td>69.5%</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>66.1%</td>\n",
       "      <td>20.7%</td>\n",
       "      <td>64.9%</td>\n",
       "      <td>15.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>50.1%</td>\n",
       "      <td>92.5%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>89.0%</td>\n",
       "      <td>58.3%</td>\n",
       "      <td>37.9%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>54.8%</td>\n",
       "      <td>37.8%</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>14.5%</td>\n",
       "      <td>65.1%</td>\n",
       "      <td>18.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>37.4%</td>\n",
       "      <td>20.7%</td>\n",
       "      <td>13.7%</td>\n",
       "      <td>36.1%</td>\n",
       "      <td>52.2%</td>\n",
       "      <td>52.7%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>31.3%</td>\n",
       "      <td>55.2%</td>\n",
       "      <td>28.1%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>43.7%</td>\n",
       "      <td>20.1%</td>\n",
       "      <td>44.2%</td>\n",
       "      <td>19.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>34.3%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>7.5%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>76.6%</td>\n",
       "      <td>40.7%</td>\n",
       "      <td>35.7%</td>\n",
       "      <td>22.4%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>63.3%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>46.8%</td>\n",
       "      <td>19.2%</td>\n",
       "      <td>51.4%</td>\n",
       "      <td>22.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             43    48    52    59    64    80  \\\n",
       "Experiment                                                                      \n",
       "1-sessions-Centralized-no-pre-training    65.9% 54.6% 92.5% 36.1% 57.0% 52.8%   \n",
       "2-sessions-Centralized-pre-training       65.9% 50.1% 92.5% 63.9% 89.0% 58.3%   \n",
       "3-sessions-Federated-no-pre-training      37.4% 20.7% 13.7% 36.1% 52.2% 52.7%   \n",
       "4-sessions-Federated-central-pre-training 34.3% 79.3%  7.5% 63.9% 76.6% 40.7%   \n",
       "\n",
       "                                             92    96   107   109   115   120  \\\n",
       "Experiment                                                                      \n",
       "1-sessions-Centralized-no-pre-training    64.3% 77.7% 54.8% 69.5% 88.0% 65.2%   \n",
       "2-sessions-Centralized-pre-training       37.9% 77.7% 54.8% 37.8% 88.0% 65.2%   \n",
       "3-sessions-Federated-no-pre-training      62.2% 31.3% 55.2% 28.1% 74.9% 65.2%   \n",
       "4-sessions-Federated-central-pre-training 35.7% 22.4% 56.0% 71.9% 63.3% 65.2%   \n",
       "\n",
       "                                           Weighted Mean  Weighted SD  Mean  \\\n",
       "Experiment                                                                    \n",
       "1-sessions-Centralized-no-pre-training             66.1%        20.7% 64.9%   \n",
       "2-sessions-Centralized-pre-training                67.3%        14.5% 65.1%   \n",
       "3-sessions-Federated-no-pre-training               43.7%        20.1% 44.2%   \n",
       "4-sessions-Federated-central-pre-training          46.8%        19.2% 51.4%   \n",
       "\n",
       "                                             SD  \n",
       "Experiment                                       \n",
       "1-sessions-Centralized-no-pre-training    15.7%  \n",
       "2-sessions-Centralized-pre-training       18.7%  \n",
       "3-sessions-Federated-no-pre-training      19.0%  \n",
       "4-sessions-Federated-central-pre-training 22.9%  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '4 - ResNet - Base')\n",
    "results['ResNet'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['ResNet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN - No Max Pooling After Last Conv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>65.6%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>92.5%</td>\n",
       "      <td>46.9%</td>\n",
       "      <td>50.8%</td>\n",
       "      <td>45.6%</td>\n",
       "      <td>67.5%</td>\n",
       "      <td>78.2%</td>\n",
       "      <td>59.4%</td>\n",
       "      <td>81.9%</td>\n",
       "      <td>62.9%</td>\n",
       "      <td>75.6%</td>\n",
       "      <td>65.5%</td>\n",
       "      <td>13.8%</td>\n",
       "      <td>67.1%</td>\n",
       "      <td>14.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>79.2%</td>\n",
       "      <td>92.1%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>57.7%</td>\n",
       "      <td>52.1%</td>\n",
       "      <td>65.5%</td>\n",
       "      <td>84.9%</td>\n",
       "      <td>62.1%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>80.6%</td>\n",
       "      <td>52.0%</td>\n",
       "      <td>69.6%</td>\n",
       "      <td>12.9%</td>\n",
       "      <td>69.4%</td>\n",
       "      <td>12.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>79.5%</td>\n",
       "      <td>65.3%</td>\n",
       "      <td>85.0%</td>\n",
       "      <td>58.0%</td>\n",
       "      <td>82.2%</td>\n",
       "      <td>61.5%</td>\n",
       "      <td>49.2%</td>\n",
       "      <td>83.8%</td>\n",
       "      <td>63.4%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>90.8%</td>\n",
       "      <td>68.1%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>15.1%</td>\n",
       "      <td>71.6%</td>\n",
       "      <td>12.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>73.7%</td>\n",
       "      <td>79.2%</td>\n",
       "      <td>82.2%</td>\n",
       "      <td>46.9%</td>\n",
       "      <td>59.4%</td>\n",
       "      <td>60.4%</td>\n",
       "      <td>67.7%</td>\n",
       "      <td>84.8%</td>\n",
       "      <td>63.7%</td>\n",
       "      <td>81.9%</td>\n",
       "      <td>88.9%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>15.9%</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>12.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>74.6%</td>\n",
       "      <td>65.4%</td>\n",
       "      <td>84.0%</td>\n",
       "      <td>58.0%</td>\n",
       "      <td>77.3%</td>\n",
       "      <td>54.8%</td>\n",
       "      <td>50.7%</td>\n",
       "      <td>81.4%</td>\n",
       "      <td>56.7%</td>\n",
       "      <td>70.5%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>67.4%</td>\n",
       "      <td>14.6%</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>12.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>73.4%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>46.9%</td>\n",
       "      <td>59.1%</td>\n",
       "      <td>60.3%</td>\n",
       "      <td>64.4%</td>\n",
       "      <td>85.1%</td>\n",
       "      <td>59.9%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>82.2%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>70.4%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>70.6%</td>\n",
       "      <td>12.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>78.4%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>86.4%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>57.9%</td>\n",
       "      <td>57.2%</td>\n",
       "      <td>85.4%</td>\n",
       "      <td>60.4%</td>\n",
       "      <td>72.6%</td>\n",
       "      <td>81.1%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>70.3%</td>\n",
       "      <td>15.5%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>10.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    65.6% 78.8% 92.5% 46.9% 50.8%   \n",
       "0-sessions-Baseline-federated-pre-training  65.9% 79.2% 92.1% 69.0% 57.7%   \n",
       "1-sessions-Centralized-no-pre-training      79.5% 65.3% 85.0% 58.0% 82.2%   \n",
       "2-sessions-Centralized-pre-training         73.7% 79.2% 82.2% 46.9% 59.4%   \n",
       "3-sessions-Federated-no-pre-training        74.6% 65.4% 84.0% 58.0% 77.3%   \n",
       "4-sessions-Federated-central-pre-training   73.4% 79.0% 89.7% 46.9% 59.1%   \n",
       "5-sessions-Federated-federated-pre-training 78.4% 79.0% 86.4% 69.0% 62.0%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    45.6% 67.5% 78.2% 59.4% 81.9%   \n",
       "0-sessions-Baseline-federated-pre-training  52.1% 65.5% 84.9% 62.1% 72.1%   \n",
       "1-sessions-Centralized-no-pre-training      61.5% 49.2% 83.8% 63.4% 72.1%   \n",
       "2-sessions-Centralized-pre-training         60.4% 67.7% 84.8% 63.7% 81.9%   \n",
       "3-sessions-Federated-no-pre-training        54.8% 50.7% 81.4% 56.7% 70.5%   \n",
       "4-sessions-Federated-central-pre-training   60.3% 64.4% 85.1% 59.9% 72.8%   \n",
       "5-sessions-Federated-federated-pre-training 57.9% 57.2% 85.4% 60.4% 72.6%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    62.9% 75.6%          65.5%   \n",
       "0-sessions-Baseline-federated-pre-training  80.6% 52.0%          69.6%   \n",
       "1-sessions-Centralized-no-pre-training      90.8% 68.1%          72.1%   \n",
       "2-sessions-Centralized-pre-training         88.9% 72.0%          71.3%   \n",
       "3-sessions-Federated-no-pre-training        74.9% 50.0%          67.4%   \n",
       "4-sessions-Federated-central-pre-training   82.2% 74.3%          70.4%   \n",
       "5-sessions-Federated-federated-pre-training 81.1% 72.4%          70.3%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           13.8% 67.1% 14.8%  \n",
       "0-sessions-Baseline-federated-pre-training         12.9% 69.4% 12.8%  \n",
       "1-sessions-Centralized-no-pre-training             15.1% 71.6% 12.7%  \n",
       "2-sessions-Centralized-pre-training                15.9% 71.7% 12.5%  \n",
       "3-sessions-Federated-no-pre-training               14.6% 66.5% 12.2%  \n",
       "4-sessions-Federated-central-pre-training          15.8% 70.6% 12.6%  \n",
       "5-sessions-Federated-federated-pre-training        15.5% 71.8% 10.5%  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '5 - CNN - No MaxPool after Conv2D')\n",
    "results['No Global Max Pooling'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['No Global Max Pooling']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution + Activation ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>66.3%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>57.7%</td>\n",
       "      <td>63.7%</td>\n",
       "      <td>48.3%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>80.5%</td>\n",
       "      <td>61.1%</td>\n",
       "      <td>81.6%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>68.9%</td>\n",
       "      <td>13.4%</td>\n",
       "      <td>69.9%</td>\n",
       "      <td>11.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>79.5%</td>\n",
       "      <td>92.3%</td>\n",
       "      <td>65.6%</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>50.9%</td>\n",
       "      <td>63.1%</td>\n",
       "      <td>82.4%</td>\n",
       "      <td>64.5%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>80.8%</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>14.1%</td>\n",
       "      <td>70.5%</td>\n",
       "      <td>11.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>72.8%</td>\n",
       "      <td>74.0%</td>\n",
       "      <td>79.8%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>89.2%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>38.3%</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>66.2%</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>89.8%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>14.9%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>14.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>79.6%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>57.7%</td>\n",
       "      <td>64.3%</td>\n",
       "      <td>66.2%</td>\n",
       "      <td>66.3%</td>\n",
       "      <td>82.1%</td>\n",
       "      <td>67.1%</td>\n",
       "      <td>82.2%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>73.3%</td>\n",
       "      <td>15.6%</td>\n",
       "      <td>73.4%</td>\n",
       "      <td>10.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>82.9%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>85.8%</td>\n",
       "      <td>57.5%</td>\n",
       "      <td>45.4%</td>\n",
       "      <td>83.4%</td>\n",
       "      <td>60.3%</td>\n",
       "      <td>57.3%</td>\n",
       "      <td>77.8%</td>\n",
       "      <td>54.6%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>14.1%</td>\n",
       "      <td>67.8%</td>\n",
       "      <td>13.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>68.3%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>83.4%</td>\n",
       "      <td>57.7%</td>\n",
       "      <td>67.2%</td>\n",
       "      <td>62.3%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>82.7%</td>\n",
       "      <td>61.6%</td>\n",
       "      <td>82.4%</td>\n",
       "      <td>86.7%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>72.9%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>10.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>66.2%</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>65.6%</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>57.5%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>84.5%</td>\n",
       "      <td>64.5%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>80.5%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>15.7%</td>\n",
       "      <td>70.5%</td>\n",
       "      <td>9.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    66.3% 79.1% 90.5% 57.7% 63.7%   \n",
       "0-sessions-Baseline-federated-pre-training  65.9% 79.5% 92.3% 65.6% 60.6%   \n",
       "1-sessions-Centralized-no-pre-training      72.8% 74.0% 79.8% 63.9% 89.2%   \n",
       "2-sessions-Centralized-pre-training         79.6% 79.3% 80.0% 57.7% 64.3%   \n",
       "3-sessions-Federated-no-pre-training        65.9% 79.0% 82.9% 63.9% 85.8%   \n",
       "4-sessions-Federated-central-pre-training   68.3% 79.1% 83.4% 57.7% 67.2%   \n",
       "5-sessions-Federated-federated-pre-training 66.2% 79.4% 85.2% 65.6% 62.5%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    48.3% 68.5% 80.5% 61.1% 81.6%   \n",
       "0-sessions-Baseline-federated-pre-training  50.9% 63.1% 82.4% 64.5% 71.9%   \n",
       "1-sessions-Centralized-no-pre-training      62.2% 38.3% 85.2% 66.2% 71.7%   \n",
       "2-sessions-Centralized-pre-training         66.2% 66.3% 82.1% 67.1% 82.2%   \n",
       "3-sessions-Federated-no-pre-training        57.5% 45.4% 83.4% 60.3% 57.3%   \n",
       "4-sessions-Federated-central-pre-training   62.3% 78.8% 82.7% 61.6% 82.4%   \n",
       "5-sessions-Federated-federated-pre-training 57.5% 60.5% 84.5% 64.5% 71.5%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    74.9% 66.5%          68.9%   \n",
       "0-sessions-Baseline-federated-pre-training  80.8% 68.7%          69.7%   \n",
       "1-sessions-Centralized-no-pre-training      89.8% 70.7%          72.4%   \n",
       "2-sessions-Centralized-pre-training         90.5% 65.9%          73.3%   \n",
       "3-sessions-Federated-no-pre-training        77.8% 54.6%          69.0%   \n",
       "4-sessions-Federated-central-pre-training   86.7% 60.0%          72.9%   \n",
       "5-sessions-Federated-federated-pre-training 80.5% 68.5%          70.2%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           13.4% 69.9% 11.8%  \n",
       "0-sessions-Baseline-federated-pre-training         14.1% 70.5% 11.4%  \n",
       "1-sessions-Centralized-no-pre-training             14.9% 72.0% 14.1%  \n",
       "2-sessions-Centralized-pre-training                15.6% 73.4% 10.0%  \n",
       "3-sessions-Federated-no-pre-training               14.1% 67.8% 13.4%  \n",
       "4-sessions-Federated-central-pre-training          15.3% 72.5% 10.6%  \n",
       "5-sessions-Federated-federated-pre-training        15.7% 70.5%  9.6%  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '6 - Activation')\n",
    "results['ReLU'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['ReLU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution + Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>68.6%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>91.6%</td>\n",
       "      <td>42.5%</td>\n",
       "      <td>67.2%</td>\n",
       "      <td>50.9%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>79.7%</td>\n",
       "      <td>61.4%</td>\n",
       "      <td>80.4%</td>\n",
       "      <td>77.3%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>13.5%</td>\n",
       "      <td>69.3%</td>\n",
       "      <td>13.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.8%</td>\n",
       "      <td>79.2%</td>\n",
       "      <td>92.3%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>74.5%</td>\n",
       "      <td>56.5%</td>\n",
       "      <td>59.3%</td>\n",
       "      <td>78.2%</td>\n",
       "      <td>57.8%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>89.9%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>14.4%</td>\n",
       "      <td>72.6%</td>\n",
       "      <td>11.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>79.3%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>81.6%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>89.2%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>49.0%</td>\n",
       "      <td>82.8%</td>\n",
       "      <td>56.3%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>89.5%</td>\n",
       "      <td>64.6%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>16.5%</td>\n",
       "      <td>72.3%</td>\n",
       "      <td>13.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>81.3%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>42.5%</td>\n",
       "      <td>67.1%</td>\n",
       "      <td>63.5%</td>\n",
       "      <td>63.4%</td>\n",
       "      <td>84.8%</td>\n",
       "      <td>69.2%</td>\n",
       "      <td>80.5%</td>\n",
       "      <td>85.8%</td>\n",
       "      <td>66.9%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>14.9%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>12.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>76.0%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>83.8%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>53.2%</td>\n",
       "      <td>49.3%</td>\n",
       "      <td>73.3%</td>\n",
       "      <td>55.5%</td>\n",
       "      <td>51.7%</td>\n",
       "      <td>66.4%</td>\n",
       "      <td>40.2%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>15.5%</td>\n",
       "      <td>65.1%</td>\n",
       "      <td>15.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>79.9%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>86.9%</td>\n",
       "      <td>42.5%</td>\n",
       "      <td>71.4%</td>\n",
       "      <td>63.0%</td>\n",
       "      <td>56.6%</td>\n",
       "      <td>83.9%</td>\n",
       "      <td>59.6%</td>\n",
       "      <td>80.5%</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>13.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>81.0%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>83.6%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>64.1%</td>\n",
       "      <td>81.0%</td>\n",
       "      <td>58.6%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>76.8%</td>\n",
       "      <td>50.2%</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>10.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    68.6% 79.1% 91.6% 42.5% 67.2%   \n",
       "0-sessions-Baseline-federated-pre-training  66.8% 79.2% 92.3% 70.7% 74.5%   \n",
       "1-sessions-Centralized-no-pre-training      79.3% 79.1% 81.6% 63.9% 89.2%   \n",
       "2-sessions-Centralized-pre-training         81.3% 79.0% 79.1% 42.5% 67.1%   \n",
       "3-sessions-Federated-no-pre-training        76.0% 79.1% 83.8% 63.9% 88.7%   \n",
       "4-sessions-Federated-central-pre-training   79.9% 79.0% 86.9% 42.5% 71.4%   \n",
       "5-sessions-Federated-federated-pre-training 81.0% 79.1% 83.6% 70.7% 78.8%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    50.9% 62.2% 79.7% 61.4% 80.4%   \n",
       "0-sessions-Baseline-federated-pre-training  56.5% 59.3% 78.2% 57.8% 71.9%   \n",
       "1-sessions-Centralized-no-pre-training      60.0% 49.0% 82.8% 56.3% 72.0%   \n",
       "2-sessions-Centralized-pre-training         63.5% 63.4% 84.8% 69.2% 80.5%   \n",
       "3-sessions-Federated-no-pre-training        53.2% 49.3% 73.3% 55.5% 51.7%   \n",
       "4-sessions-Federated-central-pre-training   63.0% 56.6% 83.9% 59.6% 80.5%   \n",
       "5-sessions-Federated-federated-pre-training 62.0% 64.1% 81.0% 58.6% 72.1%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    77.3% 70.7%          69.0%   \n",
       "0-sessions-Baseline-federated-pre-training  89.9% 73.9%          71.8%   \n",
       "1-sessions-Centralized-no-pre-training      89.5% 64.6%          71.9%   \n",
       "2-sessions-Centralized-pre-training         85.8% 66.9%          72.1%   \n",
       "3-sessions-Federated-no-pre-training        66.4% 40.2%          65.9%   \n",
       "4-sessions-Federated-central-pre-training   78.9% 65.9%          71.3%   \n",
       "5-sessions-Federated-federated-pre-training 76.8% 50.2%          71.7%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           13.5% 69.3% 13.7%  \n",
       "0-sessions-Baseline-federated-pre-training         14.4% 72.6% 11.5%  \n",
       "1-sessions-Centralized-no-pre-training             16.5% 72.3% 13.3%  \n",
       "2-sessions-Centralized-pre-training                14.9% 71.9% 12.4%  \n",
       "3-sessions-Federated-no-pre-training               15.5% 65.1% 15.3%  \n",
       "4-sessions-Federated-central-pre-training          15.3% 70.7% 13.3%  \n",
       "5-sessions-Federated-federated-pre-training        16.3% 71.5% 10.6%  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '7 - Batch Norm')\n",
    "results['Batch Norm'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Batch Norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution + Batch Norm + ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>71.7%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>91.1%</td>\n",
       "      <td>55.5%</td>\n",
       "      <td>91.0%</td>\n",
       "      <td>56.5%</td>\n",
       "      <td>65.4%</td>\n",
       "      <td>78.4%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>13.4%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>11.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.9%</td>\n",
       "      <td>75.5%</td>\n",
       "      <td>83.0%</td>\n",
       "      <td>67.7%</td>\n",
       "      <td>89.2%</td>\n",
       "      <td>51.7%</td>\n",
       "      <td>60.9%</td>\n",
       "      <td>80.2%</td>\n",
       "      <td>70.4%</td>\n",
       "      <td>75.2%</td>\n",
       "      <td>90.7%</td>\n",
       "      <td>70.6%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>10.5%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>11.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>69.0%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>78.7%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>89.9%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>38.6%</td>\n",
       "      <td>83.1%</td>\n",
       "      <td>58.9%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>88.1%</td>\n",
       "      <td>63.1%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>15.0%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>14.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>68.9%</td>\n",
       "      <td>77.4%</td>\n",
       "      <td>73.6%</td>\n",
       "      <td>55.5%</td>\n",
       "      <td>92.6%</td>\n",
       "      <td>61.4%</td>\n",
       "      <td>72.3%</td>\n",
       "      <td>84.5%</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>85.9%</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>74.0%</td>\n",
       "      <td>14.1%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>10.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>68.4%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>76.8%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>89.0%</td>\n",
       "      <td>53.6%</td>\n",
       "      <td>42.7%</td>\n",
       "      <td>68.3%</td>\n",
       "      <td>60.9%</td>\n",
       "      <td>49.7%</td>\n",
       "      <td>82.0%</td>\n",
       "      <td>58.0%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>14.1%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>14.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>69.6%</td>\n",
       "      <td>77.5%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>55.5%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>64.7%</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>70.4%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>69.5%</td>\n",
       "      <td>70.4%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>73.3%</td>\n",
       "      <td>11.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>67.4%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>85.8%</td>\n",
       "      <td>67.7%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>59.4%</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>79.5%</td>\n",
       "      <td>77.0%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>84.8%</td>\n",
       "      <td>67.6%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>11.3%</td>\n",
       "      <td>73.6%</td>\n",
       "      <td>10.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    71.7% 77.7% 91.1% 55.5% 91.0%   \n",
       "0-sessions-Baseline-federated-pre-training  66.9% 75.5% 83.0% 67.7% 89.2%   \n",
       "1-sessions-Centralized-no-pre-training      69.0% 79.0% 78.7% 63.9% 89.9%   \n",
       "2-sessions-Centralized-pre-training         68.9% 77.4% 73.6% 55.5% 92.6%   \n",
       "3-sessions-Federated-no-pre-training        68.4% 79.0% 76.8% 63.9% 89.0%   \n",
       "4-sessions-Federated-central-pre-training   69.6% 77.5% 89.7% 55.5% 91.7%   \n",
       "5-sessions-Federated-federated-pre-training 67.4% 77.7% 85.8% 67.7% 90.5%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    56.5% 65.4% 78.4% 65.2% 75.9%   \n",
       "0-sessions-Baseline-federated-pre-training  51.7% 60.9% 80.2% 70.4% 75.2%   \n",
       "1-sessions-Centralized-no-pre-training      56.0% 38.6% 83.1% 58.9% 71.8%   \n",
       "2-sessions-Centralized-pre-training         61.4% 72.3% 84.5% 68.7% 75.9%   \n",
       "3-sessions-Federated-no-pre-training        53.6% 42.7% 68.3% 60.9% 49.7%   \n",
       "4-sessions-Federated-central-pre-training   60.5% 64.7% 86.0% 70.4% 74.7%   \n",
       "5-sessions-Federated-federated-pre-training 59.4% 60.6% 79.5% 77.0% 65.2%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    63.9% 70.0%          72.1%   \n",
       "0-sessions-Baseline-federated-pre-training  90.7% 70.6%          72.8%   \n",
       "1-sessions-Centralized-no-pre-training      88.1% 63.1%          70.0%   \n",
       "2-sessions-Centralized-pre-training         85.9% 68.7%          74.0%   \n",
       "3-sessions-Federated-no-pre-training        82.0% 58.0%          66.0%   \n",
       "4-sessions-Federated-central-pre-training   69.5% 70.4%          74.3%   \n",
       "5-sessions-Federated-federated-pre-training 84.8% 67.6%          74.3%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           13.4% 71.9% 11.6%  \n",
       "0-sessions-Baseline-federated-pre-training         10.5% 73.5% 11.3%  \n",
       "1-sessions-Centralized-no-pre-training             15.0% 70.0% 14.9%  \n",
       "2-sessions-Centralized-pre-training                14.1% 73.8% 10.4%  \n",
       "3-sessions-Federated-no-pre-training               14.1% 66.0% 14.0%  \n",
       "4-sessions-Federated-central-pre-training          12.5% 73.3% 11.2%  \n",
       "5-sessions-Federated-federated-pre-training        11.3% 73.6% 10.3%  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '8 - Activation and Batch Norm')\n",
    "results['ReLU + Batch Norm'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['ReLU + Batch Norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution + Batch Norm + ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>72.2%</td>\n",
       "      <td>77.8%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>64.7%</td>\n",
       "      <td>90.9%</td>\n",
       "      <td>56.9%</td>\n",
       "      <td>66.9%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>63.0%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>70.1%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>12.2%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>10.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.2%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>86.8%</td>\n",
       "      <td>70.6%</td>\n",
       "      <td>89.2%</td>\n",
       "      <td>52.8%</td>\n",
       "      <td>57.7%</td>\n",
       "      <td>78.7%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>91.2%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>10.9%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>12.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>69.6%</td>\n",
       "      <td>61.8%</td>\n",
       "      <td>82.1%</td>\n",
       "      <td>60.7%</td>\n",
       "      <td>87.4%</td>\n",
       "      <td>59.6%</td>\n",
       "      <td>46.8%</td>\n",
       "      <td>80.2%</td>\n",
       "      <td>58.3%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>87.7%</td>\n",
       "      <td>68.3%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>15.0%</td>\n",
       "      <td>69.5%</td>\n",
       "      <td>12.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>75.3%</td>\n",
       "      <td>77.8%</td>\n",
       "      <td>77.4%</td>\n",
       "      <td>64.7%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>69.5%</td>\n",
       "      <td>82.5%</td>\n",
       "      <td>55.4%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>87.2%</td>\n",
       "      <td>68.0%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>12.8%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>10.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>69.6%</td>\n",
       "      <td>61.7%</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>60.7%</td>\n",
       "      <td>87.5%</td>\n",
       "      <td>54.8%</td>\n",
       "      <td>55.0%</td>\n",
       "      <td>68.0%</td>\n",
       "      <td>61.8%</td>\n",
       "      <td>39.8%</td>\n",
       "      <td>83.2%</td>\n",
       "      <td>63.0%</td>\n",
       "      <td>66.8%</td>\n",
       "      <td>13.7%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>14.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>74.1%</td>\n",
       "      <td>77.8%</td>\n",
       "      <td>89.5%</td>\n",
       "      <td>64.7%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>58.3%</td>\n",
       "      <td>66.7%</td>\n",
       "      <td>84.4%</td>\n",
       "      <td>68.8%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>11.2%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>10.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>68.6%</td>\n",
       "      <td>76.6%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>70.6%</td>\n",
       "      <td>89.9%</td>\n",
       "      <td>59.3%</td>\n",
       "      <td>59.9%</td>\n",
       "      <td>78.3%</td>\n",
       "      <td>68.6%</td>\n",
       "      <td>52.9%</td>\n",
       "      <td>87.9%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>73.1%</td>\n",
       "      <td>10.4%</td>\n",
       "      <td>72.7%</td>\n",
       "      <td>12.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    72.2% 77.8% 90.5% 64.7% 90.9%   \n",
       "0-sessions-Baseline-federated-pre-training  66.2% 69.0% 86.8% 70.6% 89.2%   \n",
       "1-sessions-Centralized-no-pre-training      69.6% 61.8% 82.1% 60.7% 87.4%   \n",
       "2-sessions-Centralized-pre-training         75.3% 77.8% 77.4% 64.7% 90.5%   \n",
       "3-sessions-Federated-no-pre-training        69.6% 61.7% 86.0% 60.7% 87.5%   \n",
       "4-sessions-Federated-central-pre-training   74.1% 77.8% 89.5% 64.7% 91.7%   \n",
       "5-sessions-Federated-federated-pre-training 68.6% 76.6% 89.3% 70.6% 89.9%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    56.9% 66.9% 78.1% 63.0% 74.7%   \n",
       "0-sessions-Baseline-federated-pre-training  52.8% 57.7% 78.7% 66.0% 73.5%   \n",
       "1-sessions-Centralized-no-pre-training      59.6% 46.8% 80.2% 58.3% 71.9%   \n",
       "2-sessions-Centralized-pre-training         62.0% 69.5% 82.5% 55.4% 74.4%   \n",
       "3-sessions-Federated-no-pre-training        54.8% 55.0% 68.0% 61.8% 39.8%   \n",
       "4-sessions-Federated-central-pre-training   58.3% 66.7% 84.4% 68.8% 73.7%   \n",
       "5-sessions-Federated-federated-pre-training 59.3% 59.9% 78.3% 68.6% 52.9%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    70.1% 76.1%          72.8%   \n",
       "0-sessions-Baseline-federated-pre-training  91.2% 74.4%          72.5%   \n",
       "1-sessions-Centralized-no-pre-training      87.7% 68.3%          70.2%   \n",
       "2-sessions-Centralized-pre-training         87.2% 68.0%          73.0%   \n",
       "3-sessions-Federated-no-pre-training        83.2% 63.0%          66.8%   \n",
       "4-sessions-Federated-central-pre-training   75.0% 70.7%          74.6%   \n",
       "5-sessions-Federated-federated-pre-training 87.9% 70.2%          73.1%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           12.2% 73.5% 10.3%  \n",
       "0-sessions-Baseline-federated-pre-training         10.9% 73.0% 12.0%  \n",
       "1-sessions-Centralized-no-pre-training             15.0% 69.5% 12.8%  \n",
       "2-sessions-Centralized-pre-training                12.8% 73.7% 10.3%  \n",
       "3-sessions-Federated-no-pre-training               13.7% 65.9% 14.1%  \n",
       "4-sessions-Federated-central-pre-training          11.2% 74.6% 10.0%  \n",
       "5-sessions-Federated-federated-pre-training        10.4% 72.7% 12.2%  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '9 - Activation, Batch Norm, No Global MaxPool')\n",
    "results['ReLU + Batch Norm + No Glob Max Pool'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['ReLU + Batch Norm + No Glob Max Pool']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution + Batch Norm + ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>66.3%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>64.5%</td>\n",
       "      <td>76.2%</td>\n",
       "      <td>53.7%</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>60.4%</td>\n",
       "      <td>73.2%</td>\n",
       "      <td>89.4%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>15.9%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>11.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>69.3%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>62.9%</td>\n",
       "      <td>77.1%</td>\n",
       "      <td>47.3%</td>\n",
       "      <td>58.4%</td>\n",
       "      <td>82.9%</td>\n",
       "      <td>60.7%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>51.1%</td>\n",
       "      <td>69.1%</td>\n",
       "      <td>14.9%</td>\n",
       "      <td>69.3%</td>\n",
       "      <td>13.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>71.1%</td>\n",
       "      <td>79.2%</td>\n",
       "      <td>81.4%</td>\n",
       "      <td>62.3%</td>\n",
       "      <td>90.6%</td>\n",
       "      <td>57.9%</td>\n",
       "      <td>38.2%</td>\n",
       "      <td>82.4%</td>\n",
       "      <td>61.4%</td>\n",
       "      <td>72.6%</td>\n",
       "      <td>91.2%</td>\n",
       "      <td>68.9%</td>\n",
       "      <td>71.4%</td>\n",
       "      <td>15.0%</td>\n",
       "      <td>71.4%</td>\n",
       "      <td>15.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>77.5%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>84.6%</td>\n",
       "      <td>64.5%</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>60.3%</td>\n",
       "      <td>84.4%</td>\n",
       "      <td>75.6%</td>\n",
       "      <td>74.0%</td>\n",
       "      <td>87.2%</td>\n",
       "      <td>69.1%</td>\n",
       "      <td>75.2%</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>8.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>71.4%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>86.2%</td>\n",
       "      <td>62.3%</td>\n",
       "      <td>92.1%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>45.9%</td>\n",
       "      <td>82.5%</td>\n",
       "      <td>56.7%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>72.6%</td>\n",
       "      <td>36.5%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>14.9%</td>\n",
       "      <td>66.6%</td>\n",
       "      <td>16.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>77.4%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>81.0%</td>\n",
       "      <td>64.5%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>62.8%</td>\n",
       "      <td>61.6%</td>\n",
       "      <td>81.9%</td>\n",
       "      <td>59.9%</td>\n",
       "      <td>73.4%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>55.9%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>17.1%</td>\n",
       "      <td>71.0%</td>\n",
       "      <td>9.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>80.1%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>82.6%</td>\n",
       "      <td>62.9%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>56.1%</td>\n",
       "      <td>44.2%</td>\n",
       "      <td>84.9%</td>\n",
       "      <td>57.7%</td>\n",
       "      <td>53.3%</td>\n",
       "      <td>71.6%</td>\n",
       "      <td>39.1%</td>\n",
       "      <td>66.8%</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>15.7%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    66.3% 77.7% 91.9% 64.5% 76.2%   \n",
       "0-sessions-Baseline-federated-pre-training  69.3% 78.8% 86.0% 62.9% 77.1%   \n",
       "1-sessions-Centralized-no-pre-training      71.1% 79.2% 81.4% 62.3% 90.6%   \n",
       "2-sessions-Centralized-pre-training         77.5% 77.7% 84.6% 64.5% 76.0%   \n",
       "3-sessions-Federated-no-pre-training        71.4% 79.3% 86.2% 62.3% 92.1%   \n",
       "4-sessions-Federated-central-pre-training   77.4% 77.7% 81.0% 64.5% 78.1%   \n",
       "5-sessions-Federated-federated-pre-training 80.1% 78.8% 82.6% 62.9% 78.1%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    53.7% 60.6% 79.0% 60.4% 73.2%   \n",
       "0-sessions-Baseline-federated-pre-training  47.3% 58.4% 82.9% 60.7% 71.9%   \n",
       "1-sessions-Centralized-no-pre-training      57.9% 38.2% 82.4% 61.4% 72.6%   \n",
       "2-sessions-Centralized-pre-training         65.9% 60.3% 84.4% 75.6% 74.0%   \n",
       "3-sessions-Federated-no-pre-training        54.1% 45.9% 82.5% 56.7% 60.0%   \n",
       "4-sessions-Federated-central-pre-training   62.8% 61.6% 81.9% 59.9% 73.4%   \n",
       "5-sessions-Federated-federated-pre-training 56.1% 44.2% 84.9% 57.7% 53.3%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    89.4% 70.7%          71.5%   \n",
       "0-sessions-Baseline-federated-pre-training  85.2% 51.1%          69.1%   \n",
       "1-sessions-Centralized-no-pre-training      91.2% 68.9%          71.4%   \n",
       "2-sessions-Centralized-pre-training         87.2% 69.1%          75.2%   \n",
       "3-sessions-Federated-no-pre-training        72.6% 36.5%          68.5%   \n",
       "4-sessions-Federated-central-pre-training   78.0% 55.9%          71.3%   \n",
       "5-sessions-Federated-federated-pre-training 71.6% 39.1%          66.8%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           15.9% 72.0% 11.6%  \n",
       "0-sessions-Baseline-federated-pre-training         14.9% 69.3% 13.2%  \n",
       "1-sessions-Centralized-no-pre-training             15.0% 71.4% 15.1%  \n",
       "2-sessions-Centralized-pre-training                16.3% 74.7%  8.5%  \n",
       "3-sessions-Federated-no-pre-training               14.9% 66.6% 16.9%  \n",
       "4-sessions-Federated-central-pre-training          17.1% 71.0%  9.3%  \n",
       "5-sessions-Federated-federated-pre-training        15.2% 65.8% 15.7%  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '10 - Replace Stride with Pooling')\n",
    "results['Replace Stride with Pooling'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Replace Stride with Pooling']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>67.1%</td>\n",
       "      <td>76.5%</td>\n",
       "      <td>87.0%</td>\n",
       "      <td>53.1%</td>\n",
       "      <td>90.4%</td>\n",
       "      <td>59.6%</td>\n",
       "      <td>69.6%</td>\n",
       "      <td>79.7%</td>\n",
       "      <td>61.6%</td>\n",
       "      <td>81.9%</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>81.7%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>11.8%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>11.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.6%</td>\n",
       "      <td>22.2%</td>\n",
       "      <td>92.6%</td>\n",
       "      <td>60.9%</td>\n",
       "      <td>89.6%</td>\n",
       "      <td>62.4%</td>\n",
       "      <td>63.5%</td>\n",
       "      <td>77.8%</td>\n",
       "      <td>65.4%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>87.7%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>14.0%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>18.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>67.1%</td>\n",
       "      <td>70.9%</td>\n",
       "      <td>85.8%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>58.2%</td>\n",
       "      <td>49.1%</td>\n",
       "      <td>82.4%</td>\n",
       "      <td>64.2%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>87.1%</td>\n",
       "      <td>44.3%</td>\n",
       "      <td>70.6%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>13.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>76.5%</td>\n",
       "      <td>75.6%</td>\n",
       "      <td>88.9%</td>\n",
       "      <td>53.1%</td>\n",
       "      <td>92.9%</td>\n",
       "      <td>59.5%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>78.3%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>81.6%</td>\n",
       "      <td>89.6%</td>\n",
       "      <td>75.4%</td>\n",
       "      <td>76.2%</td>\n",
       "      <td>11.5%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>11.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>68.4%</td>\n",
       "      <td>76.2%</td>\n",
       "      <td>92.3%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>78.5%</td>\n",
       "      <td>54.6%</td>\n",
       "      <td>40.9%</td>\n",
       "      <td>76.5%</td>\n",
       "      <td>62.3%</td>\n",
       "      <td>67.4%</td>\n",
       "      <td>46.1%</td>\n",
       "      <td>37.4%</td>\n",
       "      <td>66.2%</td>\n",
       "      <td>16.2%</td>\n",
       "      <td>64.1%</td>\n",
       "      <td>16.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>66.9%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>91.3%</td>\n",
       "      <td>53.1%</td>\n",
       "      <td>92.4%</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>80.3%</td>\n",
       "      <td>59.0%</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>12.1%</td>\n",
       "      <td>74.5%</td>\n",
       "      <td>12.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>74.1%</td>\n",
       "      <td>54.9%</td>\n",
       "      <td>92.0%</td>\n",
       "      <td>60.9%</td>\n",
       "      <td>91.4%</td>\n",
       "      <td>63.8%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>65.3%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>87.2%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>75.2%</td>\n",
       "      <td>15.6%</td>\n",
       "      <td>74.2%</td>\n",
       "      <td>11.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               43    48    52    59    64  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    67.1% 76.5% 87.0% 53.1% 90.4%   \n",
       "0-sessions-Baseline-federated-pre-training  66.6% 22.2% 92.6% 60.9% 89.6%   \n",
       "1-sessions-Centralized-no-pre-training      67.1% 70.9% 85.8% 69.0% 75.7%   \n",
       "2-sessions-Centralized-pre-training         76.5% 75.6% 88.9% 53.1% 92.9%   \n",
       "3-sessions-Federated-no-pre-training        68.4% 76.2% 92.3% 69.0% 78.5%   \n",
       "4-sessions-Federated-central-pre-training   66.9% 76.1% 91.3% 53.1% 92.4%   \n",
       "5-sessions-Federated-federated-pre-training 74.1% 54.9% 92.0% 60.9% 91.4%   \n",
       "\n",
       "                                               80    92    96   107   109  \\\n",
       "Experiment                                                                  \n",
       "0-sessions-Baseline-central-pre-training    59.6% 69.6% 79.7% 61.6% 81.9%   \n",
       "0-sessions-Baseline-federated-pre-training  62.4% 63.5% 77.8% 65.4% 71.9%   \n",
       "1-sessions-Centralized-no-pre-training      58.2% 49.1% 82.4% 64.2% 71.3%   \n",
       "2-sessions-Centralized-pre-training         59.5% 69.7% 78.3% 72.4% 81.6%   \n",
       "3-sessions-Federated-no-pre-training        54.6% 40.9% 76.5% 62.3% 67.4%   \n",
       "4-sessions-Federated-central-pre-training   60.6% 75.9% 80.3% 59.0% 80.0%   \n",
       "5-sessions-Federated-federated-pre-training 63.8% 73.8% 79.0% 65.3% 72.1%   \n",
       "\n",
       "                                              115   120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-sessions-Baseline-central-pre-training    76.0% 81.7%          73.5%   \n",
       "0-sessions-Baseline-federated-pre-training  87.7% 75.7%          72.4%   \n",
       "1-sessions-Centralized-no-pre-training      87.1% 44.3%          70.6%   \n",
       "2-sessions-Centralized-pre-training         89.6% 75.4%          76.2%   \n",
       "3-sessions-Federated-no-pre-training        46.1% 37.4%          66.2%   \n",
       "4-sessions-Federated-central-pre-training   79.1% 78.9%          74.7%   \n",
       "5-sessions-Federated-federated-pre-training 87.2% 75.9%          75.2%   \n",
       "\n",
       "                                             Weighted SD  Mean    SD  \n",
       "Experiment                                                            \n",
       "0-sessions-Baseline-central-pre-training           11.8% 73.7% 11.5%  \n",
       "0-sessions-Baseline-federated-pre-training         14.0% 69.7% 18.6%  \n",
       "1-sessions-Centralized-no-pre-training             15.3% 68.7% 13.5%  \n",
       "2-sessions-Centralized-pre-training                11.5% 76.1% 11.8%  \n",
       "3-sessions-Federated-no-pre-training               16.2% 64.1% 16.6%  \n",
       "4-sessions-Federated-central-pre-training          12.1% 74.5% 12.3%  \n",
       "5-sessions-Federated-federated-pre-training        15.6% 74.2% 11.9%  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '11 - All Modifications')\n",
    "results['All Modifications'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['All Modifications']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>67.5%</td>\n",
       "      <td>78.2%</td>\n",
       "      <td>92.0%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>89.2%</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>71.2%</td>\n",
       "      <td>79.2%</td>\n",
       "      <td>66.2%</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>12.8%</td>\n",
       "      <td>74.2%</td>\n",
       "      <td>9.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.0%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>58.2%</td>\n",
       "      <td>61.1%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>59.7%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>90.7%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>12.1%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>11.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>72.9%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>83.0%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>75.8%</td>\n",
       "      <td>54.5%</td>\n",
       "      <td>43.1%</td>\n",
       "      <td>83.6%</td>\n",
       "      <td>57.7%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>88.4%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>69.3%</td>\n",
       "      <td>16.2%</td>\n",
       "      <td>70.1%</td>\n",
       "      <td>13.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>76.3%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>90.9%</td>\n",
       "      <td>63.5%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>85.4%</td>\n",
       "      <td>68.9%</td>\n",
       "      <td>75.2%</td>\n",
       "      <td>88.6%</td>\n",
       "      <td>55.6%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>13.4%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>10.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>72.5%</td>\n",
       "      <td>76.2%</td>\n",
       "      <td>87.6%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>74.1%</td>\n",
       "      <td>53.4%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>69.2%</td>\n",
       "      <td>57.6%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>47.0%</td>\n",
       "      <td>67.0%</td>\n",
       "      <td>15.6%</td>\n",
       "      <td>66.6%</td>\n",
       "      <td>12.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>68.7%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>90.3%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>91.1%</td>\n",
       "      <td>63.2%</td>\n",
       "      <td>68.9%</td>\n",
       "      <td>83.6%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>75.1%</td>\n",
       "      <td>78.3%</td>\n",
       "      <td>62.4%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>11.3%</td>\n",
       "      <td>74.8%</td>\n",
       "      <td>9.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>66.8%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>89.8%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>89.8%</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>70.5%</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>74.1%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>85.5%</td>\n",
       "      <td>58.9%</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>12.1%</td>\n",
       "      <td>74.5%</td>\n",
       "      <td>10.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-sessions-Federated-central-pre-training-personalization</th>\n",
       "      <td>71.6%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>84.5%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>64.1%</td>\n",
       "      <td>79.9%</td>\n",
       "      <td>82.4%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>75.3%</td>\n",
       "      <td>90.7%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>77.5%</td>\n",
       "      <td>12.6%</td>\n",
       "      <td>77.5%</td>\n",
       "      <td>8.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-sessions-Federated-no-pre-training-local-models</th>\n",
       "      <td>67.7%</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>92.0%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>75.5%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>42.5%</td>\n",
       "      <td>67.4%</td>\n",
       "      <td>62.1%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>69.6%</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>69.4%</td>\n",
       "      <td>13.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-sessions-Federated-central-pre-training-local-models</th>\n",
       "      <td>71.4%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>81.0%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>93.0%</td>\n",
       "      <td>62.7%</td>\n",
       "      <td>67.1%</td>\n",
       "      <td>82.6%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>75.5%</td>\n",
       "      <td>90.6%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>75.8%</td>\n",
       "      <td>12.6%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>9.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-sessions-Federated-federated-pre-training-local-models</th>\n",
       "      <td>74.4%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>87.7%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>62.1%</td>\n",
       "      <td>62.8%</td>\n",
       "      <td>81.8%</td>\n",
       "      <td>67.2%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>90.8%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>75.8%</td>\n",
       "      <td>13.3%</td>\n",
       "      <td>75.8%</td>\n",
       "      <td>10.1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      43    48    52    59  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           67.5% 78.2% 92.0% 67.3%   \n",
       "0-sessions-Baseline-federated-pre-training         66.0% 73.9% 89.3% 71.9%   \n",
       "1-sessions-Centralized-no-pre-training             72.9% 75.7% 83.0% 69.0%   \n",
       "2-sessions-Centralized-pre-training                76.3% 78.0% 73.7% 67.3%   \n",
       "3-sessions-Federated-no-pre-training               72.5% 76.2% 87.6% 69.0%   \n",
       "4-sessions-Federated-central-pre-training          68.7% 78.0% 90.3% 67.3%   \n",
       "5-sessions-Federated-federated-pre-training        66.8% 74.4% 89.8% 71.9%   \n",
       "7-sessions-Federated-central-pre-training-perso... 71.6% 78.0% 84.5% 67.3%   \n",
       "9-sessions-Federated-no-pre-training-local-models  67.7% 76.0% 92.0% 69.0%   \n",
       "10-sessions-Federated-central-pre-training-loca... 71.4% 78.0% 81.0% 67.3%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 74.4% 74.6% 87.7% 71.9%   \n",
       "\n",
       "                                                      64    80    92    96  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           89.2% 60.6% 71.2% 79.2%   \n",
       "0-sessions-Baseline-federated-pre-training         89.3% 58.2% 61.1% 79.1%   \n",
       "1-sessions-Centralized-no-pre-training             75.8% 54.5% 43.1% 83.6%   \n",
       "2-sessions-Centralized-pre-training                90.9% 63.5% 72.1% 85.4%   \n",
       "3-sessions-Federated-no-pre-training               74.1% 53.4% 54.1% 69.2%   \n",
       "4-sessions-Federated-central-pre-training          91.1% 63.2% 68.9% 83.6%   \n",
       "5-sessions-Federated-federated-pre-training        89.8% 62.0% 70.5% 78.9%   \n",
       "7-sessions-Federated-central-pre-training-perso... 91.9% 64.1% 79.9% 82.4%   \n",
       "9-sessions-Federated-no-pre-training-local-models  75.5% 56.0% 42.5% 67.4%   \n",
       "10-sessions-Federated-central-pre-training-loca... 93.0% 62.7% 67.1% 82.6%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 91.7% 62.1% 62.8% 81.8%   \n",
       "\n",
       "                                                     107   109   115   120  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           66.2% 75.0% 70.2% 73.9%   \n",
       "0-sessions-Baseline-federated-pre-training         59.7% 71.9% 90.7% 73.7%   \n",
       "1-sessions-Centralized-no-pre-training             57.7% 71.8% 88.4% 65.2%   \n",
       "2-sessions-Centralized-pre-training                68.9% 75.2% 88.6% 55.6%   \n",
       "3-sessions-Federated-no-pre-training               57.6% 60.0% 79.3% 47.0%   \n",
       "4-sessions-Federated-central-pre-training          70.7% 75.1% 78.3% 62.4%   \n",
       "5-sessions-Federated-federated-pre-training        74.1% 71.5% 85.5% 58.9%   \n",
       "7-sessions-Federated-central-pre-training-perso... 70.2% 75.3% 90.7% 74.6%   \n",
       "9-sessions-Federated-no-pre-training-local-models  62.1% 71.9% 88.0% 65.2%   \n",
       "10-sessions-Federated-central-pre-training-loca... 68.5% 75.5% 90.6% 75.7%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 67.2% 71.9% 90.8% 72.8%   \n",
       "\n",
       "                                                    Weighted Mean  \\\n",
       "Experiment                                                          \n",
       "0-sessions-Baseline-central-pre-training                    74.4%   \n",
       "0-sessions-Baseline-federated-pre-training                  73.5%   \n",
       "1-sessions-Centralized-no-pre-training                      69.3%   \n",
       "2-sessions-Centralized-pre-training                         74.9%   \n",
       "3-sessions-Federated-no-pre-training                        67.0%   \n",
       "4-sessions-Federated-central-pre-training                   76.1%   \n",
       "5-sessions-Federated-federated-pre-training                 76.0%   \n",
       "7-sessions-Federated-central-pre-training-perso...          77.5%   \n",
       "9-sessions-Federated-no-pre-training-local-models           69.6%   \n",
       "10-sessions-Federated-central-pre-training-loca...          75.8%   \n",
       "11-sessions-Federated-federated-pre-training-lo...          75.8%   \n",
       "\n",
       "                                                    Weighted SD  Mean    SD  \n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training                  12.8% 74.2%  9.3%  \n",
       "0-sessions-Baseline-federated-pre-training                12.1% 73.7% 11.5%  \n",
       "1-sessions-Centralized-no-pre-training                    16.2% 70.1% 13.2%  \n",
       "2-sessions-Centralized-pre-training                       13.4% 74.6% 10.3%  \n",
       "3-sessions-Federated-no-pre-training                      15.6% 66.6% 12.2%  \n",
       "4-sessions-Federated-central-pre-training                 11.3% 74.8%  9.7%  \n",
       "5-sessions-Federated-federated-pre-training               12.1% 74.5% 10.0%  \n",
       "7-sessions-Federated-central-pre-training-perso...        12.6% 77.5%  8.8%  \n",
       "9-sessions-Federated-no-pre-training-local-models         16.3% 69.4% 13.2%  \n",
       "10-sessions-Federated-central-pre-training-loca...        12.6% 76.1%  9.5%  \n",
       "11-sessions-Federated-federated-pre-training-lo...        13.3% 75.8% 10.1%  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '12 - Personalization, Same Padding, Max Pool, Activation, Batch Norm')\n",
    "results['Same Padding'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Same Padding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Results - All Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Pain Level 0</th>\n",
       "      <th>RMSProp</th>\n",
       "      <th>ResNet</th>\n",
       "      <th>No Global Max Pooling</th>\n",
       "      <th>ReLU</th>\n",
       "      <th>Batch Norm</th>\n",
       "      <th>ReLU + Batch Norm</th>\n",
       "      <th>ReLU + Batch Norm + No Glob Max Pool</th>\n",
       "      <th>Replace Stride with Pooling</th>\n",
       "      <th>All Modifications</th>\n",
       "      <th>Same Padding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>68.7%</td>\n",
       "      <td>66.9%</td>\n",
       "      <td>69.9%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>65.5%</td>\n",
       "      <td>68.9%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>74.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>69.6%</td>\n",
       "      <td>69.6%</td>\n",
       "      <td>73.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>69.6%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>69.1%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>73.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>72.7%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>66.1%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>71.4%</td>\n",
       "      <td>70.6%</td>\n",
       "      <td>69.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>72.7%</td>\n",
       "      <td>72.9%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>73.3%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>74.0%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>75.2%</td>\n",
       "      <td>76.2%</td>\n",
       "      <td>74.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>67.1%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>43.7%</td>\n",
       "      <td>67.4%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>66.8%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>66.2%</td>\n",
       "      <td>67.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>71.3%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>46.8%</td>\n",
       "      <td>70.4%</td>\n",
       "      <td>72.9%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>76.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>69.7%</td>\n",
       "      <td>68.4%</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>70.3%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>73.1%</td>\n",
       "      <td>66.8%</td>\n",
       "      <td>75.2%</td>\n",
       "      <td>76.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Base  Pain Level 0  RMSProp  \\\n",
       "Experiment                                                                 \n",
       "0-sessions-Baseline-central-pre-training    68.7%         66.9%    69.9%   \n",
       "0-sessions-Baseline-federated-pre-training  69.6%         69.6%    73.3%   \n",
       "1-sessions-Centralized-no-pre-training      72.7%         71.3%    73.0%   \n",
       "2-sessions-Centralized-pre-training         72.7%         72.9%    72.4%   \n",
       "3-sessions-Federated-no-pre-training        67.1%         70.2%    65.9%   \n",
       "4-sessions-Federated-central-pre-training   71.3%         72.1%    74.4%   \n",
       "5-sessions-Federated-federated-pre-training 69.7%         68.4%    71.7%   \n",
       "\n",
       "                                             ResNet  No Global Max Pooling  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training       nan%                  65.5%   \n",
       "0-sessions-Baseline-federated-pre-training     nan%                  69.6%   \n",
       "1-sessions-Centralized-no-pre-training        66.1%                  72.1%   \n",
       "2-sessions-Centralized-pre-training           67.3%                  71.3%   \n",
       "3-sessions-Federated-no-pre-training          43.7%                  67.4%   \n",
       "4-sessions-Federated-central-pre-training     46.8%                  70.4%   \n",
       "5-sessions-Federated-federated-pre-training    nan%                  70.3%   \n",
       "\n",
       "                                             ReLU  Batch Norm  \\\n",
       "Experiment                                                      \n",
       "0-sessions-Baseline-central-pre-training    68.9%       69.0%   \n",
       "0-sessions-Baseline-federated-pre-training  69.7%       71.8%   \n",
       "1-sessions-Centralized-no-pre-training      72.4%       71.9%   \n",
       "2-sessions-Centralized-pre-training         73.3%       72.1%   \n",
       "3-sessions-Federated-no-pre-training        69.0%       65.9%   \n",
       "4-sessions-Federated-central-pre-training   72.9%       71.3%   \n",
       "5-sessions-Federated-federated-pre-training 70.2%       71.7%   \n",
       "\n",
       "                                             ReLU + Batch Norm  \\\n",
       "Experiment                                                       \n",
       "0-sessions-Baseline-central-pre-training                 72.1%   \n",
       "0-sessions-Baseline-federated-pre-training               72.8%   \n",
       "1-sessions-Centralized-no-pre-training                   70.0%   \n",
       "2-sessions-Centralized-pre-training                      74.0%   \n",
       "3-sessions-Federated-no-pre-training                     66.0%   \n",
       "4-sessions-Federated-central-pre-training                74.3%   \n",
       "5-sessions-Federated-federated-pre-training              74.3%   \n",
       "\n",
       "                                             ReLU + Batch Norm + No Glob Max Pool  \\\n",
       "Experiment                                                                          \n",
       "0-sessions-Baseline-central-pre-training                                    72.8%   \n",
       "0-sessions-Baseline-federated-pre-training                                  72.5%   \n",
       "1-sessions-Centralized-no-pre-training                                      70.2%   \n",
       "2-sessions-Centralized-pre-training                                         73.0%   \n",
       "3-sessions-Federated-no-pre-training                                        66.8%   \n",
       "4-sessions-Federated-central-pre-training                                   74.6%   \n",
       "5-sessions-Federated-federated-pre-training                                 73.1%   \n",
       "\n",
       "                                             Replace Stride with Pooling  \\\n",
       "Experiment                                                                 \n",
       "0-sessions-Baseline-central-pre-training                           71.5%   \n",
       "0-sessions-Baseline-federated-pre-training                         69.1%   \n",
       "1-sessions-Centralized-no-pre-training                             71.4%   \n",
       "2-sessions-Centralized-pre-training                                75.2%   \n",
       "3-sessions-Federated-no-pre-training                               68.5%   \n",
       "4-sessions-Federated-central-pre-training                          71.3%   \n",
       "5-sessions-Federated-federated-pre-training                        66.8%   \n",
       "\n",
       "                                             All Modifications  Same Padding  \n",
       "Experiment                                                                    \n",
       "0-sessions-Baseline-central-pre-training                 73.5%         74.4%  \n",
       "0-sessions-Baseline-federated-pre-training               72.4%         73.5%  \n",
       "1-sessions-Centralized-no-pre-training                   70.6%         69.3%  \n",
       "2-sessions-Centralized-pre-training                      76.2%         74.9%  \n",
       "3-sessions-Federated-no-pre-training                     66.2%         67.0%  \n",
       "4-sessions-Federated-central-pre-training                74.7%         76.1%  \n",
       "5-sessions-Federated-federated-pre-training              75.2%         76.0%  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "for key, df in results.items():\n",
    "    result_df[key] = df['Weighted Mean']\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEEDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>69.3%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>92.4%</td>\n",
       "      <td>53.3%</td>\n",
       "      <td>91.0%</td>\n",
       "      <td>59.6%</td>\n",
       "      <td>66.9%</td>\n",
       "      <td>78.6%</td>\n",
       "      <td>64.5%</td>\n",
       "      <td>79.6%</td>\n",
       "      <td>66.4%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>73.4%</td>\n",
       "      <td>12.2%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>11.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.0%</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>89.1%</td>\n",
       "      <td>59.3%</td>\n",
       "      <td>60.4%</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>61.0%</td>\n",
       "      <td>72.3%</td>\n",
       "      <td>89.4%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>73.6%</td>\n",
       "      <td>12.7%</td>\n",
       "      <td>73.4%</td>\n",
       "      <td>11.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-random</th>\n",
       "      <td>34.1%</td>\n",
       "      <td>20.7%</td>\n",
       "      <td>7.5%</td>\n",
       "      <td>36.1%</td>\n",
       "      <td>11.0%</td>\n",
       "      <td>48.9%</td>\n",
       "      <td>62.1%</td>\n",
       "      <td>22.3%</td>\n",
       "      <td>45.2%</td>\n",
       "      <td>28.1%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>34.8%</td>\n",
       "      <td>30.2%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>30.2%</td>\n",
       "      <td>16.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>79.2%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>77.6%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>91.2%</td>\n",
       "      <td>59.2%</td>\n",
       "      <td>37.8%</td>\n",
       "      <td>82.8%</td>\n",
       "      <td>57.2%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>54.6%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>15.9%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>15.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>76.5%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>79.6%</td>\n",
       "      <td>53.3%</td>\n",
       "      <td>90.1%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>71.2%</td>\n",
       "      <td>84.2%</td>\n",
       "      <td>72.2%</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>85.3%</td>\n",
       "      <td>65.6%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>13.6%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>71.0%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>90.2%</td>\n",
       "      <td>56.3%</td>\n",
       "      <td>43.6%</td>\n",
       "      <td>71.1%</td>\n",
       "      <td>61.8%</td>\n",
       "      <td>44.1%</td>\n",
       "      <td>81.3%</td>\n",
       "      <td>48.7%</td>\n",
       "      <td>68.3%</td>\n",
       "      <td>14.1%</td>\n",
       "      <td>66.7%</td>\n",
       "      <td>16.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>74.1%</td>\n",
       "      <td>77.9%</td>\n",
       "      <td>92.2%</td>\n",
       "      <td>53.3%</td>\n",
       "      <td>90.9%</td>\n",
       "      <td>62.3%</td>\n",
       "      <td>75.3%</td>\n",
       "      <td>82.4%</td>\n",
       "      <td>67.8%</td>\n",
       "      <td>76.4%</td>\n",
       "      <td>72.6%</td>\n",
       "      <td>63.1%</td>\n",
       "      <td>75.3%</td>\n",
       "      <td>12.2%</td>\n",
       "      <td>74.0%</td>\n",
       "      <td>11.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>71.1%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>88.9%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>90.7%</td>\n",
       "      <td>64.4%</td>\n",
       "      <td>67.4%</td>\n",
       "      <td>81.4%</td>\n",
       "      <td>72.9%</td>\n",
       "      <td>71.4%</td>\n",
       "      <td>87.9%</td>\n",
       "      <td>63.7%</td>\n",
       "      <td>76.8%</td>\n",
       "      <td>12.3%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>9.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6-sessions-Federated-no-pre-training-personalization</th>\n",
       "      <td>70.7%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>92.1%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>57.0%</td>\n",
       "      <td>37.8%</td>\n",
       "      <td>77.9%</td>\n",
       "      <td>60.4%</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>71.1%</td>\n",
       "      <td>15.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-sessions-Federated-central-pre-training-personalization</th>\n",
       "      <td>82.2%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>53.3%</td>\n",
       "      <td>92.4%</td>\n",
       "      <td>63.4%</td>\n",
       "      <td>77.1%</td>\n",
       "      <td>84.2%</td>\n",
       "      <td>67.9%</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>89.8%</td>\n",
       "      <td>71.3%</td>\n",
       "      <td>77.4%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>77.2%</td>\n",
       "      <td>11.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8-sessions-Federated-federated-pre-training-personalization</th>\n",
       "      <td>75.0%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>91.1%</td>\n",
       "      <td>63.1%</td>\n",
       "      <td>59.1%</td>\n",
       "      <td>83.1%</td>\n",
       "      <td>66.2%</td>\n",
       "      <td>72.3%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>68.3%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>13.7%</td>\n",
       "      <td>75.4%</td>\n",
       "      <td>10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-sessions-Federated-no-pre-training-local-models</th>\n",
       "      <td>67.5%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>92.5%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>90.3%</td>\n",
       "      <td>56.1%</td>\n",
       "      <td>37.9%</td>\n",
       "      <td>75.5%</td>\n",
       "      <td>62.1%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>87.9%</td>\n",
       "      <td>65.0%</td>\n",
       "      <td>71.6%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>70.8%</td>\n",
       "      <td>15.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-sessions-Federated-central-pre-training-local-models</th>\n",
       "      <td>82.9%</td>\n",
       "      <td>78.0%</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>53.3%</td>\n",
       "      <td>93.3%</td>\n",
       "      <td>63.2%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>85.0%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>79.6%</td>\n",
       "      <td>89.4%</td>\n",
       "      <td>69.6%</td>\n",
       "      <td>76.5%</td>\n",
       "      <td>13.1%</td>\n",
       "      <td>76.2%</td>\n",
       "      <td>12.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-sessions-Federated-federated-pre-training-local-models</th>\n",
       "      <td>72.9%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>87.9%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>90.8%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>59.1%</td>\n",
       "      <td>82.4%</td>\n",
       "      <td>66.2%</td>\n",
       "      <td>72.3%</td>\n",
       "      <td>89.2%</td>\n",
       "      <td>67.2%</td>\n",
       "      <td>75.2%</td>\n",
       "      <td>13.9%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>10.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      43    48    52    59  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           69.3% 78.1% 92.4% 53.3%   \n",
       "0-sessions-Baseline-federated-pre-training         66.0% 66.5% 90.0% 73.8%   \n",
       "0-sessions-Baseline-random                         34.1% 20.7%  7.5% 36.1%   \n",
       "1-sessions-Centralized-no-pre-training             79.2% 79.0% 77.6% 63.9%   \n",
       "2-sessions-Centralized-pre-training                76.5% 78.1% 79.6% 53.3%   \n",
       "3-sessions-Federated-no-pre-training               71.0% 79.0% 89.7% 63.9%   \n",
       "4-sessions-Federated-central-pre-training          74.1% 77.9% 92.2% 53.3%   \n",
       "5-sessions-Federated-federated-pre-training        71.1% 74.4% 88.9% 73.8%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 70.7% 79.0% 92.1% 63.9%   \n",
       "7-sessions-Federated-central-pre-training-perso... 82.2% 78.0% 88.0% 53.3%   \n",
       "8-sessions-Federated-federated-pre-training-per... 75.0% 74.4% 88.7% 73.8%   \n",
       "9-sessions-Federated-no-pre-training-local-models  67.5% 79.0% 92.5% 63.9%   \n",
       "10-sessions-Federated-central-pre-training-loca... 82.9% 78.0% 86.0% 53.3%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 72.9% 74.4% 87.9% 73.8%   \n",
       "\n",
       "                                                      64    80    92    96  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           91.0% 59.6% 66.9% 78.6%   \n",
       "0-sessions-Baseline-federated-pre-training         89.1% 59.3% 60.4% 79.4%   \n",
       "0-sessions-Baseline-random                         11.0% 48.9% 62.1% 22.3%   \n",
       "1-sessions-Centralized-no-pre-training             91.2% 59.2% 37.8% 82.8%   \n",
       "2-sessions-Centralized-pre-training                90.1% 60.5% 71.2% 84.2%   \n",
       "3-sessions-Federated-no-pre-training               90.2% 56.3% 43.6% 71.1%   \n",
       "4-sessions-Federated-central-pre-training          90.9% 62.3% 75.3% 82.4%   \n",
       "5-sessions-Federated-federated-pre-training        90.7% 64.4% 67.4% 81.4%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 90.0% 57.0% 37.8% 77.9%   \n",
       "7-sessions-Federated-central-pre-training-perso... 92.4% 63.4% 77.1% 84.2%   \n",
       "8-sessions-Federated-federated-pre-training-per... 91.1% 63.1% 59.1% 83.1%   \n",
       "9-sessions-Federated-no-pre-training-local-models  90.3% 56.1% 37.9% 75.5%   \n",
       "10-sessions-Federated-central-pre-training-loca... 93.3% 63.2% 65.2% 85.0%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 90.8% 62.2% 59.1% 82.4%   \n",
       "\n",
       "                                                     107   109   115   120  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           64.5% 79.6% 66.4% 76.1%   \n",
       "0-sessions-Baseline-federated-pre-training         61.0% 72.3% 89.4% 73.7%   \n",
       "0-sessions-Baseline-random                         45.2% 28.1% 12.0% 34.8%   \n",
       "1-sessions-Centralized-no-pre-training             57.2% 72.1% 85.2% 54.6%   \n",
       "2-sessions-Centralized-pre-training                72.2% 79.4% 85.3% 65.6%   \n",
       "3-sessions-Federated-no-pre-training               61.8% 44.1% 81.3% 48.7%   \n",
       "4-sessions-Federated-central-pre-training          67.8% 76.4% 72.6% 63.1%   \n",
       "5-sessions-Federated-federated-pre-training        72.9% 71.4% 87.9% 63.7%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 60.4% 71.7% 88.0% 65.2%   \n",
       "7-sessions-Federated-central-pre-training-perso... 67.9% 79.4% 89.8% 71.3%   \n",
       "8-sessions-Federated-federated-pre-training-per... 66.2% 72.3% 89.7% 68.3%   \n",
       "9-sessions-Federated-no-pre-training-local-models  62.1% 71.5% 87.9% 65.0%   \n",
       "10-sessions-Federated-central-pre-training-loca... 69.0% 79.6% 89.4% 69.6%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 66.2% 72.3% 89.2% 67.2%   \n",
       "\n",
       "                                                    Weighted Mean  \\\n",
       "Experiment                                                          \n",
       "0-sessions-Baseline-central-pre-training                    73.4%   \n",
       "0-sessions-Baseline-federated-pre-training                  73.6%   \n",
       "0-sessions-Baseline-random                                  30.2%   \n",
       "1-sessions-Centralized-no-pre-training                      70.2%   \n",
       "2-sessions-Centralized-pre-training                         74.9%   \n",
       "3-sessions-Federated-no-pre-training                        68.3%   \n",
       "4-sessions-Federated-central-pre-training                   75.3%   \n",
       "5-sessions-Federated-federated-pre-training                 76.8%   \n",
       "6-sessions-Federated-no-pre-training-personaliz...          71.8%   \n",
       "7-sessions-Federated-central-pre-training-perso...          77.4%   \n",
       "8-sessions-Federated-federated-pre-training-per...          75.7%   \n",
       "9-sessions-Federated-no-pre-training-local-models           71.6%   \n",
       "10-sessions-Federated-central-pre-training-loca...          76.5%   \n",
       "11-sessions-Federated-federated-pre-training-lo...          75.2%   \n",
       "\n",
       "                                                    Weighted SD  Mean    SD  \n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training                  12.2% 73.0% 11.9%  \n",
       "0-sessions-Baseline-federated-pre-training                12.7% 73.4% 11.4%  \n",
       "0-sessions-Baseline-random                                15.3% 30.2% 16.6%  \n",
       "1-sessions-Centralized-no-pre-training                    15.9% 70.0% 15.6%  \n",
       "2-sessions-Centralized-pre-training                       13.6% 74.7% 10.7%  \n",
       "3-sessions-Federated-no-pre-training                      14.1% 66.7% 16.5%  \n",
       "4-sessions-Federated-central-pre-training                 12.2% 74.0% 11.4%  \n",
       "5-sessions-Federated-federated-pre-training               12.3% 75.7%  9.4%  \n",
       "6-sessions-Federated-no-pre-training-personaliz...        15.8% 71.1% 15.7%  \n",
       "7-sessions-Federated-central-pre-training-perso...        12.0% 77.2% 11.6%  \n",
       "8-sessions-Federated-federated-pre-training-per...        13.7% 75.4% 10.7%  \n",
       "9-sessions-Federated-no-pre-training-local-models         15.3% 70.8% 15.7%  \n",
       "10-sessions-Federated-central-pre-training-loca...        13.1% 76.2% 12.1%  \n",
       "11-sessions-Federated-federated-pre-training-lo...        13.9% 74.9% 10.6%  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '123 - Seed 123')\n",
    "results['Seed 123'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Seed 123']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>70.5%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>46.2%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>67.1%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>64.5%</td>\n",
       "      <td>76.9%</td>\n",
       "      <td>67.4%</td>\n",
       "      <td>76.7%</td>\n",
       "      <td>73.1%</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>12.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.8%</td>\n",
       "      <td>69.9%</td>\n",
       "      <td>86.2%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>90.4%</td>\n",
       "      <td>60.2%</td>\n",
       "      <td>63.0%</td>\n",
       "      <td>81.8%</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>76.7%</td>\n",
       "      <td>88.9%</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>74.8%</td>\n",
       "      <td>11.3%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>10.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-random</th>\n",
       "      <td>34.1%</td>\n",
       "      <td>20.7%</td>\n",
       "      <td>7.5%</td>\n",
       "      <td>36.1%</td>\n",
       "      <td>11.0%</td>\n",
       "      <td>48.9%</td>\n",
       "      <td>62.1%</td>\n",
       "      <td>22.3%</td>\n",
       "      <td>45.2%</td>\n",
       "      <td>28.1%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>34.8%</td>\n",
       "      <td>30.2%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>30.2%</td>\n",
       "      <td>16.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>75.0%</td>\n",
       "      <td>61.9%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>80.1%</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>48.8%</td>\n",
       "      <td>81.4%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>82.9%</td>\n",
       "      <td>67.6%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>11.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>81.0%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>76.4%</td>\n",
       "      <td>46.2%</td>\n",
       "      <td>93.2%</td>\n",
       "      <td>62.7%</td>\n",
       "      <td>68.8%</td>\n",
       "      <td>84.3%</td>\n",
       "      <td>70.4%</td>\n",
       "      <td>78.2%</td>\n",
       "      <td>89.7%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>75.1%</td>\n",
       "      <td>13.4%</td>\n",
       "      <td>75.4%</td>\n",
       "      <td>12.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>74.3%</td>\n",
       "      <td>61.7%</td>\n",
       "      <td>86.7%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>79.8%</td>\n",
       "      <td>59.6%</td>\n",
       "      <td>51.6%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>63.7%</td>\n",
       "      <td>38.3%</td>\n",
       "      <td>75.3%</td>\n",
       "      <td>43.7%</td>\n",
       "      <td>65.3%</td>\n",
       "      <td>14.7%</td>\n",
       "      <td>62.7%</td>\n",
       "      <td>14.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>71.9%</td>\n",
       "      <td>77.9%</td>\n",
       "      <td>90.6%</td>\n",
       "      <td>46.2%</td>\n",
       "      <td>91.6%</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>63.8%</td>\n",
       "      <td>83.6%</td>\n",
       "      <td>70.8%</td>\n",
       "      <td>73.4%</td>\n",
       "      <td>71.1%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>11.8%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>12.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>71.6%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>90.2%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>91.8%</td>\n",
       "      <td>63.7%</td>\n",
       "      <td>62.6%</td>\n",
       "      <td>78.3%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>69.2%</td>\n",
       "      <td>82.7%</td>\n",
       "      <td>68.0%</td>\n",
       "      <td>75.5%</td>\n",
       "      <td>11.6%</td>\n",
       "      <td>74.2%</td>\n",
       "      <td>9.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6-sessions-Federated-no-pre-training-personalization</th>\n",
       "      <td>73.8%</td>\n",
       "      <td>61.9%</td>\n",
       "      <td>92.3%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>49.4%</td>\n",
       "      <td>71.4%</td>\n",
       "      <td>60.7%</td>\n",
       "      <td>71.6%</td>\n",
       "      <td>87.2%</td>\n",
       "      <td>64.8%</td>\n",
       "      <td>70.3%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>68.9%</td>\n",
       "      <td>12.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-sessions-Federated-central-pre-training-personalization</th>\n",
       "      <td>81.7%</td>\n",
       "      <td>77.8%</td>\n",
       "      <td>83.8%</td>\n",
       "      <td>46.2%</td>\n",
       "      <td>92.1%</td>\n",
       "      <td>62.6%</td>\n",
       "      <td>73.2%</td>\n",
       "      <td>83.4%</td>\n",
       "      <td>68.1%</td>\n",
       "      <td>78.2%</td>\n",
       "      <td>90.2%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>12.2%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>12.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8-sessions-Federated-federated-pre-training-personalization</th>\n",
       "      <td>81.9%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>89.1%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>90.7%</td>\n",
       "      <td>62.9%</td>\n",
       "      <td>60.4%</td>\n",
       "      <td>83.1%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>77.0%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>13.1%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>11.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-sessions-Federated-no-pre-training-local-models</th>\n",
       "      <td>73.8%</td>\n",
       "      <td>61.9%</td>\n",
       "      <td>92.0%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>79.7%</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>49.2%</td>\n",
       "      <td>70.1%</td>\n",
       "      <td>60.2%</td>\n",
       "      <td>71.4%</td>\n",
       "      <td>87.0%</td>\n",
       "      <td>64.6%</td>\n",
       "      <td>70.1%</td>\n",
       "      <td>15.7%</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>12.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-sessions-Federated-central-pre-training-local-models</th>\n",
       "      <td>84.7%</td>\n",
       "      <td>77.8%</td>\n",
       "      <td>81.6%</td>\n",
       "      <td>46.2%</td>\n",
       "      <td>91.8%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>62.3%</td>\n",
       "      <td>83.7%</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>78.2%</td>\n",
       "      <td>89.8%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>13.2%</td>\n",
       "      <td>74.8%</td>\n",
       "      <td>13.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-sessions-Federated-federated-pre-training-local-models</th>\n",
       "      <td>80.2%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>87.7%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>90.9%</td>\n",
       "      <td>60.9%</td>\n",
       "      <td>56.5%</td>\n",
       "      <td>81.8%</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>77.0%</td>\n",
       "      <td>89.8%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>74.8%</td>\n",
       "      <td>13.6%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>11.7%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      43    48    52    59  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           70.5% 78.1% 91.7% 46.2%   \n",
       "0-sessions-Baseline-federated-pre-training         66.8% 69.9% 86.2% 65.8%   \n",
       "0-sessions-Baseline-random                         34.1% 20.7%  7.5% 36.1%   \n",
       "1-sessions-Centralized-no-pre-training             75.0% 61.9% 78.1% 54.1%   \n",
       "2-sessions-Centralized-pre-training                81.0% 77.7% 76.4% 46.2%   \n",
       "3-sessions-Federated-no-pre-training               74.3% 61.7% 86.7% 54.1%   \n",
       "4-sessions-Federated-central-pre-training          71.9% 77.9% 90.6% 46.2%   \n",
       "5-sessions-Federated-federated-pre-training        71.6% 72.4% 90.2% 65.8%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 73.8% 61.9% 92.3% 54.1%   \n",
       "7-sessions-Federated-central-pre-training-perso... 81.7% 77.8% 83.8% 46.2%   \n",
       "8-sessions-Federated-federated-pre-training-per... 81.9% 72.5% 89.1% 65.8%   \n",
       "9-sessions-Federated-no-pre-training-local-models  73.8% 61.9% 92.0% 54.1%   \n",
       "10-sessions-Federated-central-pre-training-loca... 84.7% 77.8% 81.6% 46.2%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 80.2% 72.5% 87.7% 65.8%   \n",
       "\n",
       "                                                      64    80    92    96  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           90.5% 60.5% 67.1% 79.3%   \n",
       "0-sessions-Baseline-federated-pre-training         90.4% 60.2% 63.0% 81.8%   \n",
       "0-sessions-Baseline-random                         11.0% 48.9% 62.1% 22.3%   \n",
       "1-sessions-Centralized-no-pre-training             80.1% 60.6% 48.8% 81.4%   \n",
       "2-sessions-Centralized-pre-training                93.2% 62.7% 68.8% 84.3%   \n",
       "3-sessions-Federated-no-pre-training               79.8% 59.6% 51.6% 63.9%   \n",
       "4-sessions-Federated-central-pre-training          91.6% 62.5% 63.8% 83.6%   \n",
       "5-sessions-Federated-federated-pre-training        91.8% 63.7% 62.6% 78.3%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 78.8% 60.6% 49.4% 71.4%   \n",
       "7-sessions-Federated-central-pre-training-perso... 92.1% 62.6% 73.2% 83.4%   \n",
       "8-sessions-Federated-federated-pre-training-per... 90.7% 62.9% 60.4% 83.1%   \n",
       "9-sessions-Federated-no-pre-training-local-models  79.7% 60.6% 49.2% 70.1%   \n",
       "10-sessions-Federated-central-pre-training-loca... 91.8% 60.5% 62.3% 83.7%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 90.9% 60.9% 56.5% 81.8%   \n",
       "\n",
       "                                                     107   109   115   120  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           64.5% 76.9% 67.4% 76.7%   \n",
       "0-sessions-Baseline-federated-pre-training         68.7% 76.7% 88.9% 75.0%   \n",
       "0-sessions-Baseline-random                         45.2% 28.1% 12.0% 34.8%   \n",
       "1-sessions-Centralized-no-pre-training             60.5% 71.8% 82.9% 67.6%   \n",
       "2-sessions-Centralized-pre-training                70.4% 78.2% 89.7% 75.9%   \n",
       "3-sessions-Federated-no-pre-training               63.7% 38.3% 75.3% 43.7%   \n",
       "4-sessions-Federated-central-pre-training          70.8% 73.4% 71.1% 70.0%   \n",
       "5-sessions-Federated-federated-pre-training        74.6% 69.2% 82.7% 68.0%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 60.7% 71.6% 87.2% 64.8%   \n",
       "7-sessions-Federated-central-pre-training-perso... 68.1% 78.2% 90.2% 73.5%   \n",
       "8-sessions-Federated-federated-pre-training-per... 68.5% 77.0% 90.5% 66.5%   \n",
       "9-sessions-Federated-no-pre-training-local-models  60.2% 71.4% 87.0% 64.6%   \n",
       "10-sessions-Federated-central-pre-training-loca... 66.5% 78.2% 89.8% 73.9%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 66.5% 77.0% 89.8% 65.2%   \n",
       "\n",
       "                                                    Weighted Mean  \\\n",
       "Experiment                                                          \n",
       "0-sessions-Baseline-central-pre-training                    73.1%   \n",
       "0-sessions-Baseline-federated-pre-training                  74.8%   \n",
       "0-sessions-Baseline-random                                  30.2%   \n",
       "1-sessions-Centralized-no-pre-training                      69.0%   \n",
       "2-sessions-Centralized-pre-training                         75.1%   \n",
       "3-sessions-Federated-no-pre-training                        65.3%   \n",
       "4-sessions-Federated-central-pre-training                   74.3%   \n",
       "5-sessions-Federated-federated-pre-training                 75.5%   \n",
       "6-sessions-Federated-no-pre-training-personaliz...          70.3%   \n",
       "7-sessions-Federated-central-pre-training-perso...          75.9%   \n",
       "8-sessions-Federated-federated-pre-training-per...          76.1%   \n",
       "9-sessions-Federated-no-pre-training-local-models           70.1%   \n",
       "10-sessions-Federated-central-pre-training-loca...          74.3%   \n",
       "11-sessions-Federated-federated-pre-training-lo...          74.8%   \n",
       "\n",
       "                                                    Weighted SD  Mean    SD  \n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training                  12.5% 72.5% 12.7%  \n",
       "0-sessions-Baseline-federated-pre-training                11.3% 74.4% 10.4%  \n",
       "0-sessions-Baseline-random                                15.3% 30.2% 16.6%  \n",
       "1-sessions-Centralized-no-pre-training                    15.8% 68.5% 11.4%  \n",
       "2-sessions-Centralized-pre-training                       13.4% 75.4% 12.5%  \n",
       "3-sessions-Federated-no-pre-training                      14.7% 62.7% 14.5%  \n",
       "4-sessions-Federated-central-pre-training                 11.8% 72.8% 12.5%  \n",
       "5-sessions-Federated-federated-pre-training               11.6% 74.2%  9.7%  \n",
       "6-sessions-Federated-no-pre-training-personaliz...        15.8% 68.9% 12.9%  \n",
       "7-sessions-Federated-central-pre-training-perso...        12.2% 75.9% 12.7%  \n",
       "8-sessions-Federated-federated-pre-training-per...        13.1% 75.7% 11.1%  \n",
       "9-sessions-Federated-no-pre-training-local-models         15.7% 68.7% 12.9%  \n",
       "10-sessions-Federated-central-pre-training-loca...        13.2% 74.8% 13.5%  \n",
       "11-sessions-Federated-federated-pre-training-lo...        13.6% 74.6% 11.7%  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '124 - Seed 124')\n",
    "results['Seed 124'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Seed 124']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-central-pre-training</th>\n",
       "      <td>67.8%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>92.3%</td>\n",
       "      <td>48.2%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>67.0%</td>\n",
       "      <td>78.3%</td>\n",
       "      <td>64.6%</td>\n",
       "      <td>74.6%</td>\n",
       "      <td>67.0%</td>\n",
       "      <td>73.5%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>12.1%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>12.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-federated-pre-training</th>\n",
       "      <td>66.2%</td>\n",
       "      <td>78.5%</td>\n",
       "      <td>79.2%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>90.3%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>60.8%</td>\n",
       "      <td>79.9%</td>\n",
       "      <td>66.1%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>88.3%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>11.8%</td>\n",
       "      <td>73.4%</td>\n",
       "      <td>10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-sessions-Baseline-random</th>\n",
       "      <td>34.1%</td>\n",
       "      <td>20.9%</td>\n",
       "      <td>7.7%</td>\n",
       "      <td>36.1%</td>\n",
       "      <td>11.7%</td>\n",
       "      <td>48.4%</td>\n",
       "      <td>62.1%</td>\n",
       "      <td>23.2%</td>\n",
       "      <td>45.2%</td>\n",
       "      <td>28.1%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>35.4%</td>\n",
       "      <td>30.3%</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>30.4%</td>\n",
       "      <td>16.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-sessions-Centralized-no-pre-training</th>\n",
       "      <td>65.9%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>82.7%</td>\n",
       "      <td>56.9%</td>\n",
       "      <td>83.8%</td>\n",
       "      <td>50.7%</td>\n",
       "      <td>44.2%</td>\n",
       "      <td>85.6%</td>\n",
       "      <td>55.2%</td>\n",
       "      <td>69.2%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>14.9%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>15.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>79.8%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>80.4%</td>\n",
       "      <td>48.2%</td>\n",
       "      <td>91.8%</td>\n",
       "      <td>63.7%</td>\n",
       "      <td>72.2%</td>\n",
       "      <td>84.0%</td>\n",
       "      <td>69.5%</td>\n",
       "      <td>76.6%</td>\n",
       "      <td>89.5%</td>\n",
       "      <td>63.3%</td>\n",
       "      <td>75.6%</td>\n",
       "      <td>13.6%</td>\n",
       "      <td>74.8%</td>\n",
       "      <td>12.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-sessions-Federated-no-pre-training</th>\n",
       "      <td>69.3%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>83.6%</td>\n",
       "      <td>56.9%</td>\n",
       "      <td>83.1%</td>\n",
       "      <td>54.9%</td>\n",
       "      <td>54.9%</td>\n",
       "      <td>69.9%</td>\n",
       "      <td>64.1%</td>\n",
       "      <td>50.2%</td>\n",
       "      <td>82.4%</td>\n",
       "      <td>58.7%</td>\n",
       "      <td>67.8%</td>\n",
       "      <td>13.0%</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>12.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>69.6%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>48.2%</td>\n",
       "      <td>91.2%</td>\n",
       "      <td>58.9%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>85.7%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>62.2%</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>74.0%</td>\n",
       "      <td>10.9%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>12.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-sessions-Federated-federated-pre-training</th>\n",
       "      <td>71.3%</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>86.1%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>61.6%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>78.2%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>82.1%</td>\n",
       "      <td>57.6%</td>\n",
       "      <td>75.6%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>74.8%</td>\n",
       "      <td>9.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6-sessions-Federated-no-pre-training-personalization</th>\n",
       "      <td>66.8%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>92.4%</td>\n",
       "      <td>56.9%</td>\n",
       "      <td>83.5%</td>\n",
       "      <td>57.2%</td>\n",
       "      <td>44.8%</td>\n",
       "      <td>77.0%</td>\n",
       "      <td>60.1%</td>\n",
       "      <td>68.9%</td>\n",
       "      <td>87.7%</td>\n",
       "      <td>65.4%</td>\n",
       "      <td>70.9%</td>\n",
       "      <td>15.5%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>14.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-sessions-Federated-central-pre-training-personalization</th>\n",
       "      <td>79.8%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>88.2%</td>\n",
       "      <td>48.2%</td>\n",
       "      <td>91.6%</td>\n",
       "      <td>60.1%</td>\n",
       "      <td>74.4%</td>\n",
       "      <td>82.9%</td>\n",
       "      <td>67.0%</td>\n",
       "      <td>76.3%</td>\n",
       "      <td>90.4%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>75.8%</td>\n",
       "      <td>12.7%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>12.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8-sessions-Federated-federated-pre-training-personalization</th>\n",
       "      <td>79.2%</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>89.5%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>92.0%</td>\n",
       "      <td>61.9%</td>\n",
       "      <td>64.2%</td>\n",
       "      <td>82.3%</td>\n",
       "      <td>66.7%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>89.5%</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>76.3%</td>\n",
       "      <td>13.4%</td>\n",
       "      <td>76.4%</td>\n",
       "      <td>10.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-sessions-Federated-no-pre-training-local-models</th>\n",
       "      <td>65.7%</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>92.5%</td>\n",
       "      <td>56.9%</td>\n",
       "      <td>83.7%</td>\n",
       "      <td>53.1%</td>\n",
       "      <td>44.2%</td>\n",
       "      <td>74.5%</td>\n",
       "      <td>59.9%</td>\n",
       "      <td>69.0%</td>\n",
       "      <td>80.1%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>69.2%</td>\n",
       "      <td>15.9%</td>\n",
       "      <td>68.6%</td>\n",
       "      <td>14.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-sessions-Federated-central-pre-training-local-models</th>\n",
       "      <td>78.0%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>86.6%</td>\n",
       "      <td>48.2%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>58.8%</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>82.9%</td>\n",
       "      <td>68.3%</td>\n",
       "      <td>76.4%</td>\n",
       "      <td>90.3%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>74.8%</td>\n",
       "      <td>13.2%</td>\n",
       "      <td>74.5%</td>\n",
       "      <td>13.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-sessions-Federated-federated-pre-training-local-models</th>\n",
       "      <td>81.1%</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>92.4%</td>\n",
       "      <td>60.2%</td>\n",
       "      <td>61.5%</td>\n",
       "      <td>82.1%</td>\n",
       "      <td>68.0%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>68.0%</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>13.8%</td>\n",
       "      <td>76.4%</td>\n",
       "      <td>10.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      43    48    52    59  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           67.8% 79.3% 92.3% 48.2%   \n",
       "0-sessions-Baseline-federated-pre-training         66.2% 78.5% 79.2% 71.9%   \n",
       "0-sessions-Baseline-random                         34.1% 20.9%  7.7% 36.1%   \n",
       "1-sessions-Centralized-no-pre-training             65.9% 79.1% 82.7% 56.9%   \n",
       "2-sessions-Centralized-pre-training                79.8% 79.1% 80.4% 48.2%   \n",
       "3-sessions-Federated-no-pre-training               69.3% 79.1% 83.6% 56.9%   \n",
       "4-sessions-Federated-central-pre-training          69.6% 79.1% 90.5% 48.2%   \n",
       "5-sessions-Federated-federated-pre-training        71.3% 79.4% 86.1% 71.9%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 66.8% 79.1% 92.4% 56.9%   \n",
       "7-sessions-Federated-central-pre-training-perso... 79.8% 79.0% 88.2% 48.2%   \n",
       "8-sessions-Federated-federated-pre-training-per... 79.2% 79.4% 89.5% 71.9%   \n",
       "9-sessions-Federated-no-pre-training-local-models  65.7% 79.1% 92.5% 56.9%   \n",
       "10-sessions-Federated-central-pre-training-loca... 78.0% 79.0% 86.6% 48.2%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 81.1% 79.4% 89.3% 71.9%   \n",
       "\n",
       "                                                      64    80    92    96  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           90.5% 55.3% 67.0% 78.3%   \n",
       "0-sessions-Baseline-federated-pre-training         90.3% 54.1% 60.8% 79.9%   \n",
       "0-sessions-Baseline-random                         11.7% 48.4% 62.1% 23.2%   \n",
       "1-sessions-Centralized-no-pre-training             83.8% 50.7% 44.2% 85.6%   \n",
       "2-sessions-Centralized-pre-training                91.8% 63.7% 72.2% 84.0%   \n",
       "3-sessions-Federated-no-pre-training               83.1% 54.9% 54.9% 69.9%   \n",
       "4-sessions-Federated-central-pre-training          91.2% 58.9% 71.5% 85.7%   \n",
       "5-sessions-Federated-federated-pre-training        91.9% 61.6% 72.8% 78.2%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 83.5% 57.2% 44.8% 77.0%   \n",
       "7-sessions-Federated-central-pre-training-perso... 91.6% 60.1% 74.4% 82.9%   \n",
       "8-sessions-Federated-federated-pre-training-per... 92.0% 61.9% 64.2% 82.3%   \n",
       "9-sessions-Federated-no-pre-training-local-models  83.7% 53.1% 44.2% 74.5%   \n",
       "10-sessions-Federated-central-pre-training-loca... 91.7% 58.8% 63.9% 82.9%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 92.4% 60.2% 61.5% 82.1%   \n",
       "\n",
       "                                                     107   109   115   120  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training           64.6% 74.6% 67.0% 73.5%   \n",
       "0-sessions-Baseline-federated-pre-training         66.1% 73.8% 88.3% 71.5%   \n",
       "0-sessions-Baseline-random                         45.2% 28.1% 12.0% 35.4%   \n",
       "1-sessions-Centralized-no-pre-training             55.2% 69.2% 89.3% 65.2%   \n",
       "2-sessions-Centralized-pre-training                69.5% 76.6% 89.5% 63.3%   \n",
       "3-sessions-Federated-no-pre-training               64.1% 50.2% 82.4% 58.7%   \n",
       "4-sessions-Federated-central-pre-training          71.5% 62.2% 75.0% 72.0%   \n",
       "5-sessions-Federated-federated-pre-training        72.0% 72.4% 82.1% 57.6%   \n",
       "6-sessions-Federated-no-pre-training-personaliz... 60.1% 68.9% 87.7% 65.4%   \n",
       "7-sessions-Federated-central-pre-training-perso... 67.0% 76.3% 90.4% 70.2%   \n",
       "8-sessions-Federated-federated-pre-training-per... 66.7% 73.7% 89.5% 66.5%   \n",
       "9-sessions-Federated-no-pre-training-local-models  59.9% 69.0% 80.1% 65.2%   \n",
       "10-sessions-Federated-central-pre-training-loca... 68.3% 76.4% 90.3% 70.0%   \n",
       "11-sessions-Federated-federated-pre-training-lo... 68.0% 73.7% 89.3% 68.0%   \n",
       "\n",
       "                                                    Weighted Mean  \\\n",
       "Experiment                                                          \n",
       "0-sessions-Baseline-central-pre-training                    71.9%   \n",
       "0-sessions-Baseline-federated-pre-training                  72.4%   \n",
       "0-sessions-Baseline-random                                  30.3%   \n",
       "1-sessions-Centralized-no-pre-training                      68.7%   \n",
       "2-sessions-Centralized-pre-training                         75.6%   \n",
       "3-sessions-Federated-no-pre-training                        67.8%   \n",
       "4-sessions-Federated-central-pre-training                   74.0%   \n",
       "5-sessions-Federated-federated-pre-training                 75.6%   \n",
       "6-sessions-Federated-no-pre-training-personaliz...          70.9%   \n",
       "7-sessions-Federated-central-pre-training-perso...          75.8%   \n",
       "8-sessions-Federated-federated-pre-training-per...          76.3%   \n",
       "9-sessions-Federated-no-pre-training-local-models           69.2%   \n",
       "10-sessions-Federated-central-pre-training-loca...          74.8%   \n",
       "11-sessions-Federated-federated-pre-training-lo...          76.0%   \n",
       "\n",
       "                                                    Weighted SD  Mean    SD  \n",
       "Experiment                                                                   \n",
       "0-sessions-Baseline-central-pre-training                  12.1% 71.5% 12.9%  \n",
       "0-sessions-Baseline-federated-pre-training                11.8% 73.4% 10.7%  \n",
       "0-sessions-Baseline-random                                15.2% 30.4% 16.4%  \n",
       "1-sessions-Centralized-no-pre-training                    14.9% 69.0% 15.1%  \n",
       "2-sessions-Centralized-pre-training                       13.6% 74.8% 12.3%  \n",
       "3-sessions-Federated-no-pre-training                      13.0% 67.3% 12.4%  \n",
       "4-sessions-Federated-central-pre-training                 10.9% 73.0% 12.8%  \n",
       "5-sessions-Federated-federated-pre-training               12.0% 74.8%  9.6%  \n",
       "6-sessions-Federated-no-pre-training-personaliz...        15.5% 70.0% 14.3%  \n",
       "7-sessions-Federated-central-pre-training-perso...        12.7% 75.7% 12.8%  \n",
       "8-sessions-Federated-federated-pre-training-per...        13.4% 76.4% 10.5%  \n",
       "9-sessions-Federated-no-pre-training-local-models         15.9% 68.6% 14.0%  \n",
       "10-sessions-Federated-central-pre-training-loca...        13.2% 74.5% 13.2%  \n",
       "11-sessions-Federated-federated-pre-training-lo...        13.8% 76.4% 10.9%  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '125 - Seed 125')\n",
    "results['Seed 125'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['Seed 125']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-unbalanced-Baseline-central-pre-training</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-unbalanced-Baseline-federated-pre-training</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-unbalanced-Centralized-no-pre-training</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-unbalanced-Centralized-pre-training</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-unbalanced-Federated-no-pre-training</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-unbalanced-Federated-central-pre-training</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-unbalanced-Federated-federated-pre-training</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6-unbalanced-Federated-no-pre-training-personalization</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-unbalanced-Federated-central-pre-training-personalization</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8-unbalanced-Federated-federated-pre-training-personalization</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-unbalanced-Federated-no-pre-training-local-models</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-unbalanced-Federated-central-pre-training-local-models</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-unbalanced-Federated-federated-pre-training-local-models</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    43  48  52  59  64  80  \\\n",
       "Experiment                                                                   \n",
       "0-unbalanced-Baseline-central-pre-training         0.7 0.8 0.9 0.4 0.9 0.6   \n",
       "0-unbalanced-Baseline-federated-pre-training       0.7 0.7 0.9 0.7 0.9 0.6   \n",
       "1-unbalanced-Centralized-no-pre-training           nan 0.9 nan 0.9 1.0 0.8   \n",
       "2-unbalanced-Centralized-pre-training              nan 0.9 nan 0.9 0.9 0.8   \n",
       "3-unbalanced-Federated-no-pre-training             nan 0.9 nan 0.3 0.9 0.8   \n",
       "4-unbalanced-Federated-central-pre-training        nan 0.9 nan 0.2 0.9 0.8   \n",
       "5-unbalanced-Federated-federated-pre-training      nan 0.9 nan 0.3 0.9 0.8   \n",
       "6-unbalanced-Federated-no-pre-training-personal... nan 0.9 nan 0.9 0.9 0.8   \n",
       "7-unbalanced-Federated-central-pre-training-per... nan 0.9 nan 0.9 0.9 0.8   \n",
       "8-unbalanced-Federated-federated-pre-training-p... nan 0.9 nan 0.9 1.0 0.9   \n",
       "9-unbalanced-Federated-no-pre-training-local-mo... nan 0.9 nan 0.9 0.9 0.8   \n",
       "10-unbalanced-Federated-central-pre-training-lo... nan 0.9 nan 0.9 0.9 0.9   \n",
       "11-unbalanced-Federated-federated-pre-training-... nan 0.9 nan 0.9 0.9 0.9   \n",
       "\n",
       "                                                    92  96  107  109  115  \\\n",
       "Experiment                                                                  \n",
       "0-unbalanced-Baseline-central-pre-training         0.7 0.8  0.7  0.8  0.7   \n",
       "0-unbalanced-Baseline-federated-pre-training       0.6 0.8  0.6  0.7  0.9   \n",
       "1-unbalanced-Centralized-no-pre-training           0.8 nan  nan  0.9  nan   \n",
       "2-unbalanced-Centralized-pre-training              0.9 nan  nan  1.0  nan   \n",
       "3-unbalanced-Federated-no-pre-training             0.8 nan  nan  1.0  nan   \n",
       "4-unbalanced-Federated-central-pre-training        0.8 nan  nan  1.0  nan   \n",
       "5-unbalanced-Federated-federated-pre-training      0.8 nan  nan  0.9  nan   \n",
       "6-unbalanced-Federated-no-pre-training-personal... 0.9 nan  nan  0.9  nan   \n",
       "7-unbalanced-Federated-central-pre-training-per... 0.9 nan  nan  1.0  nan   \n",
       "8-unbalanced-Federated-federated-pre-training-p... 0.9 nan  nan  1.0  nan   \n",
       "9-unbalanced-Federated-no-pre-training-local-mo... 0.8 nan  nan  0.9  nan   \n",
       "10-unbalanced-Federated-central-pre-training-lo... 0.9 nan  nan  0.9  nan   \n",
       "11-unbalanced-Federated-federated-pre-training-... 1.0 nan  nan  1.0  nan   \n",
       "\n",
       "                                                    120  Weighted Mean  \\\n",
       "Experiment                                                               \n",
       "0-unbalanced-Baseline-central-pre-training          0.8            0.7   \n",
       "0-unbalanced-Baseline-federated-pre-training        0.7            0.7   \n",
       "1-unbalanced-Centralized-no-pre-training            nan            0.9   \n",
       "2-unbalanced-Centralized-pre-training               nan            0.9   \n",
       "3-unbalanced-Federated-no-pre-training              nan            0.8   \n",
       "4-unbalanced-Federated-central-pre-training         nan            0.8   \n",
       "5-unbalanced-Federated-federated-pre-training       nan            0.8   \n",
       "6-unbalanced-Federated-no-pre-training-personal...  nan            0.9   \n",
       "7-unbalanced-Federated-central-pre-training-per...  nan            0.9   \n",
       "8-unbalanced-Federated-federated-pre-training-p...  nan            0.9   \n",
       "9-unbalanced-Federated-no-pre-training-local-mo...  nan            0.9   \n",
       "10-unbalanced-Federated-central-pre-training-lo...  nan            0.9   \n",
       "11-unbalanced-Federated-federated-pre-training-...  nan            0.9   \n",
       "\n",
       "                                                    Weighted SD  Mean  SD  \n",
       "Experiment                                                                 \n",
       "0-unbalanced-Baseline-central-pre-training                  0.1   0.7 0.1  \n",
       "0-unbalanced-Baseline-federated-pre-training                0.1   0.7 0.1  \n",
       "1-unbalanced-Centralized-no-pre-training                    0.0   0.9 0.1  \n",
       "2-unbalanced-Centralized-pre-training                       0.0   0.9 0.0  \n",
       "3-unbalanced-Federated-no-pre-training                      0.0   0.8 0.2  \n",
       "4-unbalanced-Federated-central-pre-training                 0.0   0.8 0.3  \n",
       "5-unbalanced-Federated-federated-pre-training               0.0   0.8 0.2  \n",
       "6-unbalanced-Federated-no-pre-training-personal...          0.0   0.9 0.0  \n",
       "7-unbalanced-Federated-central-pre-training-per...          0.0   0.9 0.0  \n",
       "8-unbalanced-Federated-federated-pre-training-p...          0.0   0.9 0.0  \n",
       "9-unbalanced-Federated-no-pre-training-local-mo...          0.0   0.9 0.1  \n",
       "10-unbalanced-Federated-central-pre-training-lo...          0.0   0.9 0.0  \n",
       "11-unbalanced-Federated-federated-pre-training-...          0.0   0.9 0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '123 - Sd 123 - Unbalanced')\n",
    "results['123 - Sd 123 - Unbalanced'] = rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)\n",
    "results['123 - Sd 123 - Unbalanced']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Weighted Mean</th>\n",
       "      <th>Weighted SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-sessions-centralized-pre-training</th>\n",
       "      <td>67.8%</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>92.4%</td>\n",
       "      <td>49.0%</td>\n",
       "      <td>90.5%</td>\n",
       "      <td>59.2%</td>\n",
       "      <td>69.5%</td>\n",
       "      <td>78.5%</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>74.7%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>11.9%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>12.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-sessions-Centralized-pre-training</th>\n",
       "      <td>78.1%</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>86.5%</td>\n",
       "      <td>49.0%</td>\n",
       "      <td>92.1%</td>\n",
       "      <td>63.1%</td>\n",
       "      <td>64.8%</td>\n",
       "      <td>84.4%</td>\n",
       "      <td>67.5%</td>\n",
       "      <td>78.7%</td>\n",
       "      <td>89.3%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>12.9%</td>\n",
       "      <td>75.4%</td>\n",
       "      <td>12.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-sessions-Federated-central-pre-training</th>\n",
       "      <td>69.5%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>49.0%</td>\n",
       "      <td>91.3%</td>\n",
       "      <td>62.4%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>83.5%</td>\n",
       "      <td>72.8%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>78.6%</td>\n",
       "      <td>63.1%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>12.1%</td>\n",
       "      <td>74.1%</td>\n",
       "      <td>12.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-sessions-Federated-central-pre-training-personalization</th>\n",
       "      <td>77.7%</td>\n",
       "      <td>78.7%</td>\n",
       "      <td>88.9%</td>\n",
       "      <td>49.0%</td>\n",
       "      <td>92.9%</td>\n",
       "      <td>63.8%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>85.4%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>90.4%</td>\n",
       "      <td>72.4%</td>\n",
       "      <td>77.7%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>77.0%</td>\n",
       "      <td>12.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-sessions-Federated-central-pre-training-local-models</th>\n",
       "      <td>79.9%</td>\n",
       "      <td>78.7%</td>\n",
       "      <td>89.1%</td>\n",
       "      <td>49.0%</td>\n",
       "      <td>92.3%</td>\n",
       "      <td>63.2%</td>\n",
       "      <td>61.3%</td>\n",
       "      <td>84.4%</td>\n",
       "      <td>69.4%</td>\n",
       "      <td>78.7%</td>\n",
       "      <td>90.2%</td>\n",
       "      <td>73.0%</td>\n",
       "      <td>76.4%</td>\n",
       "      <td>13.0%</td>\n",
       "      <td>75.8%</td>\n",
       "      <td>13.1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      43    48    52    59  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-centralized-pre-training                67.8% 78.9% 92.4% 49.0%   \n",
       "2-sessions-Centralized-pre-training                78.1% 78.9% 86.5% 49.0%   \n",
       "4-sessions-Federated-central-pre-training          69.5% 79.0% 91.9% 49.0%   \n",
       "7-sessions-Federated-central-pre-training-perso... 77.7% 78.7% 88.9% 49.0%   \n",
       "10-sessions-Federated-central-pre-training-loca... 79.9% 78.7% 89.1% 49.0%   \n",
       "\n",
       "                                                      64    80    92    96  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-centralized-pre-training                90.5% 59.2% 69.5% 78.5%   \n",
       "2-sessions-Centralized-pre-training                92.1% 63.1% 64.8% 84.4%   \n",
       "4-sessions-Federated-central-pre-training          91.3% 62.4% 69.7% 83.5%   \n",
       "7-sessions-Federated-central-pre-training-perso... 92.9% 63.8% 74.3% 85.4%   \n",
       "10-sessions-Federated-central-pre-training-loca... 92.3% 63.2% 61.3% 84.4%   \n",
       "\n",
       "                                                     107   109   115   120  \\\n",
       "Experiment                                                                   \n",
       "0-sessions-centralized-pre-training                65.2% 79.0% 74.7% 71.9%   \n",
       "2-sessions-Centralized-pre-training                67.5% 78.7% 89.3% 72.0%   \n",
       "4-sessions-Federated-central-pre-training          72.8% 78.8% 78.6% 63.1%   \n",
       "7-sessions-Federated-central-pre-training-perso... 71.5% 78.8% 90.4% 72.4%   \n",
       "10-sessions-Federated-central-pre-training-loca... 69.4% 78.7% 90.2% 73.0%   \n",
       "\n",
       "                                                    Weighted Mean  \\\n",
       "Experiment                                                          \n",
       "0-sessions-centralized-pre-training                         73.9%   \n",
       "2-sessions-Centralized-pre-training                         75.9%   \n",
       "4-sessions-Federated-central-pre-training                   76.1%   \n",
       "7-sessions-Federated-central-pre-training-perso...          77.7%   \n",
       "10-sessions-Federated-central-pre-training-loca...          76.4%   \n",
       "\n",
       "                                                    Weighted SD  Mean    SD  \n",
       "Experiment                                                                   \n",
       "0-sessions-centralized-pre-training                       11.9% 73.0% 12.3%  \n",
       "2-sessions-Centralized-pre-training                       12.9% 75.4% 12.6%  \n",
       "4-sessions-Federated-central-pre-training                 12.1% 74.1% 12.4%  \n",
       "7-sessions-Federated-central-pre-training-perso...        12.0% 77.0% 12.3%  \n",
       "10-sessions-Federated-central-pre-training-loca...        13.0% 75.8% 13.1%  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '123 - Sd 123 - Sessions NEW')\n",
    "results['Seed 123'] = rE.results_table(EXPERIMENT, 'accuracy', view_by, subjects, pivot)\n",
    "results['Seed 123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(module_path, 'BCDL.csv'))\n",
    "df['True Label'] = np.minimum(df['True Label'], 1)\n",
    "df['BCDL_pred'] = (df['BCDL'] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139069,  25551],\n",
       "       [ 14463,  16367]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df['True Label'], df['BCDL_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(os.path.join(module_path, 'Results/Thesis/123 - Seed 123/2019-08-30-144543_PAIN_0-sessions-Baseline-central-pre-training_TEST.csv'))\n",
    "df_2 = pd.read_csv(os.path.join(module_path, 'Results/Thesis/123 - Sd 123 - Sessions NEW/2020-01-26-010842_PAIN_0-sessions-centralized-pre-training_TEST.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Session</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>loss</th>\n",
       "      <th>pr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_96_false_negatives</th>\n",
       "      <th>subject_96_false_positives</th>\n",
       "      <th>subject_96_loss</th>\n",
       "      <th>subject_96_pr</th>\n",
       "      <th>subject_96_precision</th>\n",
       "      <th>subject_96_recall</th>\n",
       "      <th>subject_96_true_negatives</th>\n",
       "      <th>subject_96_true_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>true_positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>734.00</td>\n",
       "      <td>1,413.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>835.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7,379.00</td>\n",
       "      <td>1,842.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>943.00</td>\n",
       "      <td>1,588.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,223.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7,168.00</td>\n",
       "      <td>673.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>296.00</td>\n",
       "      <td>1,166.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6,530.00</td>\n",
       "      <td>492.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1,523.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>103.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>816.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5,753.00</td>\n",
       "      <td>1,961.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.65</td>\n",
       "      <td>913.00</td>\n",
       "      <td>1,107.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,295.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6,273.00</td>\n",
       "      <td>183.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>581.00</td>\n",
       "      <td>608.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>492.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>616.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>4,244.00</td>\n",
       "      <td>239.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>155.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>863.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3,633.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>203.00</td>\n",
       "      <td>141.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,052.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3,059.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>66.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1,677.00</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows  132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Session  accuracy  auc  false_negatives  false_positives  loss  \\\n",
       "0           0        1      0.81 0.87           734.00         1,413.00  0.47   \n",
       "1           0        2      0.76 0.76           943.00         1,588.00  0.65   \n",
       "2           0        3      0.83 0.84           296.00         1,166.00  0.44   \n",
       "3           0        4      0.76 0.83           899.00         1,523.00  0.67   \n",
       "4           0        5      0.76 0.65           913.00         1,107.00  0.69   \n",
       "5           0        6      0.79 0.63           581.00           608.00  0.67   \n",
       "6           0        7      0.96 0.00             0.00           155.00  0.11   \n",
       "7           0        8      0.90 0.58           203.00           141.00  0.50   \n",
       "8           0        9      0.96 0.92            66.00             7.00  0.15   \n",
       "\n",
       "    pr  precision  recall  ...  subject_96_false_negatives  \\\n",
       "0 0.66       0.57    0.72  ...                        0.00   \n",
       "1 0.32       0.30    0.42  ...                        0.00   \n",
       "2 0.27       0.30    0.62  ...                        0.00   \n",
       "3 0.67       0.56    0.69  ...                      103.00   \n",
       "4 0.17       0.14    0.17  ...                        0.00   \n",
       "5 0.25       0.28    0.29  ...                      492.00   \n",
       "6 0.00       0.00    0.00  ...                        0.00   \n",
       "7 0.07       0.03    0.02  ...                       88.00   \n",
       "8 0.80       0.95    0.65  ...                         nan   \n",
       "\n",
       "   subject_96_false_positives  subject_96_loss  subject_96_pr  \\\n",
       "0                       65.00             0.16           0.00   \n",
       "1                        5.00             0.02           0.00   \n",
       "2                       20.00             0.05           0.00   \n",
       "3                        0.00             0.46           0.65   \n",
       "4                        5.00             0.02           0.00   \n",
       "5                        0.00             1.86           0.81   \n",
       "6                        5.00             0.02           0.00   \n",
       "7                        0.00             0.58           0.09   \n",
       "8                         nan              nan            nan   \n",
       "\n",
       "   subject_96_precision  subject_96_recall  subject_96_true_negatives  \\\n",
       "0                  0.00               0.00                     835.00   \n",
       "1                  0.00               0.00                   1,223.00   \n",
       "2                  0.00               0.00                   1,000.00   \n",
       "3                  1.00               0.08                     816.00   \n",
       "4                  0.00               0.00                   1,295.00   \n",
       "5                  1.00               0.04                     616.00   \n",
       "6                  0.00               0.00                     863.00   \n",
       "7                  0.00               0.00                   1,052.00   \n",
       "8                   nan                nan                        nan   \n",
       "\n",
       "   subject_96_true_positives  true_negatives  true_positives  \n",
       "0                       0.00        7,379.00        1,842.00  \n",
       "1                       0.00        7,168.00          673.00  \n",
       "2                       0.00        6,530.00          492.00  \n",
       "3                       9.00        5,753.00        1,961.00  \n",
       "4                       0.00        6,273.00          183.00  \n",
       "5                      20.00        4,244.00          239.00  \n",
       "6                       0.00        3,633.00            0.00  \n",
       "7                       0.00        3,059.00            5.00  \n",
       "8                        nan        1,677.00          122.00  \n",
       "\n",
       "[9 rows x 132 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Session</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>loss</th>\n",
       "      <th>pr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_96_false_negatives</th>\n",
       "      <th>subject_96_false_positives</th>\n",
       "      <th>subject_96_loss</th>\n",
       "      <th>subject_96_pr</th>\n",
       "      <th>subject_96_precision</th>\n",
       "      <th>subject_96_recall</th>\n",
       "      <th>subject_96_true_negatives</th>\n",
       "      <th>subject_96_true_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>true_positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>798.00</td>\n",
       "      <td>1,447.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>813.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7,345.00</td>\n",
       "      <td>1,778.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>879.00</td>\n",
       "      <td>1,273.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,224.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7,483.00</td>\n",
       "      <td>737.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>360.00</td>\n",
       "      <td>918.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>998.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6,778.00</td>\n",
       "      <td>428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.83</td>\n",
       "      <td>897.00</td>\n",
       "      <td>1,333.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>106.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>816.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5,943.00</td>\n",
       "      <td>1,963.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.57</td>\n",
       "      <td>971.00</td>\n",
       "      <td>1,149.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,299.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6,231.00</td>\n",
       "      <td>125.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>633.00</td>\n",
       "      <td>508.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>493.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>616.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>4,344.00</td>\n",
       "      <td>187.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>183.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>860.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3,605.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>207.00</td>\n",
       "      <td>142.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,052.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3,058.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>69.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1,681.00</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows  132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Session  accuracy  auc  false_negatives  false_positives  loss  \\\n",
       "0           0        1      0.80 0.85           798.00         1,447.00  0.59   \n",
       "1           0        2      0.79 0.78           879.00         1,273.00  0.60   \n",
       "2           0        3      0.85 0.84           360.00           918.00  0.42   \n",
       "3           0        4      0.78 0.83           897.00         1,333.00  0.70   \n",
       "4           0        5      0.75 0.57           971.00         1,149.00  0.95   \n",
       "5           0        6      0.80 0.60           633.00           508.00  0.81   \n",
       "6           0        7      0.95 0.00             0.00           183.00  0.14   \n",
       "7           0        8      0.90 0.55           207.00           142.00  0.64   \n",
       "8           0        9      0.96 0.92            69.00             3.00  0.16   \n",
       "\n",
       "    pr  precision  recall  ...  subject_96_false_negatives  \\\n",
       "0 0.60       0.55    0.69  ...                        0.00   \n",
       "1 0.37       0.37    0.46  ...                        0.00   \n",
       "2 0.32       0.32    0.54  ...                        0.00   \n",
       "3 0.69       0.60    0.69  ...                      106.00   \n",
       "4 0.14       0.10    0.11  ...                        0.00   \n",
       "5 0.24       0.27    0.23  ...                      493.00   \n",
       "6 0.00       0.00    0.00  ...                        0.00   \n",
       "7 0.07       0.01    0.00  ...                       88.00   \n",
       "8 0.82       0.98    0.63  ...                         nan   \n",
       "\n",
       "   subject_96_false_positives  subject_96_loss  subject_96_pr  \\\n",
       "0                       87.00             0.21           0.00   \n",
       "1                        4.00             0.02           0.00   \n",
       "2                       22.00             0.05           0.00   \n",
       "3                        0.00             0.64           0.58   \n",
       "4                        1.00             0.01           0.00   \n",
       "5                        0.00             2.47           0.77   \n",
       "6                        8.00             0.04           0.00   \n",
       "7                        0.00             0.79           0.08   \n",
       "8                         nan              nan            nan   \n",
       "\n",
       "   subject_96_precision  subject_96_recall  subject_96_true_negatives  \\\n",
       "0                  0.00               0.00                     813.00   \n",
       "1                  0.00               0.00                   1,224.00   \n",
       "2                  0.00               0.00                     998.00   \n",
       "3                  1.00               0.05                     816.00   \n",
       "4                  0.00               0.00                   1,299.00   \n",
       "5                  1.00               0.04                     616.00   \n",
       "6                  0.00               0.00                     860.00   \n",
       "7                  0.00               0.00                   1,052.00   \n",
       "8                   nan                nan                        nan   \n",
       "\n",
       "   subject_96_true_positives  true_negatives  true_positives  \n",
       "0                       0.00        7,345.00        1,778.00  \n",
       "1                       0.00        7,483.00          737.00  \n",
       "2                       0.00        6,778.00          428.00  \n",
       "3                       6.00        5,943.00        1,963.00  \n",
       "4                       0.00        6,231.00          125.00  \n",
       "5                      19.00        4,344.00          187.00  \n",
       "6                       0.00        3,605.00            0.00  \n",
       "7                       0.00        3,058.00            1.00  \n",
       "8                        nan        1,681.00          119.00  \n",
       "\n",
       "[9 rows x 132 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_results = rE.compute_average_metrics('person', subjects, pivot, RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-26a7b56d3a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXPERIMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rE' is not defined"
     ]
    }
   ],
   "source": [
    "rE.results_table(EXPERIMENT, metric, view_by, subjects, pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain Pivots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Person</th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th># of Persons</th>\n",
       "      <th>Pain</th>\n",
       "      <th>No Pain</th>\n",
       "      <th>Pain %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Session</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>72</td>\n",
       "      <td></td>\n",
       "      <td>244</td>\n",
       "      <td>1052</td>\n",
       "      <td>464</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>116</td>\n",
       "      <td>12</td>\n",
       "      <td>2180</td>\n",
       "      <td>12424</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>148</td>\n",
       "      <td></td>\n",
       "      <td>532</td>\n",
       "      <td>64</td>\n",
       "      <td>536</td>\n",
       "      <td>696</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>600</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>2576</td>\n",
       "      <td>8792</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>64</td>\n",
       "      <td>484</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>848</td>\n",
       "      <td></td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>1616</td>\n",
       "      <td>8756</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>484</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td>56</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>788</td>\n",
       "      <td>7696</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>248</td>\n",
       "      <td>660</td>\n",
       "      <td>724</td>\n",
       "      <td>112</td>\n",
       "      <td>828</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>2860</td>\n",
       "      <td>7276</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>188</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>792</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>116</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1096</td>\n",
       "      <td>7380</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>44</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>264</td>\n",
       "      <td></td>\n",
       "      <td>512</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>820</td>\n",
       "      <td>4852</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>3788</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>3200</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>188</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>1684</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>368</td>\n",
       "      <td>336</td>\n",
       "      <td>424</td>\n",
       "      <td>532</td>\n",
       "      <td>620</td>\n",
       "      <td>4272</td>\n",
       "      <td>1884</td>\n",
       "      <td>712</td>\n",
       "      <td>1768</td>\n",
       "      <td>716</td>\n",
       "      <td>396</td>\n",
       "      <td>304</td>\n",
       "      <td>84</td>\n",
       "      <td>12332</td>\n",
       "      <td>65848</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Person    43   48   52   59   64    80    92   96   107  109  115  120  \\\n",
       "Session                                                                  \n",
       "0        140        72       244  1052   464         32        60  116   \n",
       "1             148       532   64   536   696             600             \n",
       "2                             64   484              848       220        \n",
       "3                                  484               60        56  188   \n",
       "4        228                 248   660   724  112   828        60        \n",
       "5             188                  792                   116             \n",
       "6                   44             264        512                        \n",
       "7                                                                        \n",
       "8                  120                         88                        \n",
       "9                  188                                                   \n",
       "Total    368  336  424  532  620  4272  1884  712  1768  716  396  304   \n",
       "\n",
       "Person   # of Persons   Pain  No Pain Pain %  \n",
       "Session                                       \n",
       "0                  12   2180    12424    0.1  \n",
       "1                  12   2576     8792    0.2  \n",
       "2                  11   1616     8756    0.2  \n",
       "3                  11    788     7696    0.1  \n",
       "4                  11   2860     7276    0.3  \n",
       "5                   9   1096     7380    0.1  \n",
       "6                   8    820     4852    0.1  \n",
       "7                   6            3788         \n",
       "8                   3    208     3200    0.1  \n",
       "9                   1    188     1684    0.1  \n",
       "Total              84  12332    65848    0.2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL.create_pivot(os.path.join(DATA, 'group_2'), 'Session', 'Person', 'Session')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Session</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th># of Sessions</th>\n",
       "      <th>Pain</th>\n",
       "      <th>No Pain</th>\n",
       "      <th>Pain %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>72</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>44</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>10</td>\n",
       "      <td>424</td>\n",
       "      <td>10012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>228</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>368</td>\n",
       "      <td>4112</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>112</td>\n",
       "      <td></td>\n",
       "      <td>512</td>\n",
       "      <td></td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>712</td>\n",
       "      <td>8700</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>32</td>\n",
       "      <td></td>\n",
       "      <td>848</td>\n",
       "      <td>60</td>\n",
       "      <td>828</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>1768</td>\n",
       "      <td>6396</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td></td>\n",
       "      <td>600</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>116</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>716</td>\n",
       "      <td>6896</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>116</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>188</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>304</td>\n",
       "      <td>5960</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td></td>\n",
       "      <td>148</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>188</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>336</td>\n",
       "      <td>3192</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1052</td>\n",
       "      <td>536</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>660</td>\n",
       "      <td>792</td>\n",
       "      <td>264</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>4272</td>\n",
       "      <td>3584</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>244</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td></td>\n",
       "      <td>248</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>620</td>\n",
       "      <td>5576</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>464</td>\n",
       "      <td>696</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>724</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>1884</td>\n",
       "      <td>4124</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td>220</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>396</td>\n",
       "      <td>4736</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td></td>\n",
       "      <td>532</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>532</td>\n",
       "      <td>2560</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>2180</td>\n",
       "      <td>2576</td>\n",
       "      <td>1616</td>\n",
       "      <td>788</td>\n",
       "      <td>2860</td>\n",
       "      <td>1096</td>\n",
       "      <td>820</td>\n",
       "      <td></td>\n",
       "      <td>208</td>\n",
       "      <td>188</td>\n",
       "      <td>84</td>\n",
       "      <td>12332</td>\n",
       "      <td>65848</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Session     0     1     2    3     4     5    6 7    8    9  # of Sessions  \\\n",
       "Person                                                                       \n",
       "52         72                                44    120  188             10   \n",
       "43        140                    228                                     9   \n",
       "96                               112        512     88                   9   \n",
       "107        32         848   60   828                                     8   \n",
       "109             600                    116                               8   \n",
       "120       116              188                                           8   \n",
       "48              148                    188                               7   \n",
       "80       1052   536   484  484   660   792  264                          7   \n",
       "64        244    64    64        248                                     6   \n",
       "92        464   696              724                                     5   \n",
       "115        60         220   56    60                                     5   \n",
       "59              532                                                      2   \n",
       "Total    2180  2576  1616  788  2860  1096  820    208  188             84   \n",
       "\n",
       "Session   Pain  No Pain  Pain %  \n",
       "Person                           \n",
       "52         424    10012     0.0  \n",
       "43         368     4112     0.1  \n",
       "96         712     8700     0.1  \n",
       "107       1768     6396     0.2  \n",
       "109        716     6896     0.1  \n",
       "120        304     5960     0.1  \n",
       "48         336     3192     0.1  \n",
       "80        4272     3584     0.5  \n",
       "64         620     5576     0.1  \n",
       "92        1884     4124     0.3  \n",
       "115        396     4736     0.1  \n",
       "59         532     2560     0.2  \n",
       "Total    12332    65848     0.2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL.create_pivot(os.path.join(DATA, 'group_2'), 'Person', 'Session', 'Person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dL.create_pain_df(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Trans_1'] == 'original') & (df['Trans_2'] == 'straight')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_pain = df[df['Pain'] == 0]\n",
    "df_pain = df[df['Pain'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 42,  47,  49,  66,  95,  97, 103, 106, 108, 121, 123, 124]),\n",
       " array([1895, 1544, 2194, 1947,  304, 3212, 2738, 2281, 2453,  478,  822,\n",
       "         699]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_no_pain[df_no_pain['Person'].isin(group_1)]['Person'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 42,  47,  49,  66,  95,  97, 103, 106, 108, 121, 123, 124]),\n",
       " array([239,  64, 524, 512, 498, 147, 824, 517, 455,  40, 361, 996]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_pain[df_pain['Person'].isin(group_1)]['Person'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = [42, 47, 49, 66, 95, 97, 103, 106, 108, 121, 123, 124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = os.path.join(RESULTS, '123 - Sd 123 - Unbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_table(experiment_path, metric, view_by, subjects, pivot):\n",
    "    sessions = True if view_by in 'sessions' else False\n",
    "\n",
    "    # Sort according to name not timestamp\n",
    "    df_concat = pd.DataFrame()\n",
    "    list_dir = os.listdir(experiment_path)\n",
    "    f_paths = [file.split(\"PAIN_\")[1] for file in list_dir if 'PAIN' in file]\n",
    "    list_dir = [file for file in list_dir if 'PAIN' in file]\n",
    "    folders = [x for _, x in sorted(zip(f_paths, list_dir))]\n",
    "\n",
    "    for file in folders:\n",
    "        if os.path.isfile(os.path.join(experiment_path, file)):\n",
    "            # Read in one file per experiment\n",
    "            df = pd.read_csv(os.path.join(experiment_path, file))\n",
    "            df = df.rename(columns={'Unnamed: 0': 'Epoch'})\n",
    "\n",
    "            # Compute Means per subject\n",
    "            df_mean = weighted_mean_SD(df, subjects, metric, sessions, pivot)\n",
    "            # noinspection PyTypeChecker\n",
    "            df_mean['Experiment'] = file.split('PAIN_')[1].split('_TEST')[0]\n",
    "\n",
    "            # Concatenate all experiments\n",
    "            df_concat = pd.concat((df_concat, df_mean))\n",
    "    df_concat.set_index('Experiment', inplace=True)\n",
    "\n",
    "    # Sort rows according to experiment number\n",
    "    df_concat['indexNumber'] = [int(i.split('-')[0]) for i in df_concat.index]\n",
    "    df_concat = df_concat.sort_values(by='indexNumber')\n",
    "    df_concat.drop('indexNumber', inplace=True, axis=1)\n",
    "\n",
    "    # Calculate Regular Mean\n",
    "    cols = [col for col in df_concat.columns.values if type(col) is int]\n",
    "    df_concat['Mean'] = df_concat[cols].mean(axis=1)\n",
    "    df_concat['SD'] = df_concat[cols].std(axis=1)\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment names\n",
    "exp_names = {\n",
    "    '0-sessions-Baseline-random': 'RANDOM',\n",
    "    '0-sessions-Baseline-central-pre-training': 'BC-CNN',\n",
    "    '0-sessions-Baseline-federated-pre-training': 'BF-CNN',\n",
    "    '1-sessions-Centralized-no-pre-training': 'C-CNN (N)',\n",
    "    '10-sessions-Federated-central-pre-training-local-models': 'FL-CNN (C)',\n",
    "    '11-sessions-Federated-federated-pre-training-local-models': 'FL-CNN (F)',\n",
    "    '2-sessions-Centralized-pre-training': 'C-CNN (C)',\n",
    "    '3-sessions-Federated-no-pre-training': 'F-CNN (N)',\n",
    "    '4-sessions-Federated-central-pre-training': 'FDL',\n",
    "    '5-sessions-Federated-federated-pre-training': 'F-CNN (F)',\n",
    "    '6-sessions-Federated-no-pre-training-personalization': 'FP-CNN (N)',\n",
    "    '7-sessions-Federated-central-pre-training-personalization': 'PFDL',\n",
    "    '8-sessions-Federated-federated-pre-training-personalization': 'FP-CNN (F)',\n",
    "    '9-sessions-Federated-no-pre-training-local-models': 'FL-CNN (N)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_exp = ['FDL', 'PFDL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detailed_metric_table(results_path, subjects, metric):\n",
    "    folder_paths = [os.path.join(results_path, folder) for folder in os.listdir(results_path) if 'Seed' in folder]\n",
    "\n",
    "    count = 0\n",
    "    for folder_path in folder_paths:\n",
    "\n",
    "        # Sort according to name not timestamp\n",
    "        list_dir = os.listdir(folder_path)\n",
    "        f_paths = [file.split(\"PAIN_\")[1] for file in list_dir if 'PAIN' in file]\n",
    "        list_dir = [file for file in list_dir if 'PAIN' in file]\n",
    "        folders = [x for _, x in sorted(zip(f_paths, list_dir))]\n",
    "\n",
    "        df_concat = pd.DataFrame()\n",
    "        for file in folders:\n",
    "            if os.path.isfile(os.path.join(folder_path, file)):\n",
    "\n",
    "                # Read in df\n",
    "                df = pd.read_csv(os.path.join(folder_path, file))\n",
    "\n",
    "                # Create table\n",
    "                columns = ['subject_{}_{}'.format(subject, metric) for subject in subjects]\n",
    "                df_new = df[columns]\n",
    "                df_new = df_new.rename(columns={col: int(col.split('_')[1].split('_')[0]) for col in df_new.columns if 'subject' in col})\n",
    "                df_new['Experiment'] = file.split('PAIN_')[1].split('_TEST')[0]\n",
    "                df_concat = pd.concat((df_concat, df_new))\n",
    "\n",
    "        if count > 0:\n",
    "            df_add[subjects] = df_add[subjects].add(df_concat[subjects])\n",
    "        else:\n",
    "            df_add = df_concat.copy()\n",
    "\n",
    "        count += 1\n",
    "    df_add[subjects] = df_add[subjects].divide(count)\n",
    "    return df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detail_prec = create_detailed_metric_table(RESULTS, subjects, 'precision')\n",
    "df_detail_recall = create_detailed_metric_table(RESULTS, subjects, 'recall')\n",
    "df_detail_f1 = 2 * df_detail_recall[subjects] * df_detail_prec[subjects] / (df_detail_recall[subjects] + df_detail_prec[subjects])\n",
    "df_detail_f1['Experiment'] = df_detail_prec['Experiment']\n",
    "df_detail_f1 = df_detail_f1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan%</td>\n",
       "      <td>10.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>0.9%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>50.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>32.5%</td>\n",
       "      <td>37.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>50.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>45.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>65.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>45.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>11.8%</td>\n",
       "      <td>64.6%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.2%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>43.0%</td>\n",
       "      <td>80.7%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>59.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>37.9%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>30.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>51.2%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>75.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-central-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan%</td>\n",
       "      <td>38.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>51.6%</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>57.5%</td>\n",
       "      <td>77.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>21.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>10.5%</td>\n",
       "      <td>33.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>61.2%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>55.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>42.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>61.6%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.9%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>20.4%</td>\n",
       "      <td>70.9%</td>\n",
       "      <td>72.0%</td>\n",
       "      <td>36.0%</td>\n",
       "      <td>61.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>50.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan%</td>\n",
       "      <td>12.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>24.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0.9%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>18.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>24.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>23.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>19.9%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0.2%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>57.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-federated-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan%</td>\n",
       "      <td>26.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>37.0%</td>\n",
       "      <td>6.9%</td>\n",
       "      <td>48.6%</td>\n",
       "      <td>61.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>45.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7.5%</td>\n",
       "      <td>34.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>55.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>22.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>6.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>10.5%</td>\n",
       "      <td>35.8%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>26.4%</td>\n",
       "      <td>41.1%</td>\n",
       "      <td>43.4%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>46.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9.2%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan%</td>\n",
       "      <td>22.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>61.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>11.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>6.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>28.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>43.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>12.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0-sessions-Baseline-random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan%</td>\n",
       "      <td>33.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>36.1%</td>\n",
       "      <td>6.7%</td>\n",
       "      <td>43.8%</td>\n",
       "      <td>52.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>40.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>1-sessions-Centralized-no-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>3.8%</td>\n",
       "      <td>34.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>20.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>40.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>1-sessions-Centralized-no-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>55.2%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>27.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9.9%</td>\n",
       "      <td>44.6%</td>\n",
       "      <td>1-sessions-Centralized-no-pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>6-sessions-Federated-no-pre-training-personali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>12.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>4.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>6-sessions-Federated-no-pre-training-personali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>6-sessions-Federated-no-pre-training-personali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan%</td>\n",
       "      <td>10.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>0.9%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>50.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>37.2%</td>\n",
       "      <td>57.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>58.9%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>60.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>6.4%</td>\n",
       "      <td>48.3%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>79.3%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>70.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>49.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan%</td>\n",
       "      <td>4.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>3.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>1.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>65.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>24.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>7-sessions-Federated-central-pre-training-pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan%</td>\n",
       "      <td>38.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>51.6%</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>57.5%</td>\n",
       "      <td>77.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>21.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>17.7%</td>\n",
       "      <td>59.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>47.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>55.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>75.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>66.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>3.1%</td>\n",
       "      <td>32.2%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>71.2%</td>\n",
       "      <td>72.1%</td>\n",
       "      <td>28.3%</td>\n",
       "      <td>36.0%</td>\n",
       "      <td>71.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>26.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>1.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0.9%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>23.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>3.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>64.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8-sessions-Federated-federated-pre-training-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan%</td>\n",
       "      <td>33.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>36.1%</td>\n",
       "      <td>6.7%</td>\n",
       "      <td>43.8%</td>\n",
       "      <td>52.4%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>40.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>0.2%</td>\n",
       "      <td>51.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>25.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>19.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>65.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>10.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>13.4%</td>\n",
       "      <td>0.1%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>44.0%</td>\n",
       "      <td>48.9%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>17.1%</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>23.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>8.6%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>10.8%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>37.3%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>12.1%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9.2%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>73.7%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>nan%</td>\n",
       "      <td>9-sessions-Federated-no-pre-training-local-models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      43    48    52    59    64    80    92    96   107   109   115   120  \\\n",
       "0   nan% 10.7%  nan% 56.0%  0.9% 60.5% 91.7%  nan%  nan% 50.5%  nan%  nan%   \n",
       "1   nan%  nan%  nan%  nan% 32.5% 37.3%  nan%  nan% 50.4%  nan% 45.6%  nan%   \n",
       "2   nan%  nan%  nan%  nan%  nan% 65.5%  nan%  nan% 45.3%  nan% 11.8% 64.6%   \n",
       "3  24.2%  nan%  nan%  nan% 43.0% 80.7% 70.7% 15.8% 59.6%  nan% 37.9%  nan%   \n",
       "4   nan%  nan%  nan%  nan%  nan% 30.1%  nan%  nan%  nan%  8.3%  nan%  nan%   \n",
       "5   nan%  nan%  nan%  nan%  nan% 51.2%  nan%  8.8%  nan%  nan%  nan%  nan%   \n",
       "6   nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "7   nan%  nan%  4.6%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "8   nan%  nan% 75.1%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "0   nan% 38.7%  nan% 51.6%  2.3% 57.5% 77.4%  nan%  nan% 21.7%  nan%  nan%   \n",
       "1   nan%  nan%  nan%  nan% 10.5% 33.8%  nan%  nan% 61.2%  nan% 55.0%  nan%   \n",
       "2   nan%  nan%  nan%  nan%  nan% 71.8%  nan%  nan% 42.5%  nan%  nan% 61.6%   \n",
       "3   3.9%  nan%  nan%  nan% 20.4% 70.9% 72.0% 36.0% 61.5%  nan% 50.3%  nan%   \n",
       "4   nan% 12.6%  nan%  nan%  nan% 24.1%  nan%  nan%  nan%  0.9%  nan%  nan%   \n",
       "5   nan%  nan% 18.7%  nan%  nan% 24.0%  nan% 23.0%  nan%  nan%  nan%  nan%   \n",
       "6   nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "7   nan%  nan% 19.9%  nan%  nan%  nan%  nan%  0.2%  nan%  nan%  nan%  nan%   \n",
       "8   nan%  nan% 57.0%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "0   nan% 26.0%  nan% 37.0%  6.9% 48.6% 61.4%  nan%  nan% 45.1%  nan%  nan%   \n",
       "1   nan%  nan%  nan%  nan%  7.5% 34.5%  nan%  nan% 55.1%  nan% 22.1%  nan%   \n",
       "2   nan%  nan%  nan%  nan%  nan% 50.0%  nan%  nan%  6.5%  nan% 10.5% 35.8%   \n",
       "3  35.3%  nan%  nan%  nan% 26.4% 41.1% 43.4% 15.3% 46.5%  nan%  9.2%  nan%   \n",
       "4   nan% 22.6%  nan%  nan%  nan% 61.4%  nan%  nan%  nan% 11.5%  nan%  nan%   \n",
       "5   nan%  nan%  6.8%  nan%  nan% 28.1%  nan% 43.6%  nan%  nan%  nan%  nan%   \n",
       "6   nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "7   nan%  nan%  8.3%  nan%  nan%  nan%  nan% 10.0%  nan%  nan%  nan%  nan%   \n",
       "8   nan%  nan% 12.7%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "0   nan% 33.8%  nan% 36.1%  6.7% 43.8% 52.4%  nan%  nan% 40.6%  nan%  nan%   \n",
       "1   nan%  nan%  nan%  nan%  3.8% 34.1%  nan%  nan% 20.6%  nan% 40.1%  nan%   \n",
       "2   nan%  nan%  nan%  nan%  nan% 55.2%  nan%  nan% 27.1%  nan%  9.9% 44.6%   \n",
       "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "6   nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "7   nan%  nan% 12.6%  nan%  nan%  nan%  nan%  4.3%  nan%  nan%  nan%  nan%   \n",
       "8   nan%  nan% 74.9%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "0   nan% 10.7%  nan% 56.0%  0.9% 60.5% 91.7%  nan%  nan% 50.5%  nan%  nan%   \n",
       "1   nan%  nan%  nan%  nan% 37.2% 57.3%  nan%  nan% 58.9%  nan% 60.7%  nan%   \n",
       "2   nan%  nan%  nan%  nan%  nan% 74.3%  nan%  nan% 53.5%  nan%  6.4% 48.3%   \n",
       "3  72.0%  nan%  nan%  nan% 71.9% 79.3% 65.9% 15.8% 70.5%  nan% 49.0%  nan%   \n",
       "4   nan%  4.1%  nan%  nan%  nan%  8.6%  nan%  nan%  nan%  3.4%  nan%  nan%   \n",
       "5   nan%  nan%  1.3%  nan%  nan%  nan%  nan% 65.0%  nan%  nan%  nan%  nan%   \n",
       "6   nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "7   nan%  nan% 24.5%  nan%  nan%  nan%  nan%  2.0%  nan%  nan%  nan%  nan%   \n",
       "8   nan%  nan% 60.0%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "0   nan% 38.7%  nan% 51.6%  2.3% 57.5% 77.4%  nan%  nan% 21.7%  nan%  nan%   \n",
       "1   nan%  nan%  nan%  nan% 17.7% 59.7%  nan%  nan% 47.7%  nan% 55.8%  nan%   \n",
       "2   nan%  nan%  nan%  nan%  nan% 75.7%  nan%  nan% 66.3%  nan%  3.1% 32.2%   \n",
       "3  66.5%  nan%  nan%  nan% 71.2% 72.1% 28.3% 36.0% 71.4%  nan% 26.4%  nan%   \n",
       "4   nan%  4.0%  nan%  nan%  nan%  4.6%  nan%  nan%  nan%  1.3%  nan%  nan%   \n",
       "5   nan%  nan%  0.9%  nan%  nan%  nan%  nan% 54.1%  nan%  nan%  nan%  nan%   \n",
       "6   nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "7   nan%  nan% 23.3%  nan%  nan%  nan%  nan%  3.5%  nan%  nan%  nan%  nan%   \n",
       "8   nan%  nan% 64.8%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "0   nan% 33.8%  nan% 36.1%  6.7% 43.8% 52.4%  nan%  nan% 40.6%  nan%  nan%   \n",
       "1   nan%  nan%  nan%  nan%  0.2% 51.5%  nan%  nan% 25.8%  nan% 19.8%  nan%   \n",
       "2   nan%  nan%  nan%  nan%  nan% 65.7%  nan%  nan% 10.1%  nan% 13.4%  0.1%   \n",
       "3  21.0%  nan%  nan%  nan% 44.0% 48.9%  2.0% 17.1% 62.5%  nan% 23.7%  nan%   \n",
       "4   nan%  4.0%  nan%  nan%  nan%  8.6%  nan%  nan%  nan% 10.8%  nan%  nan%   \n",
       "5   nan%  nan%  nan%  nan%  nan%  nan%  nan% 37.3%  nan%  nan%  nan%  nan%   \n",
       "6   nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "7   nan%  nan% 12.1%  nan%  nan%  nan%  nan%  9.2%  nan%  nan%  nan%  nan%   \n",
       "8   nan%  nan% 73.7%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%  nan%   \n",
       "\n",
       "                                           Experiment  \n",
       "0            0-sessions-Baseline-central-pre-training  \n",
       "1            0-sessions-Baseline-central-pre-training  \n",
       "2            0-sessions-Baseline-central-pre-training  \n",
       "3            0-sessions-Baseline-central-pre-training  \n",
       "4            0-sessions-Baseline-central-pre-training  \n",
       "5            0-sessions-Baseline-central-pre-training  \n",
       "6            0-sessions-Baseline-central-pre-training  \n",
       "7            0-sessions-Baseline-central-pre-training  \n",
       "8            0-sessions-Baseline-central-pre-training  \n",
       "0          0-sessions-Baseline-federated-pre-training  \n",
       "1          0-sessions-Baseline-federated-pre-training  \n",
       "2          0-sessions-Baseline-federated-pre-training  \n",
       "3          0-sessions-Baseline-federated-pre-training  \n",
       "4          0-sessions-Baseline-federated-pre-training  \n",
       "5          0-sessions-Baseline-federated-pre-training  \n",
       "6          0-sessions-Baseline-federated-pre-training  \n",
       "7          0-sessions-Baseline-federated-pre-training  \n",
       "8          0-sessions-Baseline-federated-pre-training  \n",
       "0                          0-sessions-Baseline-random  \n",
       "1                          0-sessions-Baseline-random  \n",
       "2                          0-sessions-Baseline-random  \n",
       "3                          0-sessions-Baseline-random  \n",
       "4                          0-sessions-Baseline-random  \n",
       "5                          0-sessions-Baseline-random  \n",
       "6                          0-sessions-Baseline-random  \n",
       "7                          0-sessions-Baseline-random  \n",
       "8                          0-sessions-Baseline-random  \n",
       "0              1-sessions-Centralized-no-pre-training  \n",
       "1              1-sessions-Centralized-no-pre-training  \n",
       "2              1-sessions-Centralized-no-pre-training  \n",
       "..                                                ...  \n",
       "6   6-sessions-Federated-no-pre-training-personali...  \n",
       "7   6-sessions-Federated-no-pre-training-personali...  \n",
       "8   6-sessions-Federated-no-pre-training-personali...  \n",
       "0   7-sessions-Federated-central-pre-training-pers...  \n",
       "1   7-sessions-Federated-central-pre-training-pers...  \n",
       "2   7-sessions-Federated-central-pre-training-pers...  \n",
       "3   7-sessions-Federated-central-pre-training-pers...  \n",
       "4   7-sessions-Federated-central-pre-training-pers...  \n",
       "5   7-sessions-Federated-central-pre-training-pers...  \n",
       "6   7-sessions-Federated-central-pre-training-pers...  \n",
       "7   7-sessions-Federated-central-pre-training-pers...  \n",
       "8   7-sessions-Federated-central-pre-training-pers...  \n",
       "0   8-sessions-Federated-federated-pre-training-pe...  \n",
       "1   8-sessions-Federated-federated-pre-training-pe...  \n",
       "2   8-sessions-Federated-federated-pre-training-pe...  \n",
       "3   8-sessions-Federated-federated-pre-training-pe...  \n",
       "4   8-sessions-Federated-federated-pre-training-pe...  \n",
       "5   8-sessions-Federated-federated-pre-training-pe...  \n",
       "6   8-sessions-Federated-federated-pre-training-pe...  \n",
       "7   8-sessions-Federated-federated-pre-training-pe...  \n",
       "8   8-sessions-Federated-federated-pre-training-pe...  \n",
       "0   9-sessions-Federated-no-pre-training-local-models  \n",
       "1   9-sessions-Federated-no-pre-training-local-models  \n",
       "2   9-sessions-Federated-no-pre-training-local-models  \n",
       "3   9-sessions-Federated-no-pre-training-local-models  \n",
       "4   9-sessions-Federated-no-pre-training-local-models  \n",
       "5   9-sessions-Federated-no-pre-training-local-models  \n",
       "6   9-sessions-Federated-no-pre-training-local-models  \n",
       "7   9-sessions-Federated-no-pre-training-local-models  \n",
       "8   9-sessions-Federated-no-pre-training-local-models  \n",
       "\n",
       "[126 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detail_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detail_f1 = df_detail_f1.reset_index().rename(columns={'index': 'Session'})\n",
    "df_detail_f1['Session'] += 1\n",
    "df_detail_f1['Experiment'].replace(exp_names, inplace=True)\n",
    "df_top = df_detail_f1[df_detail_f1['Experiment'].isin(top_exp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winners = df_top.copy()\n",
    "for subject in subjects:\n",
    "    idx = df_top.groupby(['Session'])[subject].transform(max) == df_top[subject]\n",
    "    df_winners[subject] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winners['Best'] = df_winners[subjects].sum(axis=1)\n",
    "df_winners.rename(columns={'Session': 'Session #'}, inplace=True)\n",
    "table_final = df_winners.pivot('Experiment', 'Session #', 'Best')\n",
    "table_final_percentage = table_final / table_final.sum(axis=0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session #</th>\n",
       "      <th>43</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>59</th>\n",
       "      <th>64</th>\n",
       "      <th>80</th>\n",
       "      <th>92</th>\n",
       "      <th>96</th>\n",
       "      <th>107</th>\n",
       "      <th>109</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>FDL</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>FDL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>FDL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>FDL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>FDL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>FDL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>FDL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>FDL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>FDL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PFDL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Session #     43     48     52     59     64     80     92     96    107  \\\n",
       "72           1  False   True  False   True   True   True   True  False  False   \n",
       "73           2  False  False  False  False  False  False  False  False   True   \n",
       "74           3  False  False  False  False  False  False  False  False  False   \n",
       "75           4  False  False  False  False  False   True   True   True  False   \n",
       "76           5  False  False  False  False  False  False  False  False  False   \n",
       "77           6  False  False   True  False  False   True  False   True  False   \n",
       "78           7  False  False  False  False  False  False  False  False  False   \n",
       "79           8  False  False  False  False  False  False  False  False  False   \n",
       "80           9  False  False   True  False  False  False  False  False  False   \n",
       "99           1  False   True  False   True   True   True   True  False  False   \n",
       "100          2  False  False  False  False   True   True  False  False  False   \n",
       "101          3  False  False  False  False  False   True  False  False   True   \n",
       "102          4   True  False  False  False   True  False  False  False   True   \n",
       "103          5  False   True  False  False  False   True  False  False  False   \n",
       "104          6  False  False  False  False  False  False  False  False  False   \n",
       "105          7  False  False  False  False  False  False  False  False  False   \n",
       "106          8  False  False   True  False  False  False  False   True  False   \n",
       "107          9  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "       109    115    120 Experiment  Best  \n",
       "72    True  False  False        FDL     6  \n",
       "73   False  False  False        FDL     1  \n",
       "74   False  False   True        FDL     1  \n",
       "75   False  False  False        FDL     3  \n",
       "76    True  False  False        FDL     1  \n",
       "77   False  False  False        FDL     3  \n",
       "78   False  False  False        FDL     0  \n",
       "79   False  False  False        FDL     0  \n",
       "80   False  False  False        FDL     1  \n",
       "99    True  False  False       PFDL     6  \n",
       "100  False   True  False       PFDL     3  \n",
       "101  False   True  False       PFDL     3  \n",
       "102  False   True  False       PFDL     4  \n",
       "103  False  False  False       PFDL     2  \n",
       "104  False  False  False       PFDL     0  \n",
       "105  False  False  False       PFDL     0  \n",
       "106  False  False  False       PFDL     2  \n",
       "107  False  False  False       PFDL     0  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PLT Parameters\n",
    "plt.rcParams.update({'font.size': 22, \n",
    "                     'font.family' : 'cmr10', \n",
    "                     'font.weight' : 'normal',\n",
    "                     'axes.titlesize' : 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = table_final.T.reset_index().plot.bar(x='Session #', y=['FDL', 'PFDL'], figsize=(12,8), rot=0, color=['#CD6155', '#2E86C1'])\n",
    "# ax = table_final_percentage.T.reset_index().plot.bar(x='Session #', y=['FDL', 'PFDL'], figsize=(12,8), rot=0, color=['#CD6155', '#2E86C1'])\n",
    "# ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.legend(['FDL', 'PFDL'])\n",
    "# ax.set_ylabel('% of test subjects')\n",
    "ax.set_ylabel('# of test subjects')\n",
    "plt.savefig('F1 Comparison absolute.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FederatedLearning",
   "language": "python",
   "name": "federatedlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
